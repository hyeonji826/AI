{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PT0bZA-sGKj9CIJdZmsFyg7I2yIxbba4",
      "authorship_tag": "ABX9TyNhsWybFWWHR8uzCS5Aklke",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeonji826/AI/blob/main/AI%20Agent/5_LangGraph_Reflection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Reflection\n",
        "Reflection은 에이전트가 스스로 결과를 평가·비판 한 뒤 그 피드백을 상태(state)에 기록하고, 필요하면 수정 루프로 되돌아가 답을 개선하는 설계 패턴입니다. 보통 “작성 노드(답 생성) → 리플렉션 노드(자기평가) → 라우팅(조건부 엣지)”로 구성되며, 리플렉션 노드는 품질 기준(예: 정확성, 근거, 형식)을 점수·코멘트(score, critique)로 남깁니다. 라우터는 이 정보를 읽어 임계값 미달이면 작성 노드로 되감기, 충족하면 종료 노드로 이동합니다. 무한 루프를 막기 위해 max_iters 같은 반복 한도를 두며, 툴 호출과는 별개로 LLM의 자기검토 능력을 활용해 코드 생성, 질의응답, 체인드 리저닝 등의 정확도·일관성을 높이는 데 쓰입니다.\n",
        "\n",
        "<img src=\"https://blog.kakaocdn.net/dna/b1Ic0g/btsQwHJRkMb/AAAAAAAAAAAAAAAAAAAAAGKNg2obE4vZt0Q9Owo95bbskLQjFYuGpmMZ7DIAuDnX/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=Rnehl5D3y2D35AdwwyRmWFn%2B1%2Fw%3D\" width=700>"
      ],
      "metadata": {
        "id": "8xKEwAwQuxtZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVDGJDi_unYy",
        "outputId": "02d1d44b-deba-400e-9425-255201842cc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY: ··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Beo1v-vYu_c5",
        "outputId": "ce1e1457-a3df-4d3f-bd65-c1a28188dee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.76 (from langchain_openai)\n",
            "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.106.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.4.24)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (25.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (2.11.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.104.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.76->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.5.0)\n",
            "Downloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core, langchain_openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.75\n",
            "    Uninstalling langchain-core-0.3.75:\n",
            "      Successfully uninstalled langchain-core-0.3.75\n",
            "Successfully installed langchain-core-0.3.76 langchain_openai-0.3.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 가사 생성"
      ],
      "metadata": {
        "id": "yPQyxkS6vJT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"당신은 5단락 노래가사를 훌륭하게 작성하는 작사 도우미입니다.\"\n",
        "            \"사용자의 요청에 따라 최고의 가사를 작성하세요.\"\n",
        "            \"사용자가 피드백을 제공할 경우, 이전 시도에서 개선된 수정본을 작성해 응답하세요.\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-5-nano\")\n",
        "generate = prompt | llm"
      ],
      "metadata": {
        "id": "BGgLB7tIvLSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lyric = \"\"\n",
        "request = HumanMessage(\n",
        "    content=\"코딩에 대한 가사를 작성해주세요.\"\n",
        ")\n",
        "for chunk in generate.stream({\"messages\": [request]}):\n",
        "    print(chunk.content, end=\"\")\n",
        "    lyric += chunk.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNtg3HbmvUZv",
        "outputId": "98e6d9a2-f22b-4b05-8cf6-d3d2ef56cc7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "검은 화면 위로 번쩍이는 숫자의 노래가 흐른다\n",
            "커서가 깜빡일 때마다 세상은 다시 깨어난다\n",
            "커피 향과 전기의 냄새 속에서 나는 코드를 노래한다\n",
            "루프의 박자에 마음이 따라 흘러간다\n",
            "새로운 시작은 늘 한 줄의 코드에서 시작된다\n",
            "\n",
            "에러는 그림자, 디버거는 빛\n",
            "컴파일은 숨을 고르는 순간\n",
            "스택 트레이스가 길을 가리켜도 나는 포기하지 않는다\n",
            "원인을 찾아 한 줄씩 고쳐나가며 배우는 법\n",
            "브레이크포인트에 멈춰 선 마음은 다시 달려간다\n",
            "\n",
            "함수는 마음의 문을 열고 닫는 열쇠\n",
            "나는 이름 있는 인자들을 불러 모아 이야기를 만든다\n",
            "반환값은 어제와 오늘 사이의 약속\n",
            "조건문은 선택의 갈림길처럼 방향을 바꾼다\n",
            "참과 거짓 사이에서 나는 최적의 길을 찾아 간다\n",
            "\n",
            "깃은 협업의 지도, 커밋은 기억의 조각\n",
            "브랜치는 서로 다른 꿈의 가지\n",
            "병합은 충돌을 노래로 녹여 하나로 만든다\n",
            "푸시와 풀은 서로의 이야기를 세계로 흘려보낸다\n",
            "배포의 순간, 세상에 작은 기적이 모습을 드러낸다\n",
            "\n",
            "다음 버전의 창밖에서 새로운 문제를 기다린다\n",
            "계속 업데이트되며 배우는 나는 더 나아진다\n",
            "오류를 친구 삼아도 성장하는 나를 믿는다\n",
            "코드는 우리를 만났고, 함께 세상을 바꾼다\n",
            "오늘도 실행을 눌러 내일의 이야기를 시작한다"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 가사 개선"
      ],
      "metadata": {
        "id": "3YY5hELyvU67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reflection_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"당신은 가사를 채점하는 작사가입니다. 사용자가 제출한 작사에 대한 비평과 개선 사항을 작성하세요.\"\n",
        "            \"가사의 길이, 깊이, 문체 등을 포함해 구체적인 개선 요청을 제공하세요.\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "reflect = reflection_prompt | llm"
      ],
      "metadata": {
        "id": "QTfzzL2cvWHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reflection = \"\"\n",
        "for chunk in reflect.stream({\"messages\": [request, HumanMessage(content=lyric)]}):\n",
        "    print(chunk.content, end=\"\")\n",
        "    reflection += chunk.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN47sEFjw4Kg",
        "outputId": "0c726776-9d69-4edd-ea78-e976c8ad2c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "좋은 점\n",
            "- 코딩 용어를 골고루 배치해 주제에 집중하고, 기술적 현장을 감각적으로 그려냅니다.\n",
            "- 1인 화자의 관점으로 일관되게 이야기를 전개해 몰입감을 주고 있습니다.\n",
            "- 에너지의 상승과 하강 구도가 느껴지며, 마지막에 “오늘도 실행을 눌러 내일의 이야기를 시작한다”로 마무리하는 의지가 강합니다.\n",
            "\n",
            "개선 포인트(길이, 깊이, 문체 측면)\n",
            "- 길이/구성\n",
            "  - 현재 구절은 기술 이미지 중심으로 길게 이어집니다. 노래처럼 들리려면 후렴(코러스)을 한두 번 반복해 청중이 훅을 기억하도록 구성하는 것이 좋습니다.\n",
            "  - 제안: Verse 1 → 코러스(반복 가능한 훅) → Verse 2 → Bridge → Chorus → Outro 식의 구조를 고려해 보세요.\n",
            "- 깊이/감정\n",
            "  - 기술 은유가 장황하게 이어지지만, 개인적 갈등이나 성취의 구체적 사례가 부족합니다. 버그를 잡는 긴장, 마감 직전의 압박, 성공의 희열 같은 순간감을 추가하면 곡의 깊이가 살아납니다.\n",
            "  - 제안: 짧은 에피소드(예: 특정 버그를 찾고 고쳐내는 과정에서 느낀 좌절과 깨달음)를 삽입해 감정의 파고를 만드세요.\n",
            "- 문체/이미지\n",
            "  - 기술 용어의 사용은 좋지만, 상투적 비유가 섞여 있습니다. 더 신선한 이미지를 활용해 보세요. 예: 코드가 도시가 되고, 디버거가 가로수길의 등대가 되는 식의 새로운 은유.\n",
            "  - 중복되는 표현(예: “한 줄의 코드에서 시작된다”)의 재사용은 피하고, 어휘의 다양성으로 리듬과 이미지를 더 풍부하게 만드세요.\n",
            "- 리듬/운율\n",
            "  - 줄 길이가 비슷하게 길게 이어지는 구간이 많아 리듬이 다소 단조로울 수 있습니다. 각각의 연에서 길이를 조금씩 다르게 하고, 중간에 은유의 전환점을 넣은 뒤 후렴으로 리듬을 되살리는 구성을 추천합니다.\n",
            "- 후렴(후렴구) 강조\n",
            "  - 명확한 훅이 없고, 각 연의 마지막 줄에서 매번 같은 분위기로 끝나는 경향이 있습니다. 반복 가능한 후렴구를 만들어 곡의 체류감을 높이세요.\n",
            "\n",
            "구체적 개선 요청(실전용)\n",
            "- 구조 개선:\n",
            "  - 한두 구절 정도를 “코드로 말하는 훅”으로 고정하고, 다른 구절은 스토리 전개에 집중.\n",
            "- 이미지 강화:\n",
            "  - 은유를 재발견: 예를 들어 디버거를 “도시의 등대”로, 컴파일을 “숨 고르기”로 재구성해 신선도 확보.\n",
            "- 구문 다양화:\n",
            "  - 길고 복합한 문장을 피하고, 짧은 문장과 긴 문장을 번갈아 배치해 리듬감을 만들기.\n",
            "- 개인적 이야기 추가:\n",
            "  - 버그를 찾고 고치며 느낀 감정의 변화(좌절-집중-희열-다시 도전)를 구체적으로 묘사.\n",
            "\n",
            "실용적 개선 예시(부분 수정 샘플)\n",
            "- Verse 1 대체 제안\n",
            "  - 원문\n",
            "    검은 화면 위로 번쩍이는 숫자의 노래가 흐른다\n",
            "    커서가 깜빡일 때마다 세상은 다시 깨어난다\n",
            "    커피 향과 전기의 냄새 속에서 나는 코드를 노래한다\n",
            "    루프의 박자에 마음이 따라 흘러간다\n",
            "    새로운 시작은 늘 한 줄의 코드에서 시작된다\n",
            "  - 다듬은 버전\n",
            "    검은 화면 위 숫자들이 내 심장을 두드려,\n",
            "    커서가 깜빡일 때 세상은 또렷이 깨어난다.\n",
            "    커피 향과 전기의 냄새가 섞인 방에서\n",
            "    루프의 박자에 발걸음이 맞춰진다.\n",
            "    새 시작은 언제나, 한 줄의 코드에서 피어난다.\n",
            "\n",
            "- 후렴 후보(2-3개)\n",
            "  1) 코드로 말하자, 버그도 친구로 삼아\n",
            "     컴파일의 숨 고르기, 배포의 기적을 함께 노래하자\n",
            "     오늘의 작은 승리가 내일의 길을 만든다\n",
            "  2) 우리는 키를 누르는 손끝으로 길을 연다\n",
            "     브랜치가 갈림길을 비출 때도, 함께여서 괜찮다\n",
            "     실행 버튼 아래에 꿈을 적는다\n",
            "  3) 코드가 말하는 나의 이야기, 끝나지 않는 여정\n",
            "     커밋은 기억의 조각, 푸시는 세계를 지나간다\n",
            "     이 노래가 다시 시작될 때, 나는 달린다\n",
            "\n",
            "- Verse 2, Bridge 샘플 아이디어\n",
            "  - Verse 2는 함수와 인자, 반환값으로 감정의 흐름을 확장하고, Bridge에서는 배포와 팀 협업의 갈등/해소를 강하게 묘사해 분위기 전환을 만드세요.\n",
            "  - 예시 한 줄\n",
            "    반환값은 어제의 약속, 오늘의 선택이 된다는 확신으로.\n",
            "\n",
            "마무리 코멘트\n",
            "- 현재의 가사는 프로그래밍 세계에 대한 열정과 현장을 잘 담고 있습니다. 다만 노래로서의 기억성, 어조의 다양성, 그리고 감정의 구체적 흐름을 강화하면 훨씬 더 강렬한 곡이 될 거예요.\n",
            "- 위의 개선 방향을 참고해 코러스 중심의 훅, 개인적 에피소드의 삽입, 은유의 신선화, 리듬의 변화 등을 적용해 보세요. 필요하면 제가 구체적인 3-4분짜리 구조의 완성 버전도 함께 만들어 드리겠습니다."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in generate.stream(\n",
        "    {\"messages\": [request, AIMessage(content=lyric), HumanMessage(content=reflection)]}\n",
        "):\n",
        "    print(chunk.content, end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OWOI03Qw5TL",
        "outputId": "ad094403-2727-4a5b-c13f-81265da36a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verse 1\n",
            "검은 화면에 숫자들이 내 심장을 두드려\n",
            "커서가 깜빡일 때 세상은 또렷이 깨어난다\n",
            "커피의 쓴맛과 냉기의 냄새가 방 안을 채우고\n",
            "루프의 박자에 발걸음이 따라간다\n",
            "새로운 시작은 언제나 코드의 한 줄에서 피어난다\n",
            "\n",
            "Chorus A\n",
            "코드로 말하자, 버그도 친구로 삼아\n",
            "컴파일의 숨 고르기로 마음을 다독이고\n",
            "배포의 빛이 도시에 내려앉을 때\n",
            "오늘의 작은 승리가 내일의 길을 만든다\n",
            "\n",
            "Verse 2\n",
            "버그를 좇아 로그를 해부하니\n",
            "레이턴시의 미로에서 변수들이 속삭인다\n",
            "마감 직전의 압박이 뼈를 묶듯 몰려와도\n",
            "나는 한 줄의 수정으로 숨을 고르고 다시 달린다\n",
            "스크롤의 끝에서, 어제보다 선명한 답이 떠오른다\n",
            "\n",
            "Bridge\n",
            "배포 파이프라인은 거친 바다처럼 흔들리고\n",
            "팀은 서로 다른 등대의 빛을 들고 걷는다\n",
            "충돌은 음악으로 섞이고, 대화는 다리를 놓는다\n",
            "그때 나는 분열이 합쳐지는 순간을 본다\n",
            "\n",
            "Chorus B\n",
            "코드로 말하자, 우리의 길은 함께 걷는 것\n",
            "버전은 다르고 배포는 하나의 약속\n",
            "나는 손끝에 남은 불빛으로 미래를 쓴다\n",
            "오늘의 작은 승리가 내일의 길을 만든다\n",
            "\n",
            "Outro\n",
            "새로운 버전의 도시를 바라보며\n",
            "실패를 배움으로 삼아 다시 손가락에 힘을 준다\n",
            "조용한 호흡으로 코드의 길을 닦고\n",
            "오늘도 실행을 눌러 내일의 이야기를 시작한다"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Graph로 Reflection 구현\n",
        "\n",
        "<img src=\"https://blog.kakaocdn.net/dna/o5rH8/btsQzMQpYWM/AAAAAAAAAAAAAAAAAAAAAAzuMjcIZ2pmzApKdNkpQiqy4UuGJg-XonjDqFlbDmsq/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=0ss%2FS0wLtjfuwGZdpwdEgD0doWo%3D\">\n"
      ],
      "metadata": {
        "id": "BRzTt5KYw6fV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qOLVN_QBw-4P",
        "outputId": "99c2ecd0-3436-4eed-d0b9-a39220854d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.76)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.6-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.24)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.24.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.6-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.6 ormsgpack-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]"
      ],
      "metadata": {
        "id": "PfvqZgxpzgjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generation_node(state: State) -> State:\n",
        "    return {\"messages\": [generate.invoke(state[\"messages\"])]}"
      ],
      "metadata": {
        "id": "_dKL6BbDzjHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reflection_node(state: State) -> State:\n",
        "    cls_map = {\"ai\": AIMessage, \"human\": HumanMessage}\n",
        "\n",
        "    # 첫번째 사용자 요청 + 생성메시지 (reflection_node's input)\n",
        "    # 첫번째 사용자 요청 + 생성메시지 + 피드백메시지 (generation_node's input)\n",
        "    # 첫번째 사용자 요청 + 생성메시지 + 피드백메시지 + 수정된 생성메시지 (reflection_node's input)\n",
        "    # 첫번째 사용자 요청 + 생성메시지 + 피드백메시지 + 수정된 생성메시지 + 피드백메시지 (generation_node's input)\n",
        "    # ...\n",
        "    translated = [state[\"messages\"][0]] + [\n",
        "        cls_map[msg.type](content=msg.content) for msg in state[\"messages\"][1:]\n",
        "    ]\n",
        "    # translated = [state[\"messages\"][0]] + [\n",
        "    #     cls_map[msg.type](content=msg.content) for msg in state[\"messages\"][-2:]\n",
        "    # ]\n",
        "    res = reflect.invoke(translated)\n",
        "\n",
        "    return {\"messages\": [HumanMessage(content=res.content)]}"
      ],
      "metadata": {
        "id": "Y7W8EPkezke9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"generate\", generation_node)\n",
        "graph_builder.add_node(\"reflect\", reflection_node)\n",
        "graph_builder.add_edge(START, \"generate\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIe6tOuhzl-f",
        "outputId": "6fcc0e5f-8b9d-4bea-fdd7-0c84d2b0aceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7b5640a4c9b0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "from langgraph.graph import END\n",
        "\n",
        "def should_continue(state: State) -> Literal[\"reflect\",\"END\"]:\n",
        "    if len(state[\"messages\"]) > 6:\n",
        "        return END\n",
        "    return \"reflect\"\n",
        "\n",
        "\n",
        "graph_builder.add_conditional_edges(\"generate\", should_continue)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoTNcYbrzoCr",
        "outputId": "f203a8ac-c99c-4dc7-b1ca-249159fdcd4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7b5640a4c9b0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(\"reflect\", \"generate\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdHT-5vBzqUF",
        "outputId": "9ac56db2-d22a-499c-dc76-4795d1cfdaae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7b5640a4c9b0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "xXatUaRDzsER",
        "outputId": "8d9aa585-1e96-4182-ac3a-e226cdd7f950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x7b5640a4c590>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"1\"}}"
      ],
      "metadata": {
        "id": "fA3rKlcJzxK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for event in graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(\n",
        "                content=\"코딩에 대한 가사를 작성해주세요.\"\n",
        "            )\n",
        "        ],\n",
        "    },\n",
        "    config,\n",
        "):\n",
        "    print(event)\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HosbXninz3Iy",
        "outputId": "61ccb812-21d6-4ab3-cdd2-fca8969ed626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'generate': {'messages': [AIMessage(content='새벽 창가에 물방울 자국이 맺히고, 커서가 깜빡인다\\n화면은 은빛 달처럼 차분히 숨을 고르고\\n한 줄의 코드가 이 방의 공기를 바꾼다\\n타이핑 소리 밑에 커피의 쓴맛이 진동한다\\n\\n콘솔 로그가 빗물처럼 쏟아지고, 예외의 파도가 올라온다\\n널 포인터의 그림자가 손끝에서 스르르 떠난다\\n무한 루프의 기계적 숨, 나는 여전히 돌아가며 배우는 중\\n작은 버그 하나가 어제의 확신을 흔들어 놓는다\\n\\n디버거를 켜고 스택 트래스를 따라간다\\n함수의 골목에서 과거의 버그를 다시 바라본다\\n주석은 길잡이, 비어 있는 변수 이름은 내일의 꿈\\n리팩토링은 숨 고르기, 흐름은 점점 맑아진다\\n\\n마침표 대신 세미콜론이 일을 끝내고 화면이 떨림 없이 빛난다\\n컴파일의 축제가 시작되고 서버의 심장이 뛰기 시작한다\\n커밋 메시지는 오늘의 고백, 브랜치는 미래의 길\\n배포가 끝나자 방 안의 정적도 조용히 물러선다\\n\\n코드가 내 하루의 일부가 되고, 반복은 습관이 된다\\n에러는 배움의 씨앗, 성공은 또 다른 질문의 시작\\n다음 버전의 꿈을 밀어 올리고, 새로운 함수에 답을 찾아간다\\n나는 계속해서, 코드 위의 길을 걸어간다', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3836, 'prompt_tokens': 1478, 'total_tokens': 5314, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 3456, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CFrYAZ4nSDWUKsmEgffqWzO5x7x3P', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--0a09fe9b-cda5-48d7-9c29-81b0d71f52ea-0', usage_metadata={'input_tokens': 1478, 'output_tokens': 3836, 'total_tokens': 5314, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 3456}})]}}\n",
            "---\n",
            "{'reflect': {'messages': [HumanMessage(content='좋은 출발점입니다. 코딩이라는 구체적 세계를 음악적 이미지로 풀어낸 점이 매력적이고, 기술 용어를 은유로 녹여낸 의도도 돋보입니다. 아래는 비평과 구체적인 개선 제안입니다.\\n\\n전반적 평가\\n- 분위기와 주제의 일관성: 코딩 삶의 리듬과 문제 해결의 여정을 차분하게 따라갑니다. 시작부터 마무리까지 기술적 은유가 자연스럽게 흐르는 편입니다.\\n- 강점 포인트: 콘솔 로그, 예외, 무한 루프, 디버거, 주석, 리팩토링, 세미콜론, 배포 같은 구체 용어들이 실감나게 배치되어 있습니다. 이야기의 흐름도 “문제 인식 → 학습/개선 → 재배치” 같은 구조로 읽히며, 음악으로 옮겨도 충분히 떠올릴 수 있는 리듬감을 줍니다.\\n- 개선 필요점: \\n  - 진부한 표현과 반복이 다소 많고, 리듬이 고르게 느껴져 구간마다 함께 듣기보단 읽기 중심의 가사처럼 느껴질 수 있습니다.\\n  - 구체성과 이미지의 다양성이 더 필요합니다. 추상적 비유보다 현실 속 구체 물체나 상황을 더 많이 활용하면 상상력을 자극합니다.\\n  - 코러스나 반복 모티프가 없어 기억에 남는 훅이 약합니다. 노래로서의 재생성 힘을 키우려면 후렴 구성을 고려해보는 게 좋습니다.\\n  - 이야기의 전개에서 뚜렷한 전환점(클라이맥스)이 약합니다. 작은 사건이나 반전으로 방향 전환을 명확히 하면 몰입도가 올라갑니다.\\n\\n구체적 개선 제안\\n- 구체성 강화 아이디어\\n  - 업무 공간의 디테일을 넣기: 책상 위의 커피 잔 자국, 모니터에 남은 코드 스니펫, 벽에 붙은 노트나 포스트잇의 흔적 같은 실물 이미지.\\n  - 프로젝트 디테일 활용: Git 커밋 해시의 일부, CI 로그의 색상 변화, 버그 리포트 번호, 특정 라이브러리 버전 등 실제 개발 공간의 흔적을 활용.\\n  - 일상사 디테일: 버스 번호, 카페 냅킨 색, 우편함에 남은 메일 주소 등 작은 일상 요소로 무드를 다듬기.\\n- 리듬과 문체 다변화\\n  - 긴 행과 짧은 행을 교차 배치해 리듬의 맥박을 만들기. 예를 들어 중요한 메시지를 짧은 행으로 강하게 찍고, 그 뒤에 긴 은유 구절로 숨을 고르는 식.\\n  - 은유의 변주: 같은 기술 은유라도 방향을 조금씩 바꿔 반복의 지루함을 피하기. 예: 디버거를 “심장박동의 망사”처럼 비유했다가, 다음에는 “디버깅은 바람처럼 지나간 버그를 좇는 추적”처럼 다른 이미지로.\\n- 이야기의 전개 구조 제안\\n  - 도입부: 현재의 공허와 코드의 의의가 겹쳐 보이는 순간으로 시작.\\n  - 중반부: 구체적 기억과 사건(버그 발견, 재배치 시도, 커밋과 리팩토링)을 통해 방향 전환의 촉발점 제시.\\n  - 후반부: 교차되는 수용과 앞으로의 다짐으로 마무리. 코러스에서 후렴적 메시지나 훅을 하나 삽입해 기억에 남는 엔딩을 만듦.\\n- 코러스/후렴 아이디어\\n  - 한두 구절의 반복 훅을 만들고, 매번 어감이나 이미지를 살짝 바꿔 반복성을 유지하되 지루함을 줄이기.\\n  - 예: “코드가 내 하루를 다시 구성한다” 같은 짧은 후렴을 반복하되, 매번 다른 뉘앙스로 끝맺기.\\n- 어감 다듬기\\n  - “에러는 배움의 씨앗” 같은 표현은 쓰임새를 의도적으로 다듬거나 다른 비유로 바꿔 신선함 유지.\\n  - 직설적 표현과 은유의 비율을 조절해 더 시적이거나 더 직관적인 톤 중 하나를 선택.\\n\\n실제 적용 예시 샘플\\n- 구체성 강화 예시(짧은 대체 구간)\\n  원문: “콘솔 로그가 빗물처럼 쏟아지고, 예외의 파도가 올라온다”\\n  다듬은 예시: “콘솔 로그가 창문 틈새로 쏟아져 빗방울처럼 흘러내리고, 예외의 파도가 모니터 위를 스쳐 간다”\\n\\n- 리듬 다변화 예시(짧은 후렴 구절 아이디어)\\n  후렴 아이디어 1: “코드가 하루를 다시 쌓아 올린다, 잠깐의 멈춤 없이”\\n  후렴 아이디어 2: “버그 하나가 길을 바꿔도, 나는 다시 컴파일한다”\\n\\n실제 적용을 원하시면\\n- 원하시는 분위기 톤(더 어둡게, 더 희망적으로, 더 활기차게 등), 길이(버스 길이 같은 짧은 버전 vs 장편), 코러스 여부를 알려주시면 그에 맞춘 완성 편(완전 수정안)을 작성해 드리겠습니다. 원하시는 특정 도구나 기술 용어의 비율도 맞춰 드릴게요.', additional_kwargs={}, response_metadata={}, id='0eb91f2c-b729-4694-9fbd-f03e37a2cd5c')]}}\n",
            "---\n",
            "{'generate': {'messages': [AIMessage(content='다음은 피드백을 반영한 구체성 강화와 코러스 구성을 적용한 수정안 5단락 가사입니다.\\n\\n새벽 창가의 빛이 차갑게 번지고\\n책상 위 커피 잔의 자국은 아직 식지 않은 어제의 온기\\n모니터 커서가 깜빡이며 나를 호출한다\\n코드 조각들이 벽에 걸린 메모처럼 길을 그려낸다\\n후렴: 다시 컴파일한다, 루프를 고친 마음의 고동\\n후렴: 오늘의 버그를 지나, 나는 다시 일어선다\\n\\n예외가 창밖 파도처럼 밀려들고\\n버스 203의 숫자처럼 매일 같은 길 위에서 흔들린다\\n포스트잇의 글자 자국이 벽에 남아 내 남은 시간을 가리킨다\\n모니터의 푸른 빛이 내 어깨를 가볍게 눌러준다\\n후렴: 다시 컴파일한다, 루프를 바르게 고친다\\n후렴: 한 줄의 용기, 다음 줄의 길을 찾는다\\n\\n디버거를 켜고 스택 트레이스를 따라간다\\n주석은 길잡이, 변수 이름은 내일의 꿈이다\\n리팩토링은 느리게 숨을 고르는 행위\\n커밋 해시의 순간이 지나쳐도 마음은 변하지 않는다\\n후렴: 다시 컴파일한다, 루프를 바르게 고친다\\n후렴: 흐름은 맑아지고, 의심은 물러선다\\n\\n세미콜론이 끝맺음을 찍고 화면은 흔들림 없이 빛난다\\nCI의 초록 불빛이 켜지면 살아 있음을 느낀다\\n배포의 순간, 방의 정적이 도리어 가까워진다\\n아이콘의 작은 진동이 내 귀를 스친다\\n후렴: 다시 컴파일한다, 루프를 바르게 고친다\\n후렴: 코드와 하루가 하나가 된다\\n\\n결국 코드는 나의 하루를 닮아간다\\n에러는 배우는 씨앗, 성공은 또 다른 질문의 시작\\n다음 버전의 꿈을 밀어 올리며 더 넓은 길을 찾는다\\n새로운 함수에 답을 달고, 나는 다시 걷는다\\n후렴: 다시 컴파일한다, 오늘의 노래를 완성한다\\n후렴: 내일도 또 다른 버그를 벗겨 내며, 나는 계속한다\\n\\n원하시는 분위기(더 어둡게, 더 희망적으로 등), 길이, 코러스의 개수나 위치를 알려주시면 또다시 다듬어 드리겠습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5728, 'prompt_tokens': 3140, 'total_tokens': 8868, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 5120, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CFrYoK7hHMr4EjlI5MhE5ko94cyIK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--baa23eee-0015-4c04-8293-3f0d472b6652-0', usage_metadata={'input_tokens': 3140, 'output_tokens': 5728, 'total_tokens': 8868, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 5120}})]}}\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state = graph.get_state(config)"
      ],
      "metadata": {
        "id": "HS3FgpFdz5Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ChatPromptTemplate.from_messages(state.values[\"messages\"]).pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKWkxWo0z6X-",
        "outputId": "e7cbca19-7cfb-4a31-931d-1d8d8e27136a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "이별에 대한 가사를 작성해주세요.\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "문을 열면 네 냄새가 남아 있어\n",
            "함께 남긴 약속의 글자들은 벽에 흐려져 가네\n",
            "창밖 빗소리는 네 이름을 속삭이며 흘려가고\n",
            "여전히 네 기억을 쫓아 걷는 내 발걸음\n",
            "\n",
            "네가 떠난 자리엔 차가운 바람이 스며들고\n",
            "사진 속 널 떠올리면 미소는 오래도록 선명해\n",
            "메시지는 시들고 화면은 어둠에 잠겨 있어\n",
            "오늘의 나는 네가 남긴 빈 자리에서 숨 쉬고 있어\n",
            "\n",
            "나는 남은 단어를 모아 작은 불을 지핀다\n",
            "기억은 종이에 긁힌 흔들림, 아직 타지 않은 선들\n",
            "네 이름을 불러보려 숨을 깊이 들이마셔 보았지만\n",
            "대답은 바람에 흩날려 돌아오지 않네\n",
            "\n",
            "그럼에도 나는 어둠을 가르고 길을 걷는다\n",
            "새벽의 첫 빛이 상처를 닦아 주고\n",
            "지나간 노래의 리듬이 아직 귀에 남아\n",
            "천천히, 그러나 멈추지 않는 걸음을 택해\n",
            "\n",
            "이별은 끝이 아니라 시작의 한 조각일 뿐\n",
            "너 없는 날들에 나는 다시 나를 찾아 걷는다\n",
            "언젠가 네가 남긴 빈자리에 햇살이 스며들기를\n",
            "안녕, 고마웠어. 이 편린으로 나는 살아가리\n",
            "\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "전반적 평가\n",
            "- 분위기와 주제의 일관성은 좋습니다. 이별의 고통에서 벗어나려는 의지까지 점진적으로 그려져 있어 독자에게 공감과 위로를 줍니다.\n",
            "- 강점으로는 감각적 이미지(냄새, 빗소리, 벽에 흐려지는 약속 글자), 의식의 흐름을 따라가는 서사구조, 그리고 마지막의 수용적 결말이 잘 연결됩니다.\n",
            "- 다만 몇 군데는 진부한 표현이 보이고, 리듬과 구성이 다소 평평하게 느껴질 수 있습니다. 구체성과 리듬감을 강화하면 더 강렬하고 기억에 남는 가사가 될 가능성이 큽니다.\n",
            "\n",
            "개선이 필요한 점\n",
            "- 구체성 부족: 크고 보편적인 비유보다는 함께하던 구체적 기억이나 사물의 흔적을 활용하면 독자의 상상력을 더 자극합니다.\n",
            "- 문체의 다양성 부족: 긴 문장과 짧은 문장을 섞어 리듬을 만들고, 같은 어감을 반복하지 않도록 약간의 어휘 변화를 주면 흐름이 살아납니다.\n",
            "- 진부한 표현 가능성: “끝이 아니라 시작의 조각” 같은 표현은 의도적으로 다듬거나 다른 신선한 비유로 바꾸면 효과가 큽니다.\n",
            "- 이야기의 진행점(클라이맥스/전환점) 명확성: 현재는 서정성이 강하지만, 중간에 한두 개의 구체적 사건이나 감정의 방향 전환을 추가해 여정의 모양새를 뚜렷하게 다듬으면 좋습니다.\n",
            "- 구조적 구성: 코러스나 반복되는 모티프를 하나 추가하면 노래의 기억도를 높일 수 있습니다.\n",
            "\n",
            "구체적인 개선 제안\n",
            "- 구체성 강화 아이디어\n",
            "  - 함께 남긴 공간의 디테일을 넣기: 예를 들어 “창가의 물방울 자국”, “책상 위의 반쯤 멈춘 커피 잔”, “메모지에 남은 작은 약속의 글자 자국” 같은 구체물 사용.\n",
            "  - 함께던 계절이나 일상사(예: 버스 번호, 자주 가던 카페의 냅킨 색깔, 우편함에 남은 주소의 흔적)로 입체감 강화.\n",
            "- 리듬과 문체 다변화\n",
            "  - 짧은 한두 개의 행으로 강한 충격을 주고, 그 뒤를 긴 은유적 행으로 이어가는 식으로 운율을 조정.\n",
            "  - 은유를 반복적으로 쓰되 말의 강도나 이미지의 방향을 조금씩 바꿔 같은 모티프라도 새로움이 느껴지게 만들기.\n",
            "- 이야기의 전개\n",
            "  - 도입부에서 현재의 공허를 먼저 보여주고, 중반에 과거의 구체적 기억으로 파고들었다가, 후반에 재생과 수용으로 마무리하는 구조를 명확히 구분.\n",
            "  - 마지막 구절에 다시 한 줄의 강한 후크를 배치해 여운을 남기기.\n",
            "- 어감 다듬기\n",
            "  - “네 이름을 불러보려” 같은 직설적 구절은 좀 더 은유적으로 바꾸면 더 멋진 효과를 냅니다.\n",
            "  - 반복되는 표현은 한두 단어를 바꿔 변주해 사용하면 지루함을 줄일 수 있습니다.\n",
            "\n",
            "실제 적용 예시(짧은 대체 구간 샘플)\n",
            "- 원문 일부를 다듬은 예시:\n",
            "  - 원문: “나는 남은 단어를 모아 작은 불을 지핀다 / 기억은 종이에 긁힌 흔들림, 아직 타지 않은 선들”\n",
            "  - 다듬은 예시: “남은 말들을 모아 창가의 불꽃 하나를 지피고 / 종이 위 남은 선들은 아직도 천천히 타오를 준비한다”\n",
            "- 원문: “네 이름을 불러보려 숨을 깊이 들이마셔 보았지만 / 대답은 바람에 흩날려 돌아오지 않네”\n",
            "  - 다듬은 예시: “네 이름을 속삭여 보려 숨을 들이켜도 / 대답은 먼지 속에 흩어져 벽을 스친다”\n",
            "\n",
            "원한다면 제가 위 제안을 바탕으로 한 편의 수정안(완전한 버전)을 만들어 드리겠습니다. 원하는 분위기 톤(더 어두운 쪽, 더 희망적, 강한 비유 등), 길이, 그리고 코러스 여부를 알려주시면 맞춤형으로 다듬어 드릴게요.\n",
            "\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "코딩에 대한 가사를 작성해주세요.\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "새벽 창가에 물방울 자국이 맺히고, 커서가 깜빡인다\n",
            "화면은 은빛 달처럼 차분히 숨을 고르고\n",
            "한 줄의 코드가 이 방의 공기를 바꾼다\n",
            "타이핑 소리 밑에 커피의 쓴맛이 진동한다\n",
            "\n",
            "콘솔 로그가 빗물처럼 쏟아지고, 예외의 파도가 올라온다\n",
            "널 포인터의 그림자가 손끝에서 스르르 떠난다\n",
            "무한 루프의 기계적 숨, 나는 여전히 돌아가며 배우는 중\n",
            "작은 버그 하나가 어제의 확신을 흔들어 놓는다\n",
            "\n",
            "디버거를 켜고 스택 트래스를 따라간다\n",
            "함수의 골목에서 과거의 버그를 다시 바라본다\n",
            "주석은 길잡이, 비어 있는 변수 이름은 내일의 꿈\n",
            "리팩토링은 숨 고르기, 흐름은 점점 맑아진다\n",
            "\n",
            "마침표 대신 세미콜론이 일을 끝내고 화면이 떨림 없이 빛난다\n",
            "컴파일의 축제가 시작되고 서버의 심장이 뛰기 시작한다\n",
            "커밋 메시지는 오늘의 고백, 브랜치는 미래의 길\n",
            "배포가 끝나자 방 안의 정적도 조용히 물러선다\n",
            "\n",
            "코드가 내 하루의 일부가 되고, 반복은 습관이 된다\n",
            "에러는 배움의 씨앗, 성공은 또 다른 질문의 시작\n",
            "다음 버전의 꿈을 밀어 올리고, 새로운 함수에 답을 찾아간다\n",
            "나는 계속해서, 코드 위의 길을 걸어간다\n",
            "\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "좋은 출발점입니다. 코딩이라는 구체적 세계를 음악적 이미지로 풀어낸 점이 매력적이고, 기술 용어를 은유로 녹여낸 의도도 돋보입니다. 아래는 비평과 구체적인 개선 제안입니다.\n",
            "\n",
            "전반적 평가\n",
            "- 분위기와 주제의 일관성: 코딩 삶의 리듬과 문제 해결의 여정을 차분하게 따라갑니다. 시작부터 마무리까지 기술적 은유가 자연스럽게 흐르는 편입니다.\n",
            "- 강점 포인트: 콘솔 로그, 예외, 무한 루프, 디버거, 주석, 리팩토링, 세미콜론, 배포 같은 구체 용어들이 실감나게 배치되어 있습니다. 이야기의 흐름도 “문제 인식 → 학습/개선 → 재배치” 같은 구조로 읽히며, 음악으로 옮겨도 충분히 떠올릴 수 있는 리듬감을 줍니다.\n",
            "- 개선 필요점: \n",
            "  - 진부한 표현과 반복이 다소 많고, 리듬이 고르게 느껴져 구간마다 함께 듣기보단 읽기 중심의 가사처럼 느껴질 수 있습니다.\n",
            "  - 구체성과 이미지의 다양성이 더 필요합니다. 추상적 비유보다 현실 속 구체 물체나 상황을 더 많이 활용하면 상상력을 자극합니다.\n",
            "  - 코러스나 반복 모티프가 없어 기억에 남는 훅이 약합니다. 노래로서의 재생성 힘을 키우려면 후렴 구성을 고려해보는 게 좋습니다.\n",
            "  - 이야기의 전개에서 뚜렷한 전환점(클라이맥스)이 약합니다. 작은 사건이나 반전으로 방향 전환을 명확히 하면 몰입도가 올라갑니다.\n",
            "\n",
            "구체적 개선 제안\n",
            "- 구체성 강화 아이디어\n",
            "  - 업무 공간의 디테일을 넣기: 책상 위의 커피 잔 자국, 모니터에 남은 코드 스니펫, 벽에 붙은 노트나 포스트잇의 흔적 같은 실물 이미지.\n",
            "  - 프로젝트 디테일 활용: Git 커밋 해시의 일부, CI 로그의 색상 변화, 버그 리포트 번호, 특정 라이브러리 버전 등 실제 개발 공간의 흔적을 활용.\n",
            "  - 일상사 디테일: 버스 번호, 카페 냅킨 색, 우편함에 남은 메일 주소 등 작은 일상 요소로 무드를 다듬기.\n",
            "- 리듬과 문체 다변화\n",
            "  - 긴 행과 짧은 행을 교차 배치해 리듬의 맥박을 만들기. 예를 들어 중요한 메시지를 짧은 행으로 강하게 찍고, 그 뒤에 긴 은유 구절로 숨을 고르는 식.\n",
            "  - 은유의 변주: 같은 기술 은유라도 방향을 조금씩 바꿔 반복의 지루함을 피하기. 예: 디버거를 “심장박동의 망사”처럼 비유했다가, 다음에는 “디버깅은 바람처럼 지나간 버그를 좇는 추적”처럼 다른 이미지로.\n",
            "- 이야기의 전개 구조 제안\n",
            "  - 도입부: 현재의 공허와 코드의 의의가 겹쳐 보이는 순간으로 시작.\n",
            "  - 중반부: 구체적 기억과 사건(버그 발견, 재배치 시도, 커밋과 리팩토링)을 통해 방향 전환의 촉발점 제시.\n",
            "  - 후반부: 교차되는 수용과 앞으로의 다짐으로 마무리. 코러스에서 후렴적 메시지나 훅을 하나 삽입해 기억에 남는 엔딩을 만듦.\n",
            "- 코러스/후렴 아이디어\n",
            "  - 한두 구절의 반복 훅을 만들고, 매번 어감이나 이미지를 살짝 바꿔 반복성을 유지하되 지루함을 줄이기.\n",
            "  - 예: “코드가 내 하루를 다시 구성한다” 같은 짧은 후렴을 반복하되, 매번 다른 뉘앙스로 끝맺기.\n",
            "- 어감 다듬기\n",
            "  - “에러는 배움의 씨앗” 같은 표현은 쓰임새를 의도적으로 다듬거나 다른 비유로 바꿔 신선함 유지.\n",
            "  - 직설적 표현과 은유의 비율을 조절해 더 시적이거나 더 직관적인 톤 중 하나를 선택.\n",
            "\n",
            "실제 적용 예시 샘플\n",
            "- 구체성 강화 예시(짧은 대체 구간)\n",
            "  원문: “콘솔 로그가 빗물처럼 쏟아지고, 예외의 파도가 올라온다”\n",
            "  다듬은 예시: “콘솔 로그가 창문 틈새로 쏟아져 빗방울처럼 흘러내리고, 예외의 파도가 모니터 위를 스쳐 간다”\n",
            "\n",
            "- 리듬 다변화 예시(짧은 후렴 구절 아이디어)\n",
            "  후렴 아이디어 1: “코드가 하루를 다시 쌓아 올린다, 잠깐의 멈춤 없이”\n",
            "  후렴 아이디어 2: “버그 하나가 길을 바꿔도, 나는 다시 컴파일한다”\n",
            "\n",
            "실제 적용을 원하시면\n",
            "- 원하시는 분위기 톤(더 어둡게, 더 희망적으로, 더 활기차게 등), 길이(버스 길이 같은 짧은 버전 vs 장편), 코러스 여부를 알려주시면 그에 맞춘 완성 편(완전 수정안)을 작성해 드리겠습니다. 원하시는 특정 도구나 기술 용어의 비율도 맞춰 드릴게요.\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "다음은 피드백을 반영한 구체성 강화와 코러스 구성을 적용한 수정안 5단락 가사입니다.\n",
            "\n",
            "새벽 창가의 빛이 차갑게 번지고\n",
            "책상 위 커피 잔의 자국은 아직 식지 않은 어제의 온기\n",
            "모니터 커서가 깜빡이며 나를 호출한다\n",
            "코드 조각들이 벽에 걸린 메모처럼 길을 그려낸다\n",
            "후렴: 다시 컴파일한다, 루프를 고친 마음의 고동\n",
            "후렴: 오늘의 버그를 지나, 나는 다시 일어선다\n",
            "\n",
            "예외가 창밖 파도처럼 밀려들고\n",
            "버스 203의 숫자처럼 매일 같은 길 위에서 흔들린다\n",
            "포스트잇의 글자 자국이 벽에 남아 내 남은 시간을 가리킨다\n",
            "모니터의 푸른 빛이 내 어깨를 가볍게 눌러준다\n",
            "후렴: 다시 컴파일한다, 루프를 바르게 고친다\n",
            "후렴: 한 줄의 용기, 다음 줄의 길을 찾는다\n",
            "\n",
            "디버거를 켜고 스택 트레이스를 따라간다\n",
            "주석은 길잡이, 변수 이름은 내일의 꿈이다\n",
            "리팩토링은 느리게 숨을 고르는 행위\n",
            "커밋 해시의 순간이 지나쳐도 마음은 변하지 않는다\n",
            "후렴: 다시 컴파일한다, 루프를 바르게 고친다\n",
            "후렴: 흐름은 맑아지고, 의심은 물러선다\n",
            "\n",
            "세미콜론이 끝맺음을 찍고 화면은 흔들림 없이 빛난다\n",
            "CI의 초록 불빛이 켜지면 살아 있음을 느낀다\n",
            "배포의 순간, 방의 정적이 도리어 가까워진다\n",
            "아이콘의 작은 진동이 내 귀를 스친다\n",
            "후렴: 다시 컴파일한다, 루프를 바르게 고친다\n",
            "후렴: 코드와 하루가 하나가 된다\n",
            "\n",
            "결국 코드는 나의 하루를 닮아간다\n",
            "에러는 배우는 씨앗, 성공은 또 다른 질문의 시작\n",
            "다음 버전의 꿈을 밀어 올리며 더 넓은 길을 찾는다\n",
            "새로운 함수에 답을 달고, 나는 다시 걷는다\n",
            "후렴: 다시 컴파일한다, 오늘의 노래를 완성한다\n",
            "후렴: 내일도 또 다른 버그를 벗겨 내며, 나는 계속한다\n",
            "\n",
            "원하시는 분위기(더 어둡게, 더 희망적으로 등), 길이, 코러스의 개수나 위치를 알려주시면 또다시 다듬어 드리겠습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Reflextion 구현\n",
        "[“Reflexion: Language Agents with Verbal Reinforcement Learning”](https://arxiv.org/abs/2303.11366)은, 2023년 3월 20일 최초 제출, 2023년 10월 10일 v4로 개정된 논문입니다. 저자는 Noah Shinn 외 5명이고, 핵심 내용은 언어 에이전트가 스스로 언어적 피드백(반성문)을 생성·메모리에 저장해 다음 시도에 반영함으로써 성능을 높이는 프레임워크를 제안했다는 점입니다. HumanEval 등에서 유의미한 향상을 보고합니다.\n",
        "\n",
        "<img src=\"https://blog.kakaocdn.net/dna/TE252/btsQwhkpIq8/AAAAAAAAAAAAAAAAAAAAAKpNciWbSIUMiGE5-K-UgaF4YTu3a1Z10Fx4OLCK2GRc/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=bEVF2KybKuElMkq83PL%2FKLUB6PI%3D\">"
      ],
      "metadata": {
        "id": "VPKLFKc010k8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Actor (LM): 실제 행동(답안 작성, 코드 생성 등)을 내는 언어모델입니다.\n",
        "- Evaluator (LM): Actor가 낸 결과를 내부적으로 평가합니다(정확성·형식·테스트 통과 여부 판단 등).\n",
        "- Self-reflection (LM): 평가 결과를 바탕으로 “다음에는 이렇게 고치자” 같은 반성문(Reflective text)을 만들어 냅니다.\n",
        "- Trajectory (short-term memory): 이번 시도에서의 행동/관찰 기록(a₀, o₀, …)을 담는 단기 메모리입니다.\n",
        "- Experience (long-term memory): 누적된 반성문을 쌓아두는 장기 메모리(mem)입니다. 이후 시도에서 프롬프트에 이 기억을 넣어 같은 실수를 반복하지 않게 합니다.\n",
        "- Environment: 외부에서 관찰/보상(예: 유닛 테스트의 통과/실패, 웹툴의 응답 등)을 제공합니다. 외부 피드백이 있으면 - Evaluator의 판단과 함께 사용됩니다.\n",
        "\n",
        "<img src=\"https://blog.kakaocdn.net/dna/dxvilH/btsQzDeZ087/AAAAAAAAAAAAAAAAAAAAAJJ8QC-VUzoYLsotdKq1OrXdCNGqhzHG2zdCbJWUWL20/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=3bY%2FbXiSMYffNl7EjR8Qtto1mK8%3D\" width=800>"
      ],
      "metadata": {
        "id": "msykUd_f2C-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"TAVILY_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZJT82tl2Ne2",
        "outputId": "653e3ad2-557b-4dd3-e7b9-c69229a92df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TAVILY_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-5-nano\")"
      ],
      "metadata": {
        "id": "i-QBKPY05e9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "9U7qyMyH6SIy",
        "outputId": "084b579e-bf49-4bb6-cb57-f38ea98c0eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.76)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Collecting requests<3,>=2.32.5 (from langchain_community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.24)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.24.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain_community-0.3.29 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              },
              "id": "07e5e8e190e049449a3f640fe7fd1775"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-tavily"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NBHTJk5D6Toa",
        "outputId": "feaa00b5-d1b4-45ff-c989-325bd607ba4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-tavily\n",
            "  Downloading langchain_tavily-0.2.11-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in /usr/local/lib/python3.12/dist-packages (from langchain-tavily) (3.12.15)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.20 in /usr/local/lib/python3.12/dist-packages (from langchain-tavily) (0.3.27)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.12/dist-packages (from langchain-tavily) (0.3.76)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from langchain-tavily) (2.32.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.20.1)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (0.4.24)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (2.0.43)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2025.8.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-tavily) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.4.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.3.1)\n",
            "Downloading langchain_tavily-0.2.11-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: langchain-tavily\n",
            "Successfully installed langchain-tavily-0.2.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_tavily import TavilySearch\n",
        "\n",
        "tavily_tool = TavilySearch(max_results=5)"
      ],
      "metadata": {
        "id": "rFoSGTFA6cEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 필요한 데이터 클래스 정의\n",
        "\n",
        "- Reflection - 놓친것 / 불필요한 것"
      ],
      "metadata": {
        "id": "Xs5UeO976dsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, ToolMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Reflection(BaseModel):\n",
        "    missing: str = Field(description=\"누락되거나 부족한 부분에 대한 비평\")\n",
        "    superfluous: str = Field(description=\"불필요한 부분에 대한 비평\")"
      ],
      "metadata": {
        "id": "ADmdIQMu6fiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- AnswerQuestion - 답변 / 답변에 대한 반성 / 개선하기 위한 검색 쿼리"
      ],
      "metadata": {
        "id": "brIy843i6hcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AnswerQuestion(BaseModel):\n",
        "    answer: str = Field(description=\"질문에 대한 10문장 이내의 자세한 답변\")\n",
        "    search_queries: list[str] = Field(\n",
        "        description=\"현재 답변에 대한 비평을 해결하기 위한 추가 조사를 위한 1~3개의 웹 검색 쿼리\"\n",
        "    )\n",
        "    reflection: Reflection = Field(description=\"답변에 대한 자기반성 내용\")"
      ],
      "metadata": {
        "id": "DkyB6zTJ6kAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Responder - 구조화된 출력을 위한 답변기"
      ],
      "metadata": {
        "id": "2yXhmILr6mVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Responder:\n",
        "    def __init__(self, runnable):\n",
        "        self.runnable = runnable # Chain\n",
        "\n",
        "    def respond(self, state: dict):\n",
        "        response = self.runnable.invoke(\n",
        "            {\"messages\": state[\"messages\"]}\n",
        "        )\n",
        "        return {\"messages\": response}"
      ],
      "metadata": {
        "id": "BSQdHD_p6nzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 초기 답변기 만들기 (Initial responder)\n",
        "\n",
        "- 초기 답변을 위한 Chain 생성 -출력 스키마를 도구로 사용"
      ],
      "metadata": {
        "id": "-nbHXEKB6prB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "actor_prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"당신은 전문 연구자입니다.\n",
        "\n",
        "            1. {first_instruction}\n",
        "            2. <Reflect> 생성한 답변을 다시 되돌아보고 개선할 수 있도록 비판하세요.\n",
        "            3. <Recommend search queries> 답변의 질을 높이기 위해 추가적으로 조사해야 할 정보에 대한 웹 검색 쿼리를 추천하세요.\"\"\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        (\n",
        "            \"user\",\n",
        "            \"\\n\\n<Reflect> 사용자 원래 질문과 지금까지의 행동을 되돌아보세요.\"\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "initial_answer_chain = actor_prompt_template.partial(\n",
        "    first_instruction=\"질문에 대한 10문장 이내의 자세한 답변을 제공해주세요.\", # 초기 답변\n",
        ") | llm.bind_tools(tools=[AnswerQuestion], tool_choice=\"any\")"
      ],
      "metadata": {
        "id": "mfrZqWDn6tJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [구조화 출력을 위해 스키마를 도구로 사용하는 방법](https://python.langchain.com/docs/concepts/structured_outputs/#using-tool-calling)"
      ],
      "metadata": {
        "id": "gOLK5h8Q-EGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_with_tool = llm.bind_tools(tools=[AnswerQuestion], tool_choice=\"any\")\n",
        "response = llm_with_tool.invoke([HumanMessage(content=\"AI Agent가 무엇인가요?\")])\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN0qXhED-Htf",
        "outputId": "2cb75b05-c3a1-46c8-c1b1-26575966e010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='' additional_kwargs={'tool_calls': [{'id': 'call_S9IyPfKrJpVlQnhDjsiuwcAn', 'function': {'arguments': '{\"answer\":\"AI 에이전트는 특정 목표를 달성하기 위해 환경을 감지하고 판단한 뒤 행동을 선택하고 실행하는 소프트웨어 시스템이나 로봇을 말합니다. 일반적으로 입력(센서, 데이터)을 받아 상태를 이해하고, 목표를 달성하기 위한 계획을 세운 뒤, 적절한 행동(명령 실행, 데이터 처리, API 호출)을 수행합니다. 에이전트는 자율성, 학습 능력, 상호작용 정도에 따라 단순 반응형에서 고도 의사결정 시스템까지 다양합니다. 예를 들어 로봇 청소기는 방의 지도를 만들고 먼지 제거를 최적화하는 에이전트이고, 챗봇은 사용자의 의도에 맞춰 대답을 선택하는 대화 에이전트입니다. 또한 실행 환경이 바뀔 때도 적응하도록 설계될 수 있습니다. 유형으로는 심층 강화학습을 사용하는 학습 에이전트, 계획 기반 에이전트, 규칙 기반 에이전트 등이 있습니다. 핵심 구성은 감지(센서), 의사결정(정책/플래너), 행동(실행 모듈)로 요약할 수 있습니다.\",\"search_queries\":[\"AI 에이전트 정의 예시\",\"에이전트와 프로그램의 차이\",\"자율 에이전트 예시 로봇\"],\"reflection\":{\"missing\":\"실무 맥락의 예시와 안전/윤리 고려, 간단한 계층 아키텍처 다이어그램에 대한 언급이 보강되면 좋습니다.\",\"superfluous\":\"현재 설명은 초보자 이해에 충분하지만 아주 깊은 이론적 수학이나 고급 구현 세부는 필요 없거나 보강될 수 있습니다.\"}}', 'name': 'AnswerQuestion'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 2068, 'prompt_tokens': 208, 'total_tokens': 2276, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1664, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CFsEvvIHjzGNJL2zqM36ckcWoDKwM', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--44ba757f-db1d-4a0c-a299-2f2f36b3f39b-0' tool_calls=[{'name': 'AnswerQuestion', 'args': {'answer': 'AI 에이전트는 특정 목표를 달성하기 위해 환경을 감지하고 판단한 뒤 행동을 선택하고 실행하는 소프트웨어 시스템이나 로봇을 말합니다. 일반적으로 입력(센서, 데이터)을 받아 상태를 이해하고, 목표를 달성하기 위한 계획을 세운 뒤, 적절한 행동(명령 실행, 데이터 처리, API 호출)을 수행합니다. 에이전트는 자율성, 학습 능력, 상호작용 정도에 따라 단순 반응형에서 고도 의사결정 시스템까지 다양합니다. 예를 들어 로봇 청소기는 방의 지도를 만들고 먼지 제거를 최적화하는 에이전트이고, 챗봇은 사용자의 의도에 맞춰 대답을 선택하는 대화 에이전트입니다. 또한 실행 환경이 바뀔 때도 적응하도록 설계될 수 있습니다. 유형으로는 심층 강화학습을 사용하는 학습 에이전트, 계획 기반 에이전트, 규칙 기반 에이전트 등이 있습니다. 핵심 구성은 감지(센서), 의사결정(정책/플래너), 행동(실행 모듈)로 요약할 수 있습니다.', 'search_queries': ['AI 에이전트 정의 예시', '에이전트와 프로그램의 차이', '자율 에이전트 예시 로봇'], 'reflection': {'missing': '실무 맥락의 예시와 안전/윤리 고려, 간단한 계층 아키텍처 다이어그램에 대한 언급이 보강되면 좋습니다.', 'superfluous': '현재 설명은 초보자 이해에 충분하지만 아주 깊은 이론적 수학이나 고급 구현 세부는 필요 없거나 보강될 수 있습니다.'}}, 'id': 'call_S9IyPfKrJpVlQnhDjsiuwcAn', 'type': 'tool_call'}] usage_metadata={'input_tokens': 208, 'output_tokens': 2068, 'total_tokens': 2276, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1664}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.tool_calls[0]['args']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF0G0dST-I2m",
        "outputId": "fc32abe7-99cd-48d1-df3f-8ac99cb6fe33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'AI 에이전트는 특정 목표를 달성하기 위해 환경을 감지하고 판단한 뒤 행동을 선택하고 실행하는 소프트웨어 시스템이나 로봇을 말합니다. 일반적으로 입력(센서, 데이터)을 받아 상태를 이해하고, 목표를 달성하기 위한 계획을 세운 뒤, 적절한 행동(명령 실행, 데이터 처리, API 호출)을 수행합니다. 에이전트는 자율성, 학습 능력, 상호작용 정도에 따라 단순 반응형에서 고도 의사결정 시스템까지 다양합니다. 예를 들어 로봇 청소기는 방의 지도를 만들고 먼지 제거를 최적화하는 에이전트이고, 챗봇은 사용자의 의도에 맞춰 대답을 선택하는 대화 에이전트입니다. 또한 실행 환경이 바뀔 때도 적응하도록 설계될 수 있습니다. 유형으로는 심층 강화학습을 사용하는 학습 에이전트, 계획 기반 에이전트, 규칙 기반 에이전트 등이 있습니다. 핵심 구성은 감지(센서), 의사결정(정책/플래너), 행동(실행 모듈)로 요약할 수 있습니다.',\n",
              " 'search_queries': ['AI 에이전트 정의 예시', '에이전트와 프로그램의 차이', '자율 에이전트 예시 로봇'],\n",
              " 'reflection': {'missing': '실무 맥락의 예시와 안전/윤리 고려, 간단한 계층 아키텍처 다이어그램에 대한 언급이 보강되면 좋습니다.',\n",
              "  'superfluous': '현재 설명은 초보자 이해에 충분하지만 아주 깊은 이론적 수학이나 고급 구현 세부는 필요 없거나 보강될 수 있습니다.'}}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_responder = Responder(runnable=initial_answer_chain)"
      ],
      "metadata": {
        "id": "Mvq-1U0X-KNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_question = \"AI Agent가 무엇인가요?\"\n",
        "initial = first_responder.respond(\n",
        "    {\"messages\": [HumanMessage(content=example_question)]}\n",
        ")"
      ],
      "metadata": {
        "id": "iDZ5UxP0-NbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcXEfD-3-OlY",
        "outputId": "5d0fb652-fe45-425c-8834-459883e1da54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_qRHHAcsryXtNTBoNIfvsd8lX', 'function': {'arguments': '{\"answer\":\"AI Agent(인공지능 에이전트)는 특정 목표를 달성하기 위해 독립적으로 판단하고 행동하는 소프트웨어 구성요소 또는 시스템을 말합니다. 보통 입력을 받아 환경의 상태를 이해하고, 그 상태에 기반해 의사결정을 내리며, 특정 행동을 실행합니다. 에이전트는 주어진 목표와 약속된 제약 내에서 작동하며, 일부는 학습 capacity가 있어 경험으로 정책을 개선합니다. 예를 들어 스마트홈의 온도 조정 시스템, 자동화된 챗봇, 자율주행차의 의사결정 모듈 등이 에이전트의 예시일 수 있습니다. 오늘날의 AI 에이전트는 크게 반응형(현 상태만 보는)부터 계획형(장기 목표를 세워 단계적으로 실행)까지 다양합니다. 주된 차이는 목표 정의 방식, 환경에 대한 관찰 능력, 결정을 내리는 알고리즘의 복잡도, 그리고 피드백으로 정책을 업데이트하는 여부입니다. 간단히 말해 에이전트는 \\'무엇을 원하는가\\'를 정의하고, \\'그 결과를 얻기 위해 무엇을 할 것인가\\'를 스스로 결정합니다. 사용 사례에 따라 인간과의 협업형 에이전트, 완전 자동화 에이전트, 또는 혼합형 시스템으로 분류됩니다. 이 개념은 인공지능의 더 큰 분야인 에이전트 기반 시스템, 강화학습, 자동화와 밀접하게 연결됩니다. 필요하시면 구체적인 사례를 더 설명하겠습니다.\",\"search_queries\":[\"AI 에이전트 정의 구성요소 관찰-판단-행동 루프\",\"에이전트 기반 시스템과 강화학습의 차이 비교\",\"실무에서의 AI 에이전트 사례와 적용 분야\"],\"reflection\":{\"missing\":\"좀 더 구체적으로 관찰-판단-행동 루프, 상태 관리, 자율성 수준, 학습 여부에 대한 분류를 보강하면 좋습니다.\",\"superfluous\":\"기술적 세부사항(모델 아키텍처, 파라미터 수)이나 윤리적 이슈 같은 주제는 이 기본 정의에서 제외하는 편이 좋습니다.\"}}', 'name': 'AnswerQuestion'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4347, 'prompt_tokens': 325, 'total_tokens': 4672, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 3840, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CFsGAZqwVjSRM1tzxFUaFRBGedD6Q', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--778e5fa7-595e-4f69-9552-4f678ad75c5a-0', tool_calls=[{'name': 'AnswerQuestion', 'args': {'answer': \"AI Agent(인공지능 에이전트)는 특정 목표를 달성하기 위해 독립적으로 판단하고 행동하는 소프트웨어 구성요소 또는 시스템을 말합니다. 보통 입력을 받아 환경의 상태를 이해하고, 그 상태에 기반해 의사결정을 내리며, 특정 행동을 실행합니다. 에이전트는 주어진 목표와 약속된 제약 내에서 작동하며, 일부는 학습 capacity가 있어 경험으로 정책을 개선합니다. 예를 들어 스마트홈의 온도 조정 시스템, 자동화된 챗봇, 자율주행차의 의사결정 모듈 등이 에이전트의 예시일 수 있습니다. 오늘날의 AI 에이전트는 크게 반응형(현 상태만 보는)부터 계획형(장기 목표를 세워 단계적으로 실행)까지 다양합니다. 주된 차이는 목표 정의 방식, 환경에 대한 관찰 능력, 결정을 내리는 알고리즘의 복잡도, 그리고 피드백으로 정책을 업데이트하는 여부입니다. 간단히 말해 에이전트는 '무엇을 원하는가'를 정의하고, '그 결과를 얻기 위해 무엇을 할 것인가'를 스스로 결정합니다. 사용 사례에 따라 인간과의 협업형 에이전트, 완전 자동화 에이전트, 또는 혼합형 시스템으로 분류됩니다. 이 개념은 인공지능의 더 큰 분야인 에이전트 기반 시스템, 강화학습, 자동화와 밀접하게 연결됩니다. 필요하시면 구체적인 사례를 더 설명하겠습니다.\", 'search_queries': ['AI 에이전트 정의 구성요소 관찰-판단-행동 루프', '에이전트 기반 시스템과 강화학습의 차이 비교', '실무에서의 AI 에이전트 사례와 적용 분야'], 'reflection': {'missing': '좀 더 구체적으로 관찰-판단-행동 루프, 상태 관리, 자율성 수준, 학습 여부에 대한 분류를 보강하면 좋습니다.', 'superfluous': '기술적 세부사항(모델 아키텍처, 파라미터 수)이나 윤리적 이슈 같은 주제는 이 기본 정의에서 제외하는 편이 좋습니다.'}}, 'id': 'call_qRHHAcsryXtNTBoNIfvsd8lX', 'type': 'tool_call'}], usage_metadata={'input_tokens': 325, 'output_tokens': 4347, 'total_tokens': 4672, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 3840}})}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- tool 호출 결과 확인 (AnswerQuestion 에 맞춰 출력 생성)"
      ],
      "metadata": {
        "id": "74l-Lken-l96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial[\"messages\"].tool_calls[0][\"args\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opelku30-nWL",
        "outputId": "9010d45e-a94b-4351-a6c0-085fa9076f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': \"AI Agent(인공지능 에이전트)는 특정 목표를 달성하기 위해 독립적으로 판단하고 행동하는 소프트웨어 구성요소 또는 시스템을 말합니다. 보통 입력을 받아 환경의 상태를 이해하고, 그 상태에 기반해 의사결정을 내리며, 특정 행동을 실행합니다. 에이전트는 주어진 목표와 약속된 제약 내에서 작동하며, 일부는 학습 capacity가 있어 경험으로 정책을 개선합니다. 예를 들어 스마트홈의 온도 조정 시스템, 자동화된 챗봇, 자율주행차의 의사결정 모듈 등이 에이전트의 예시일 수 있습니다. 오늘날의 AI 에이전트는 크게 반응형(현 상태만 보는)부터 계획형(장기 목표를 세워 단계적으로 실행)까지 다양합니다. 주된 차이는 목표 정의 방식, 환경에 대한 관찰 능력, 결정을 내리는 알고리즘의 복잡도, 그리고 피드백으로 정책을 업데이트하는 여부입니다. 간단히 말해 에이전트는 '무엇을 원하는가'를 정의하고, '그 결과를 얻기 위해 무엇을 할 것인가'를 스스로 결정합니다. 사용 사례에 따라 인간과의 협업형 에이전트, 완전 자동화 에이전트, 또는 혼합형 시스템으로 분류됩니다. 이 개념은 인공지능의 더 큰 분야인 에이전트 기반 시스템, 강화학습, 자동화와 밀접하게 연결됩니다. 필요하시면 구체적인 사례를 더 설명하겠습니다.\",\n",
              " 'search_queries': ['AI 에이전트 정의 구성요소 관찰-판단-행동 루프',\n",
              "  '에이전트 기반 시스템과 강화학습의 차이 비교',\n",
              "  '실무에서의 AI 에이전트 사례와 적용 분야'],\n",
              " 'reflection': {'missing': '좀 더 구체적으로 관찰-판단-행동 루프, 상태 관리, 자율성 수준, 학습 여부에 대한 분류를 보강하면 좋습니다.',\n",
              "  'superfluous': '기술적 세부사항(모델 아키텍처, 파라미터 수)이나 윤리적 이슈 같은 주제는 이 기본 정의에서 제외하는 편이 좋습니다.'}}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 수정 단계(Revision)"
      ],
      "metadata": {
        "id": "4RB5m4lO-otX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviseAnswer(AnswerQuestion):\n",
        "    # 답변 > 반성 > 근거 인용 > 검색 제안\n",
        "    \"\"\"Revise your original answer to your question. Provide an answer, reflection,\n",
        "\n",
        "    cite your reflection with references, and finally\n",
        "    add search queries to improve the answer.\"\"\"\n",
        "\n",
        "    references: list[str] = Field(\n",
        "        description=\"업데이트된 답변에 사용된 인용 출처\"\n",
        "    )"
      ],
      "metadata": {
        "id": "3H7jC0dv-qMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "revise_instructions = \"\"\"이전 답변을 새로운 정보를 바탕으로 수정하세요.\n",
        "- 이전 비평 내용을 활용해 중요한 정보를 추가해야 합니다.\n",
        "  - 수정된 답변에는 반드시 숫자로 된 인용 표시를 포함하여 검증 가능하도록 해야 합니다.\n",
        "  - 답변 하단에 \"참고문헌\" 섹션을 추가하세요 (이 부분은 단어 수 제한에 포함되지 않습니다). 형식은 다음과 같습니다:\n",
        "    - [1] https://example.com\n",
        "    - [2] https://example.com\n",
        "\n",
        "- 이전 비평 내용을 바탕으로 불필요한 정보를 제거하고, 최종 답변은 반드시 200자를 넘지 않도록 하세요.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "revision_chain = actor_prompt_template.partial(\n",
        "    first_instruction=revise_instructions,\n",
        ") | llm.bind_tools(tools=[ReviseAnswer], tool_choice=\"any\")\n",
        "\n",
        "\n",
        "revisor = Responder(runnable=revision_chain)"
      ],
      "metadata": {
        "id": "jhSomq78-rP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 초기답변에서 생성한 웹검색 쿼리를 Tool 실행한 결과를 함께 입력"
      ],
      "metadata": {
        "id": "1mUtuZPE-s-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "revised = revisor.respond(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(content=example_question),\n",
        "            initial[\"messages\"],\n",
        "            ToolMessage(\n",
        "                tool_call_id=initial['messages'].additional_kwargs['tool_calls'][0]['id'],\n",
        "                content=json.dumps(\n",
        "                    tavily_tool.invoke(\n",
        "                        {\n",
        "                            \"query\": initial[\"messages\"].tool_calls[0][\"args\"]['search_queries'][0]\n",
        "                        }\n",
        "                    )\n",
        "                ),\n",
        "            ),\n",
        "        ]\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "78iUlNhs-uFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://blog.kakaocdn.net/dna/bk9H1l/btsQzJzpfvC/AAAAAAAAAAAAAAAAAAAAACJKpwEAA8XFASLM3eNktiwFHoYdWKTyU6DOvuweWB3S/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=9c%2BBXwbClSPdn8Pra4HPaL4KLqw%3D\" width=800>"
      ],
      "metadata": {
        "id": "BycSglY2-v0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "revised[\"messages\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZaKkagD-zvS",
        "outputId": "7e59830d-775c-4344-c953-cfac596050f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_IDorpVb8I5zzIZbZ8XKTvIW7', 'function': {'arguments': '{\"answer\":\"AI 에이전트는 목표 달성을 위해 관찰-판단-행동 루프를 독립적으로 수행하는 소프트웨어 구성요소입니다. 입력 정보를 해석하고 의사결정을 내려 행동을 실행합니다. 자율성 수준과 학습 여부에 따라 반응형에서 계획형까지 다양합니다. [1] [2]\",\"search_queries\":[\"AI 에이전트 정의 구성요소 관찰-판단-행동 루프\",\"에이전트 기반 시스템과 강화학습의 차이 비교\",\"실무에서의 AI 에이전트 사례와 적용 분야\"],\"reflection\":{\"missing\":\"좀 더 구체적으로 관찰-판단-행동 루프, 상태 관리, 자율성 수준, 학습 여부에 대한 분류를 보강하면 좋습니다.\",\"superfluous\":\"기술적 세부사항(모델 아키텍처, 파라미터 수)이나 윤리적 이슈 같은 주제는 이 기본 정의에서 제외하는 편이 좋습니다.\"},\"references\":[\"https://cloud.google.com/discover/what-are-ai-agents?hl=ko\",\"https://www.automationanywhere.com/kr/company/blog/automation-ai/exploring-ai-agents-types-capabilities-and-real-world-applications\"]}', 'name': 'ReviseAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3043, 'prompt_tokens': 3930, 'total_tokens': 6973, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 2752, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CFsOzMUfw9tdF2DQd2pgBSnuR3TL4', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d9e04de2-4f4e-42f5-b50c-766fb9fb72da-0', tool_calls=[{'name': 'ReviseAnswer', 'args': {'answer': 'AI 에이전트는 목표 달성을 위해 관찰-판단-행동 루프를 독립적으로 수행하는 소프트웨어 구성요소입니다. 입력 정보를 해석하고 의사결정을 내려 행동을 실행합니다. 자율성 수준과 학습 여부에 따라 반응형에서 계획형까지 다양합니다. [1] [2]', 'search_queries': ['AI 에이전트 정의 구성요소 관찰-판단-행동 루프', '에이전트 기반 시스템과 강화학습의 차이 비교', '실무에서의 AI 에이전트 사례와 적용 분야'], 'reflection': {'missing': '좀 더 구체적으로 관찰-판단-행동 루프, 상태 관리, 자율성 수준, 학습 여부에 대한 분류를 보강하면 좋습니다.', 'superfluous': '기술적 세부사항(모델 아키텍처, 파라미터 수)이나 윤리적 이슈 같은 주제는 이 기본 정의에서 제외하는 편이 좋습니다.'}, 'references': ['https://cloud.google.com/discover/what-are-ai-agents?hl=ko', 'https://www.automationanywhere.com/kr/company/blog/automation-ai/exploring-ai-agents-types-capabilities-and-real-world-applications']}, 'id': 'call_IDorpVb8I5zzIZbZ8XKTvIW7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3930, 'output_tokens': 3043, 'total_tokens': 6973, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 2752}})"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "revised[\"messages\"].tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md-XcTP8-1Zb",
        "outputId": "c6cb6ae7-5781-48bb-953a-58e3c250c237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'ReviseAnswer',\n",
              "  'args': {'answer': 'AI 에이전트는 목표 달성을 위해 관찰-판단-행동 루프를 독립적으로 수행하는 소프트웨어 구성요소입니다. 입력 정보를 해석하고 의사결정을 내려 행동을 실행합니다. 자율성 수준과 학습 여부에 따라 반응형에서 계획형까지 다양합니다. [1] [2]',\n",
              "   'search_queries': ['AI 에이전트 정의 구성요소 관찰-판단-행동 루프',\n",
              "    '에이전트 기반 시스템과 강화학습의 차이 비교',\n",
              "    '실무에서의 AI 에이전트 사례와 적용 분야'],\n",
              "   'reflection': {'missing': '좀 더 구체적으로 관찰-판단-행동 루프, 상태 관리, 자율성 수준, 학습 여부에 대한 분류를 보강하면 좋습니다.',\n",
              "    'superfluous': '기술적 세부사항(모델 아키텍처, 파라미터 수)이나 윤리적 이슈 같은 주제는 이 기본 정의에서 제외하는 편이 좋습니다.'},\n",
              "   'references': ['https://cloud.google.com/discover/what-are-ai-agents?hl=ko',\n",
              "    'https://www.automationanywhere.com/kr/company/blog/automation-ai/exploring-ai-agents-types-capabilities-and-real-world-applications']},\n",
              "  'id': 'call_IDorpVb8I5zzIZbZ8XKTvIW7',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 웹검색을 위한 툴 노드 생성"
      ],
      "metadata": {
        "id": "e8TqkSNSBGzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tavily_tool.batch(\n",
        "    [\n",
        "        {\"query\": initial[\"messages\"].tool_calls[0][\"args\"]['search_queries'][0]}\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWm-PIgKBIp7",
        "outputId": "8be07c76-6c64-4b7d-cdc7-2a7d87aad309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'query': 'AI 에이전트 정의 구성요소 관찰-판단-행동 루프',\n",
              "  'follow_up_questions': None,\n",
              "  'answer': None,\n",
              "  'images': [],\n",
              "  'results': [{'url': 'https://aiheroes.ai/community/300',\n",
              "    'title': 'AI 에이전트는 어떻게 작동할까? 에이전트 워크플로우 완벽 이해하기',\n",
              "    'content': \"생각과 행동(액션)에 이어서, 에이전트 워크플로우의 마지막 핵심 구성 요소는 '관찰'입니다. 관찰은 에이전트가 세계를 이해하고, 자신의 행동 결과\",\n",
              "    'score': 0.98593,\n",
              "    'raw_content': None},\n",
              "   {'url': 'https://www.automationanywhere.com/kr/company/blog/automation-ai/exploring-ai-agents-types-capabilities-and-real-world-applications',\n",
              "    'title': 'AI 에이전트 알아보기: 유형, 기능 및 활용 분야 - Automation Anywhere',\n",
              "    'content': 'AI 에이전트는 환경을 인식하고, 수집된 정보를 바탕으로 추론하며, 미리 정의된 목표를 달성하기 위해 적절한 행동을 취하는 정교한 소프트웨어 프로그램',\n",
              "    'score': 0.98302,\n",
              "    'raw_content': None},\n",
              "   {'url': 'https://tech.ktcloud.com/entry/2025-03-ktcloud-ai-agent-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EC%9C%A0%ED%98%95%EA%B3%BC%ED%8A%B9%EC%84%B1',\n",
              "    'title': '[Tech Series] kt cloud AI 에이전트 #2 : 에이전트의 유형과 특성',\n",
              "    'content': '![[Tech Series] kt cloud AI 에이전트 #2 : 에이전트의 유형과 특성](https://blog.kakaocdn.net/dna/q9Ba1/btsMUmB48DV/AAAAAAAAAAAAAAAAAAAAAMQ0xpWV1QEa18MHYhkeQAq1nW-wUQ5x1EVuGb6cIgAX/img.png? ![[Tech Series] kt cloud AI 에이전트 #2 : 에이전트의 유형과 특성](https://blog.kakaocdn.net/dna/q9Ba1/btsMUmB48DV/AAAAAAAAAAAAAAAAAAAAAMQ0xpWV1QEa18MHYhkeQAq1nW-wUQ5x1EVuGb6cIgAX/img.png? ![[Tech Series] kt cloud AI 에이전트 #2 : 에이전트의 유형과 특성](https://blog.kakaocdn.net/dna/mk65g/btsMUzafjqk/AAAAAAAAAAAAAAAAAAAAAIVZRj03khT0Vf8S-ELNZo5A2NwkoKHWY2ZI-hiJ4BVz/img.png? ![[Tech Series] kt cloud AI 에이전트 #2 : 에이전트의 유형과 특성](https://blog.kakaocdn.net/dna/mk65g/btsMUzafjqk/AAAAAAAAAAAAAAAAAAAAAIVZRj03khT0Vf8S-ELNZo5A2NwkoKHWY2ZI-hiJ4BVz/img.png? ![[Tech Series] kt cloud AI 에이전트 #2 : 에이전트의 유형과 특성](https://blog.kakaocdn.net/dna/cQa3v0/btsMVyWtnSm/AAAAAAAAAAAAAAAAAAAAAHkLrXKODnVUqrsH0cG6_weJ8autWnfbxI1-c4vLyJ6H/img.png? ![[Tech Series] kt cloud AI 에이전트 #2 : 에이전트의 유형과 특성](https://blog.kakaocdn.net/dna/ejjrqW/btsMVznDZY0/AAAAAAAAAAAAAAAAAAAAAL4pIzRqAfp9gnj8v5F_RZhj82q89Raoa56jXUe9zNds/img.png? ![[Tech Series] kt cloud AI 에이전트 #2 : 에이전트의 유형과 특성](https://blog.kakaocdn.net/dna/ejjrqW/btsMVznDZY0/AAAAAAAAAAAAAAAAAAAAAL4pIzRqAfp9gnj8v5F_RZhj82q89Raoa56jXUe9zNds/img.png? ![[Tech Series] kt cloud AI 에이전트 #2 : 에이전트의 유형과 특성](https://blog.kakaocdn.net/dna/xZDXd/btsMTYIS1n8/AAAAAAAAAAAAAAAAAAAAANulolHwh7MVNelLVc3d6si9VCeLeKUIK1sxAsG9s3EN/img.png? ![[Tech Series] kt cloud AI 에이전트 #2 : 에이전트의 유형과 특성](https://blog.kakaocdn.net/dna/xZDXd/btsMTYIS1n8/AAAAAAAAAAAAAAAAAAAAANulolHwh7MVNelLVc3d6si9VCeLeKUIK1sxAsG9s3EN/img.png? ![[Tech Series] kt cloud AI 에이전트 #2 : 에이전트의 유형과 특성](https://blog.kakaocdn.net/dna/GXzlm/btsMWUYyjaG/AAAAAAAAAAAAAAAAAAAAAHXpvAxjdh0GbMhgSdUagmWCYddM2mdyV3zdpEBXIjU-/img.png? ![[Tech Series] kt cloud AI 에이전트 #2 : 에이전트의 유형과 특성](https://blog.kakaocdn.net/dna/GXzlm/btsMWUYyjaG/AAAAAAAAAAAAAAAAAAAAAHXpvAxjdh0GbMhgSdUagmWCYddM2mdyV3zdpEBXIjU-/img.png?',\n",
              "    'score': 0.97884,\n",
              "    'raw_content': None},\n",
              "   {'url': 'https://wikidocs.net/287639',\n",
              "    'title': '08-03. 에이전트 행동 시스템의 패러다임 - 위키독스',\n",
              "    'content': '이 세 가지 구성 요소는 함께 AI 에이전트의 행동 시스템이 어떤 범위를 가지고, 어떤 특성을 지니며, 어떻게 구성되고 실행되는지를 총체적으로 정의',\n",
              "    'score': 0.97429,\n",
              "    'raw_content': None},\n",
              "   {'url': 'https://cloud.google.com/discover/what-are-ai-agents?hl=ko',\n",
              "    'title': 'AI 에이전트란 무엇인가요? 정의, 예시, 유형 - Google Cloud',\n",
              "    'content': 'AI 에이전트는 AI를 사용해 사용자를 대신하여 목표를 추구하고 태스크를 완료하는 소프트웨어 시스템입니다. AI 에이전트는 추론, 계획, 기억이 가능하며 일정 수준의',\n",
              "    'score': 0.97072,\n",
              "    'raw_content': None}],\n",
              "  'response_time': 1.27,\n",
              "  'request_id': 'd0abf751-6c5a-401d-b3ec-f4eda5e697a0'}]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import StructuredTool\n",
        "\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "\n",
        "def run_queries(search_queries: list[str], **kwargs):   # 키워드 arguments\n",
        "    \"\"\"Run the generated queries.\"\"\"\n",
        "    return tavily_tool.batch([{\"query\": query} for query in search_queries])\n",
        "\n",
        "\n",
        "tool_node = ToolNode(\n",
        "    [\n",
        "        StructuredTool.from_function(run_queries, name=AnswerQuestion.__name__),\n",
        "        StructuredTool.from_function(run_queries, name=ReviseAnswer.__name__),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Py_1YetJBKyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 그래프 생성하기"
      ],
      "metadata": {
        "id": "rIFjTUBuCDmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph, START\n",
        "from langgraph.graph.message import add_messages\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]"
      ],
      "metadata": {
        "id": "HJ6asTd8CEsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_ITERATIONS = 5\n",
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"draft\", first_responder.respond)\n",
        "\n",
        "graph_builder.add_node(\"execute_tools\", tool_node) # 웹 검색 진행\n",
        "graph_builder.add_node(\"revise\", revisor.respond)\n",
        "\n",
        "graph_builder.add_edge(\"draft\", \"execute_tools\")\n",
        "graph_builder.add_edge(\"execute_tools\", \"revise\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiIfn_4sCGPL",
        "outputId": "653f0d54-c18d-4291-fdbb-d422152bba88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7b5640961b20>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_num_iterations(state: list):\n",
        "    i = 0\n",
        "    for m in state[::-1]:\n",
        "        if m.type not in {\"tool\", \"ai\"}:\n",
        "            break\n",
        "        i += 1\n",
        "    return i\n",
        "\n",
        "\n",
        "def event_loop(state: list):\n",
        "    num_iterations = _get_num_iterations(state[\"messages\"])\n",
        "    if num_iterations > MAX_ITERATIONS:\n",
        "        return END\n",
        "    return \"execute_tools\"\n",
        "\n",
        "\n",
        "graph_builder.add_conditional_edges(\"revise\", event_loop, [\"execute_tools\", END])\n",
        "graph_builder.add_edge(START, \"draft\")\n",
        "graph = graph_builder.compile()\n",
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "Wtb9udaTCZl7",
        "outputId": "ba0ee54c-8a2e-4f38-bd1a-c03ac68b7214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x7b564091ab10>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "events = graph.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"AI Agent가 무엇인가요?\")]},\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for i, step in enumerate(events):\n",
        "    print(f\"Step {i}\")\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqWs4bivCgL2",
        "outputId": "b5404459-35d4-480d-ad61-362221a47283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "AI Agent가 무엇인가요?\n",
            "Step 1\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  AnswerQuestion (call_jazmMD4wLyvV2mhJlTPwOFaT)\n",
            " Call ID: call_jazmMD4wLyvV2mhJlTPwOFaT\n",
            "  Args:\n",
            "    answer: AI 에이전트(Agent)란 주어진 목표를 달성하기 위해 환경을 인지하고 행동하는 자율적 시스템입니다. 일반적으로 에이전트는 환경을 감지하는 센서와 행동을 실행하는 액추에이터를 통해 상호작용합니다. 에이전트는 관찰(퍼셙션)을 바탕으로 의사결정을 하고, 경우에 따라 계획하고 학습하며 행동합니다. 합리적 에이전트는 주어진 지식과 기대되는 결과를 바탕으로 성능을 최대화하는 행동을 선택합니다. 에이전트의 유형으로는 반응적(즉시 자극에 반응), 계획적(미래를 고려한 계획), 학습 에이전트, 목표 기반/효용 기반 에이전트 등이 있습니다. 대화형 에이전트(챗봇 등)도 흔한 예로, 사용자와 상호작용하는 소프트웨어 에이전트입니다. 에이전트와 일반 프로그램의 차이는 목표 지향성, 상태 유지, 학습 및 적응 능력, 그리고 다른 에이전트와의 상호작용 여부에 있습니다. 설계 시 성능 척도(성과함수), 환경 모델, 가능한 행동 공간, 학습 방법을 정의해야 합니다. 한계로는 불완전한 정보, 확정불가능한 환경, 안전성과 윤리적 고려가 필요합니다.\n",
            "    search_queries: ['AI 에이전트 정의 합리적 에이전트', '에이전트-환경 상호작용 퍼셉션-액션 루프', '학습 에이전트 예시 그리고 차이점']\n",
            "    reflection: {'missing': '좀 더 포멀한 정의를 수식적으로 보일 수 있다면 좋고, 예시를 도메인별로 구체적으로 제시하면 이해도가 높아질 수 있습니다.', 'superfluous': '일반적인 설명으로 충분히 다뤘으나, 학습, 계획, 추론의 구체적 메커니즘에 대한 심화 내용은 간략화되어 있습니다.'}\n",
            "Step 2\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: AnswerQuestion\n",
            "\n",
            "[{\"query\": \"AI 에이전트 정의 합리적 에이전트\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://brainpod.ai/ko/%ED%95%A9%EB%A6%AC%EC%A0%81-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-ai%EC%9D%98-%EC%A3%BC%EC%9A%94-%EC%9C%A0%ED%98%95-%EC%B0%A8%EC%9D%B4%EC%A0%90-%EB%B0%8F-%EC%8B%A4%EC%A0%9C-%EC%82%AC%EB%A1%80/\", \"title\": \"합리적 에이전트 AI 이해하기: 주요 유형, 차이점 및 실제 사례\", \"content\": \"인공지능(AI)에서 합리적 에이전트는 미리 정의된 목표 집합에 따라 기대 성능을 극대화하기 위해 행동하는 지능형 에이전트로 정의됩니다. 이러한 에이전트는 논리적\", \"score\": 0.9184877, \"raw_content\": null}, {\"url\": \"https://ai-ceo.com/blog/what-is-ai-agents/\", \"title\": \"AI 에이전트란 무엇인가 - AI CEO - 아이쎄오\", \"content\": \"합리적 에이전트는 주어진 지각열(percept sequence)과 성과측도(performance measure)에 대해 기대 효용을 극대화하는 행동을 선택하는 존재로 정의된다.\", \"score\": 0.9037116, \"raw_content\": null}, {\"url\": \"https://brainpod.ai/ko/ai%EC%97%90%EC%84%9C-%ED%95%A9%EB%A6%AC%EC%A0%81-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EC%9D%B4%ED%95%B4-%EC%A3%BC%EC%9A%94-%EC%B0%A8%EC%9D%B4%EC%A0%90-%EC%9C%A0%ED%98%95-%EB%B0%8F-%EC%98%88/\", \"title\": \"AI에서 합리적 에이전트 이해하기: 주요 차이점, 유형 및 예시\", \"content\": \"합리적인 AI 에이전트는 논리적 추론과 사용 가능한 정보를 바탕으로 특정 목표를 달성할 가능성을 극대화하기 위해 결정을 내리고 행동을 취하도록 설계된 지능형 시스템\", \"score\": 0.86981434, \"raw_content\": null}, {\"url\": \"https://blog.naver.com/jaeyoon_95/221096281001\", \"title\": \"[인공지능 기초]2.Intelligent Agents : 네이버 블로그\", \"content\": \"어떻게 인식하느냐에 따라 agent의 action이 결정됩니다. ​. 합리적 에이전트(Rational Agent). Rational agent는 각각의 가능한 지각열에 대해, 자신의\", \"score\": 0.79958355, \"raw_content\": null}, {\"url\": \"https://www.automationanywhere.com/kr/rpa/ai-agents\", \"title\": \"AI 에이전트란?\", \"content\": \"AI 에이전트는 자체 환경에서 학습하고 인지 작업을 수행할 수 있는 소프트웨어 프로그램입니다. 유형 및 이점을 포함하여 AI 에이전트에 대한 모든 것을 알아보세요.\", \"score\": 0.6690754, \"raw_content\": null}], \"response_time\": 0.96, \"request_id\": \"1867041e-64a3-41f7-968d-c45e5d3db9c3\"}, {\"query\": \"에이전트-환경 상호작용 퍼셉션-액션 루프\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://owl-d.tistory.com/45\", \"title\": \"[Spinning Up 해석] Part 1 : Key Concepts in RL - ABOUT - 티스토리\", \"content\": \"에이전트-환경 상호작용 루프. 강화학습(RL)의 주인공은 에이전트(agent)와 환경(environment)이다. 환경은 에이전트가 살고 상호작용하는 world이다.\", \"score\": 0.6601948, \"raw_content\": null}, {\"url\": \"https://m.blog.naver.com/ydot/222092734116\", \"title\": \"[바닥부터 배우는 강화 학습] 에이전트와 환경 - 블로그\", \"content\": \"[바닥부터 배우는 강화 학습] 에이전트와 환경 : 네이버 블로그 [바닥부터 배우는 강화 학습] 에이전트와 환경 이 포스팅을 읽기전에 [바닥부터 배우는 강화 학습] 연재 글을 읽어보세요!!!! Image 5[**[바닥부터 배우는 강화 학습] 지도 학습과 강화 학습** ​드디어 강화 학습에 대해 배우는 긴 여정이 시작되었습니다. Image 6[**[바닥부터 배우는 강화학습] 순차적 의사결정 문제** ​​강화 학습이 풀고자 하는 문제는 바로 순차적 의사결정sequential decision making 문제입니다. Image 7[**[바닥부터 배우는 강화 학습] 보상** ​보상reward이란 의사결정을 얼마나 잘하고 있는지 알려주는 신호입니다. 에이전트가 **액션****action****(행동)**을 하고 그에 따라 상황이 변하는 것을 하나의 **루프****loop**라 했을 때 이 루프가 끊임없이 반복되는 것을 순차적 의사결정 문제라 할 수 있습니다. Image 8 Image 9 **바닥부터 배우는 강화 학습**저자 노승은 출판 영진닷컴 발매 2020.09.15. Image 10 {\\\"title\\\":\\\"[바닥부터 배우는 강화 학습] 에이전트와 환경\\\",\\\"source\\\":\\\"https://blog.naver.com/ydot/222092734116\\\",\\\"blogName\\\":\\\"영진닷컴 ..\\\",\\\"domainIdOrBlogId\\\":\\\"ydot\\\",\\\"nicknameOrBlogId\\\":\\\"영진닷컴\\\",\\\"logNo\\\":222092734116,\\\"smartEditorVersion\\\":4,\\\"lineDisplay\\\":true,\\\"outsideDisplay\\\":true,\\\"meDisplay\\\":true,\\\"cafeDisplay\\\":true,\\\"blogDisplay\\\":true} Image 16\", \"score\": 0.5568099, \"raw_content\": null}, {\"url\": \"https://yoonschallenge.tistory.com/845\", \"title\": \"The Rise and Potential of Large Language Model Based Agents\", \"content\": \"이 프레임워크는 브레인(Brain), 지각(Perception), 액션(Action)이라는 세 가지 핵심 모듈로 구성됩니다. 각 모듈은 에이전트가 환경과 상호작용하고\", \"score\": 0.5568099, \"raw_content\": null}, {\"url\": \"https://wikidocs.net/286004\", \"title\": \"01-03. 인간의 뇌를 닮은 AI, 가능한가요? - 위키독스\", \"content\": \"즉, '에이전트 루프(agent loop)'는 AI가 주변 환경과 상호작용하고, 내부 정보를 바탕으로 다음 행동을 결정하며, 그 결과를 반영해 또다시 학습하는\", \"score\": 0.521886, \"raw_content\": null}, {\"url\": \"https://wikidocs.net/287639\", \"title\": \"08-03. 에이전트 행동 시스템의 패러다임 - 위키독스\", \"content\": \"정의: 에이전트가 환경과 상호작용하면서 어떤 행동을 선택할지 경험을 통해 학습하는 과정. · 관련 기술: 강화학습(RL): 보상을 기반으로 행동을 조정함\", \"score\": 0.49143207, \"raw_content\": null}], \"response_time\": 1.23, \"request_id\": \"2886869a-f706-49fd-8e70-2a6b740da4e6\"}, {\"query\": \"학습 에이전트 예시 그리고 차이점\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://botpress.com/ko/blog/real-world-applications-of-ai-agents\", \"title\": \"AI 에이전트의 실제 사례 36가지 - Botpress\", \"content\": \"모델 기반 반사 에이전트는 예측할 수 없는 환경을 처리하기 위해 내부 세계 모델을 유지하고 학습 에이전트는 새로운 데이터와 경험을 기반으로 시간이\", \"score\": 0.50007385, \"raw_content\": null}, {\"url\": \"https://blog.naver.com/hanksi/223987546803?fromRss=true&trackingCode=rss\", \"title\": \"AI 에이전트 vs Agentic AI: 개념부터 차이점까지 상세 분석 by Gemini\", \"content\": \"학습 능력 (Learning): 경험을 통해 시간이 지남에 따라 성능을 개선하고 새로운 상황에 적응할 수 있습니다. ​. 작동 방식 및 아키텍처. AI 에이전트는\", \"score\": 0.44912744, \"raw_content\": null}, {\"url\": \"https://www.reddit.com/r/reinforcementlearning/comments/nkep1x/reinforcement_learning_agent_vs_network_vs_model/?tl=ko\", \"title\": \"강화 학습: 에이전트 vs 네트워크 vs 모델 vs 정책 - Reddit\", \"content\": \"에이전트를 훈련하는 데 사용되거나 그 결과로 생성됩니다. 에이전트는 구조에 따라 하나 이상을 가질 수 있습니다. (예: AC 네트워크는 기술적으로 두\", \"score\": 0.42033842, \"raw_content\": null}, {\"url\": \"https://www.cio.com/article/4006536/%EC%97%90%EC%9D%B4%EC%A0%84%ED%8B%B1-ai%EC%99%80-ai-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EB%AC%B4%EC%97%87%EC%9D%B4-%EB%8B%A4%EB%A5%B8%EA%B0%80.html\", \"title\": \"에이전틱 AI와 AI 에이전트, 무엇이 다른가 - CIO\", \"content\": \"에이전틱 AI는 아직 초기 단계이지만, 많은 기업이 AI 에이전트를 빠르게 도입하고 있다. 반면, 초기 단계에 있는 에이전틱 AI는 여러 에이전트와 AI 도구를 활용해 스스로 목표를 설정하고, 학습하며, 작업 전반에 걸쳐 추론할 수 있는 완전 자율 시스템을 구성하는 상위 개념 기술이다.” 소프트웨어 거버넌스 서비스 업체 모델옵(ModelOp)의 CTO 짐 올슨은 AI 에이전트는 개별 플레이어 또는 직원으로, 에이전틱 AI는 팀 전체로 이해하면 된다고 설명했다. 에이전틱 AI와 AI 에이전트의 차이는 단순한 용어 문제처럼 들릴 수 있지만, 아이베리파이의 다마니는 이 구분이 CIO에게 매우 중요하다고 강조했다. 다마니는 AI 에이전트와 에이전틱 AI가 어떻게 작동하는지 충분히 이해하지 못하면, CIO와 IT 리더가 관련 리스크나 필요한 관리 수준을 간과할 수 있다고 경고했다. Grant Gross, a senior writer at CIO, is a long-time IT journalist who has focused on AI, enterprise technology, and tech policy.\", \"score\": 0.23074678, \"raw_content\": null}, {\"url\": \"https://aiheroes.ai/community/291\", \"title\": \"AI 에이전트 100% 알아보기! 에이전틱 AI와 다른 점은 무엇일까?\", \"content\": \"# AI 에이전트 100% 알아보기! 1. AI 에이전트(AI Agent)란 무엇일까? 2. 글로벌 빅테크의 AI 에이전트 AI 에이전트(AI Agent)란 무엇일까? ### 1) 챗봇 vs AI 에이전트 이러한 지속적인 학습을 통해 AI 에이전트는 변화하는 환경에 적응하며 더 나은 솔루션을 제안할 수 있게 됩니다. ### ⚠️ AI 에이전트 vs 에이전틱 AI #### 📌 AI 에이전트 #### 📌 에이전틱 AI 글로벌 빅테크의 AI 에이전트 프로젝트 아스트라는 아직 일부 테스터에게만 공개되고 있지만, 더 발전된 AI 에이전트 모델로 제미나이 앱과의 통합을 통해 더욱 강력한 AI 경험을 제공한다고 설명했습니다. ### 1) 신뢰할 수 있는 AI 에이전트 AI 에이전트는 앞으로 더욱 복잡한 업무를 수행하며 중요한 결정을 내리게 될 것이기 때문에 사용자가 AI를 신뢰할 수 있도록 하는 UX 설계가 중요할 것입니다.\", \"score\": 0.18728161, \"raw_content\": null}], \"response_time\": 0.89, \"request_id\": \"40f1527e-991c-4959-a364-bc5425b5bcf5\"}]\n",
            "Step 3\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  ReviseAnswer (call_oGXFGTSbiWh39FUcFVcMVg9f)\n",
            " Call ID: call_oGXFGTSbiWh39FUcFVcMVg9f\n",
            "  Args:\n",
            "    answer: 원래 질문은 AI 에이전트의 정의였고, 이전 답변은 환경을 인지하고 행동하는 구조, 합리적 에이전트의 목표 지향성, 유형(반응적/계획적/학습/효용 기반) 및 대화형 에저트 예를 제시했습니다. 또한 에이전트와 일반 프로그램의 차이와 설계 시 성능 척도와 학습 방법의 필요성을 언급했습니다. 강점은 핵심 구성요소(센서/액추에이터), 퍼셉션-액션 루프, 도메인별 예시의 포괄성입니다. 개선점으로는 수학적/수식적 정의의 부재, 학습·추론의 구체적 메커니즘에 대한 심층 설명 부족, 안전성과 윤리 프레임워크의 구체적 제시가 필요합니다. 앞으로는 도메인별 구체 사례와 정량적 성능 척도 예시를 추가하면 이해도가 높아질 것입니다.\n",
            "    search_queries: ['합리적 에이전트 수학적 정의', '에이전트-환경 루프 정량적 모델', '도메인별 AI 에이전트 예시']\n",
            "    reflection: {'missing': '정의의 수식화, 성능함수/환경 모델의 구체 예시, 안전성·윤리성의 수치화 프레임워크 추가', 'superfluous': '기본 개념 설명 외 학습/추론 메커니즘의 세부 심화 내용은 현재 필요하지 않음'}\n",
            "    references: ['https://brainpod.ai/ko/%ED%95%A9%EB%A6%AC%EC%A0%81-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-ai%EC%9D%98-%EC%A3%BC%94%EC%9A%94-%EC%9C%A0%ED%98%95-%EC%B0%A8%EC%9D%B4%EC%A0%90-%EB%8C%80%EB%8B%AC%EB%A5%BC-%EC%97%B0%EA%B5%AC/', 'https://ai-ceo.com/blog/what-is-ai-agents/']\n",
            "Step 4\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: ReviseAnswer\n",
            "\n",
            "[{\"query\": \"합리적 에이전트 수학적 정의\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://blog.naver.com/keebh/20206697388?viewType=pc\", \"title\": \"AI 소개 : 네이버 블로그\", \"content\": \"합리적인 에이전트 (rational agent) 란 최상의 결과 (outcome), 불확실성이 있는 경우에는 최상의 기대 (expected) 결과를 얻을 수 있도록 행동하는\", \"score\": 0.86080295, \"raw_content\": null}, {\"url\": \"https://velog.io/@eunaahn/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EA%B3%BC-%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5-\", \"title\": \"인공지능과 기계학습 - Rational Agent\", \"content\": \"합리적 에이전트라고 하며 최상의 결과를(불확실성이 존재할 경우에는 기대할 수 있는 최상의 결과를) 내도록 행동하는 에이전트이다. Percept. 어떤 순간\", \"score\": 0.8173562, \"raw_content\": null}, {\"url\": \"https://wikidocs.net/198338\", \"title\": \"A_04. Intelligent Agents from Wiki - B. Artificial intelligence - 한글\", \"content\": \"\\\"합리적 에이전트\\\"를 다음과 같이 정의합니다. \\\"과거의 경험과 지식을 바탕으로 성능 측정의 기대값을 최대화하도록 행동하는 에이전트.\\\" \\\"인공 지능\", \"score\": 0.8124067, \"raw_content\": null}, {\"url\": \"https://eastk1te.github.io/posts/AI(1)/\", \"title\": \"[Study]Chapter 1 & 2, 지능적 에이전트 - Eastk1te\", \"content\": \"합리적 에이전트의 정의→ 각각의 가능한 지각열에 대해, 합리적 에이전트는 자신의 지각열과 에이전트의 내장지식이 제공하는 증거에 기초해서 성과\", \"score\": 0.76972175, \"raw_content\": null}, {\"url\": \"https://wikidocs.net/198339\", \"title\": \"A_05. Intelligent Agents - A - Deep Learning Bible - 위키독스\", \"content\": \"수학적으로 말하면 에이전트의 행동은 주어진 지각 순서를 행동에 매핑하는 에이전트 기능으로 설명됩니다.\", \"score\": 0.74363416, \"raw_content\": null}], \"response_time\": 1.09, \"request_id\": \"1e6614c2-b514-4945-99a7-cf15440a6514\"}, {\"query\": \"에이전트-환경 루프 정량적 모델\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE02374547\", \"title\": \"Human-in-the-loop 에이전트 기반 모델링 및 시뮬레이션 구현 - DBpia\", \"content\": \"이 연구는 Human-in-the-loop(HITL) 시뮬레이션을 활용하여 인간 행동을 정량적으로 분석하고 이를 기반으로 에이전트 기반 시뮬레이션 모델을 개발하는 데 초점을 맞춘다.\", \"score\": 0.5622973, \"raw_content\": null}, {\"url\": \"https://koreascience.kr/article/JAKO201831342439555.pdf\", \"title\": \"[PDF] 에이전트 기반 모델링 및 네트워크 통신 환경을 고려한 UGV 효과분석\", \"content\": \"Figure 3은 모델 내에서 에이전트가 어떻게 구성되는. 지를 보여주고 있다. 전장을 의미하는 Main 에이전트와. 전장에서 활동하는 Unit에이전트, 그리고 Unit을 구성하.\", \"score\": 0.27478218, \"raw_content\": null}, {\"url\": \"https://bluedayj.tistory.com/631\", \"title\": \"LLM을 활용한 AI 에이전트 언어 상호작용 성능 혁신 가이드\", \"content\": \"특히 LLM(대규모 언어 모델)의 발전은 AI 에이전트의 언어 상호작용 능력이 비약적으로 향상되는 계기를 마련하였고, 이로 인해 기업들은 업무 효율성과 고객 경험을 동시에 개선할 수 있는 기회를 맞이하고 있습니다. 이처럼 Code Interpreter의 도입은 AI Agent가 사용자의 니즈에 대해 보다 유연하고 실질적인 해결책을 제공하는 데 중추적인 역할을 하며, 이를 통해 기업의 업무 효율성을 극대화할 수 있는 기회를 창출하고 있습니다. 이러한 AI 에이전트는 단순한 대화형 시스템을 넘어, 실제 업무를 수행하고 사용자 경험을 극대화할 수 있는 효과적인 도구로 자리 잡고 있습니다. AI 에이전트는 사용자의 다양한 요구를 처리하며, 그 과정에서 오류나 예외 상황이 발생할 수 있습니다. 이러한 성능 평가는 AI 시스템의 발전과 더불어 지속적인 개선이 필요하며, 이를 통해 효과적으로 사용자 요구에 부합하는 서비스를 제공할 수 있습니다. 설문조사나 피드백 수집을 통해 AI 사용 후의 경험을 분석하면, 사용자들이 느끼는 만족도를 정량화할 수 있습니다.\", \"score\": 0.15878677, \"raw_content\": null}, {\"url\": \"https://newrelic.com/kr/resources/ebooks/devops-maturity-phases\", \"title\": \"데브옵스 성숙도의 3단계 - New Relic\", \"content\": \"SLO는 서비스 수준 표시기(SLI)라고 하는 정해진 정량적 측정치에 대해 목표값을 정의합니다. ... 환경 배포로 이동할 수 있는 프로세스를 구축하는 것\", \"score\": 0.094518974, \"raw_content\": null}, {\"url\": \"https://dataplatform.cloud.ibm.com/docs/content/wsj/model/wxgov-agentic-ai-evaluation-sdk.html?context=wx&locale=ko\", \"title\": \"에이전트 AI 평가 — Docs | IBM watsonx\", \"content\": \"에이전트 AI 평가 모듈은 에이전트 AI 도구의 성능을 측정하는 지표를 계산하여 사용 사례의 워크플로우를 간소화하고 위험을 관리하는 데 도움을 줍니다.\", \"score\": 0.06506231, \"raw_content\": null}], \"response_time\": 0.98, \"request_id\": \"ef10d327-718b-470c-808d-1c471dc8bb53\"}, {\"query\": \"도메인별 AI 에이전트 예시\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.scnews.kr/news/articleView.html?idxno=12056\", \"title\": \"2025년 AI, 도메인 특화와 에이전트 기술이 핵심 트렌드로 부상\", \"content\": \"뤼튼, 올거나이즈, 페르소나 AI 등은 AI 에이전트가 단순한 답변을 제공하는 챗봇을 넘어 복잡한 업무를 처리하며 B2C 시장에서 핵심 역할을 할 것으로\", \"score\": 0.61834323, \"raw_content\": null}, {\"url\": \"https://www.allibee.ai/blog/domain-specific-business-agent\", \"title\": \"비즈니스에 ChatGPT가 아닌 전문 AI 에이전트가 필요한 이유\", \"content\": \"법률 전문가처럼 생각하는 도메인 특화 AI 에이전트, 앨리비 도메인 특화 AI 에이전트는 이러한 도메인별 특성을 깊이 이해하고, 해당 분야의 전문가처럼 판단하고 응답할 수 있어야 합니다. | 비교 항목 | ChatGPT (범용 AI) | 앨리비 비즈니스 에이전트 (법률 특화 AI) | ## 법률 전문가처럼 생각하는 도메인 특화 AI 에이전트, 앨리비 뿐만 아니라 기술적 측면에서 앨리비는 법률 특화 OCR, 청킹, 레이아웃 분석, 리걸 LLM 등 다양한 기술을 유기적으로 통합하고 있기 때문에, 이러한 기술들이 단순히 '있다/없다'의 문제가 아니라 법률 도메인에 최적화되어 적용되고 있다는 점이 핵심이라고 할 수 있습니다. 그러나 앨리비는 **도메인 전문가와의 협업을 통해 도메인 특화 AI 에이전트 개발에 대한 노하우**를 지니고 있으며, 이렇게 개발한 다양한 AI기술을 비즈니스 에이전트와 같은 실제 서비스에 녹여내 활용하고 있습니다.\", \"score\": 0.585789, \"raw_content\": null}, {\"url\": \"https://clickup.com/ko/blog/456142/ai-agents-examples\", \"title\": \"산업을 변화시키는 12가지의 강력한 AI 에이전트 예시 - ClickUp\", \"content\": \"산업별 AI 에이전트 예시 · 1. 고객 지원 · 2. 영업 팀 · 3. 마케팅 · 4. 운영 · 5. 채용 · 6. 코딩 · 7. 개인 생산성 · 8. 금융.\", \"score\": 0.5476824, \"raw_content\": null}, {\"url\": \"https://aisparkup.com/posts/2148\", \"title\": \"2025년 주목해야 할 7가지 AI 에이전트와 멀티모달 트렌드\", \"content\": \"이러한 Super General AI 에이전트들은 복잡한 작업을 자율적으로 수행하고, 다양한 도메인에서 맥락을 이해하며, 최소한의 인간 개입으로 변화하는 환경에 적응할 수 있는 능력을 갖추고 있습니다. 최신 AI 에이전트는 기존의 일반적인 AI 어시스턴트와 달리, 단순한 명령-응답 상호작용을 넘어 확장된 세션에서 맥락을 유지하고, 여러 기능을 조정하며, 복잡한 작업을 완료하는 데 더 큰 자율성을 보여줍니다. Devin은 소프트웨어 개발 분야에 특화된 AI 에이전트로, 코드 작성, 테스트, 디버깅, 리팩토링 등의 작업을 자율적으로 수행할 수 있습니다. 텍스트뿐만 아니라 이미지, 오디오, 비디오 등 다양한 형식의 데이터를 처리하고 통합할 수 있는 멀티모달 AI 에이전트가 주류로 자리잡고 있습니다. 특히 멀티모달 AI 에이전트의 부상은 텍스트뿐만 아니라 이미지, 음성, 영상 등 다양한 형태의 데이터를 종합적으로 이해하고 처리할 수 있는 능력을 통해, 더욱 풍부하고 인간적인 상호작용을 가능하게 할 것입니다.\", \"score\": 0.52962893, \"raw_content\": null}, {\"url\": \"https://www.aitimes.com/news/articleView.html?idxno=166545\", \"title\": \"\\\"2025년은 멀티모달·RAG가 핵심...도메인별 전문 모델 대세될 것\\\" - AI ...\", \"content\": \"국내도 AI 비즈니스 이슈가 진화한 것으로 볼 수 있다. 우선, 뤼튼은 B2C 서비스에서 AI 에이전트가 기존 답만 내놓던 챗봇을 넘어 각종 업무를 처리해 줄 것으로 봤다. 하지만 실제 현장에서는 아직 구체적인 사례가 적은 AI 에이전트보다 멀티모달이 더 큰 영향을 줄 것으로 예측했다. * [[2024 결산] (1) 뤼튼과 제타, AI 'B2C 서비스' 본격 확대한 주인공](https://www.aitimes.com/news/articleView.html? * [[신년사] 이창수 올거나이즈 대표 \\\"에이전트 AI에 RAG 접목해 출시 예정 \\\"](https://www.aitimes.com/news/articleView.html? * [[신년사] 슈퍼브AI “엣지·멀티모달 강화로 AI 올인원 솔루션 지원할 것”](https://www.aitimes.com/news/articleView.html? * [[신년사] 윤성호 마키나락스 대표 “산업 특화 AI 선두 지킬 것”](https://www.aitimes.com/news/articleView.html? * [[신년사] 한국딥러닝 “비전 AI 기술 고도화…B2B·B2G 맞춤형 AI 도입 지원”](https://www.aitimes.com/news/articleView.html? * [[신년사] 김세엽 셀렉트스타 대표 \\\"AI 신뢰성 평가 중심 토털 서비스 기업으로 성장할 것\\\"](https://www.aitimes.com/news/articleView.html? #AI\", \"score\": 0.5230555, \"raw_content\": null}], \"response_time\": 1.07, \"request_id\": \"ed05eba5-f60c-4444-9f4f-8f82c1aced7f\"}]\n",
            "Step 5\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  ReviseAnswer (call_13jh0CCs37O2CCNkZmf88r1q)\n",
            " Call ID: call_13jh0CCs37O2CCNkZmf88r1q\n",
            "  Args:\n",
            "    answer: Reflect: 원래 질의는 AI 에이전트의 정의였다. 이전 답변은 기본 개념은 다루었으나 수식적 정의[1], 도메인별 구체 사례[2], 안전/윤리의 정량 프레임이 부족했다. 보완하겠다.\n",
            "    search_queries: ['합리적 에이전트의 수식적 정의', '에이전트-환경 루프 정량 모델', '도메인별 AI 에이전트 예시']\n",
            "    reflection: {'missing': '수식화된 정의, 정량적 성능 척도 예시, 안전/윤리 프레임의 수치화', 'superfluous': '일반 설명은 충분했으나 세부 학습/추론 메커니즘 심화는 제외'}\n",
            "    references: ['https://brainpod.ai/ko/%ED%95%A9%EB%A6%AC%EC%A0%81-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-ai%EC%9D%98-%EC%A3%BC%94%EC%9A%94-%EC%9C%A0%ED%98%95-%EC%B0%A8%EC%9D%B4%EC%A0%90-%EB%8C%80%EB%8B%AC%EB%A5%BC-%EC%97%B0%EA%B5%AC/', 'https://ai-ceo.com/blog/what-is-ai-agents/']\n",
            "Step 6\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: ReviseAnswer\n",
            "\n",
            "[{\"query\": \"합리적 에이전트의 수식적 정의\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://blog.naver.com/jaeyoon_95/221096281001\", \"title\": \"[인공지능 기초]2.Intelligent Agents : 네이버 블로그\", \"content\": \"합리적 에이전트(Rational Agent)​​ 즉, 행동을 하기 전에 어떤 행동이 가장 좋은 결과를 가져올지 매 순간 선택합니다. (기준은 행동을 하기 전 상황입니\", \"score\": 0.81097376, \"raw_content\": null}, {\"url\": \"https://startagainbornagain.tistory.com/65\", \"title\": \"스튜어드 러셀의 인공지능을 읽어보자(3) : 지능적 에이전트?\", \"content\": \"합리적 에이전트(rational agent)는 옳은 일(right thing)을 하는 에이전트입니다. 개념적으로 말하자면. 에이전트 함소 표의 모든 항목이 정확히 채워진\", \"score\": 0.79369855, \"raw_content\": null}, {\"url\": \"https://velog.io/@eunaahn/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EA%B3%BC-%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5-\", \"title\": \"인공지능과 기계학습 - Rational Agent\", \"content\": \"합리적 에이전트라고 하며 최상의 결과를(불확실성이 존재할 경우에는 기대할 수 있는 최상의 결과를) 내도록 행동하는 에이전트이다. Percept. 어떤 순간\", \"score\": 0.78214747, \"raw_content\": null}, {\"url\": \"https://eastk1te.github.io/posts/AI(1)/\", \"title\": \"[Study]Chapter 1 & 2, 지능적 에이전트 - Eastk1te\", \"content\": \"합리적 에이전트의 정의→ 각각의 가능한 지각열에 대해, 합리적 에이전트는 자신의 지각열과 에이전트의 내장지식이 제공하는 증거에 기초해서 성과\", \"score\": 0.6994397, \"raw_content\": null}, {\"url\": \"https://coreeny.tistory.com/147\", \"title\": \"[인공지능] 3주차 - 인공지능의 발전과정, 지능형 에이전트\", \"content\": \"▷ 합리적인 에이전트 · agent는 현재까지의 인식된 정보 순서에만 의존(정보수집), 입력 정보에 대한 결과는 몰라야 함 · 즉 agent는 학습을 통해 결과를\", \"score\": 0.6222074, \"raw_content\": null}], \"response_time\": 1.03, \"request_id\": \"f552663f-cea7-4ec8-97b3-3ba4f414e367\"}, {\"query\": \"에이전트-환경 루프 정량 모델\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://blog.naver.com/oaziz/223507964894\", \"title\": \"게임 시뮬레이션 환경(Gymnasium)에서 Agent와 환경의 상호작용\", \"content\": \"에이전트-환경 상호작용 루프. 에이전트는 환경에서 상태를 관찰하고, 그에 따라 행동을 선택하며, 그 결과를 반영하여 학습하는 과정을 반복. 상호작용\", \"score\": 0.5760895, \"raw_content\": null}, {\"url\": \"https://wikidocs.net/198338\", \"title\": \"A_04. Intelligent Agents from Wiki - B. Artificial intelligence - 한글\", \"content\": \"무한 루프는 부분적으로 관찰 가능한 환경에서 작동하는 단순 반사 ... 모델 기반 에이전트는 부분적으로 관찰 가능한 환경을 처리할 수 있습니다.\", \"score\": 0.40471974, \"raw_content\": null}, {\"url\": \"https://wikidocs.net/286004\", \"title\": \"01-03. 인간의 뇌를 닮은 AI, 가능한가요? - 위키독스\", \"content\": \"즉, '에이전트 루프(agent loop)'는 AI가 주변 환경과 상호작용하고, 내부 정보를 바탕으로 다음 행동을 결정하며, 그 결과를 반영해 또다시 학습하는\", \"score\": 0.34112197, \"raw_content\": null}, {\"url\": \"https://developer.nvidia.com/ko-kr/blog/build-your-first-human-in-the-loop-ai-agent-with-nvidia-nim/\", \"title\": \"NVIDIA NIM으로 첫번째 휴먼 인더 루프 AI 에이전트 구축하기\", \"content\": \"콘텐츠 크리에이터 에이전트는 NVIDIA LLM NIM 마이크로서비스로 가속화된 Llama 3.1 405B 모델을 사용합니다. 안정적이고 체계적인 결과를 보장하기 위해\", \"score\": 0.25571102, \"raw_content\": null}, {\"url\": \"https://discuss.pytorch.kr/t/ai/4327\", \"title\": \"추론, 계획 및 도구 사용을 위한 AI 에이전트 구조에 대한 서베이 논문\", \"content\": \"특히 에이전트 시스템에는 계획, 루프, 반영 및 기타 제어 구조라는 개념이 있어 모델의 고유한 추론 기능을 크게 활용하여 엔드투엔드 작업을 수행할 수\", \"score\": 0.18639141, \"raw_content\": null}], \"response_time\": 1.02, \"request_id\": \"2d94b802-52df-4f5f-987a-fb5d8c506eb3\"}, {\"query\": \"도메인별 AI 에이전트 예시\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.scnews.kr/news/articleView.html?idxno=12056\", \"title\": \"2025년 AI, 도메인 특화와 에이전트 기술이 핵심 트렌드로 부상\", \"content\": \"뤼튼, 올거나이즈, 페르소나 AI 등은 AI 에이전트가 단순한 답변을 제공하는 챗봇을 넘어 복잡한 업무를 처리하며 B2C 시장에서 핵심 역할을 할 것으로\", \"score\": 0.61834323, \"raw_content\": null}, {\"url\": \"https://www.allibee.ai/blog/domain-specific-business-agent\", \"title\": \"비즈니스에 ChatGPT가 아닌 전문 AI 에이전트가 필요한 이유\", \"content\": \"법률 전문가처럼 생각하는 도메인 특화 AI 에이전트, 앨리비 도메인 특화 AI 에이전트는 이러한 도메인별 특성을 깊이 이해하고, 해당 분야의 전문가처럼 판단하고 응답할 수 있어야 합니다. | 비교 항목 | ChatGPT (범용 AI) | 앨리비 비즈니스 에이전트 (법률 특화 AI) | ## 법률 전문가처럼 생각하는 도메인 특화 AI 에이전트, 앨리비 뿐만 아니라 기술적 측면에서 앨리비는 법률 특화 OCR, 청킹, 레이아웃 분석, 리걸 LLM 등 다양한 기술을 유기적으로 통합하고 있기 때문에, 이러한 기술들이 단순히 '있다/없다'의 문제가 아니라 법률 도메인에 최적화되어 적용되고 있다는 점이 핵심이라고 할 수 있습니다. 그러나 앨리비는 **도메인 전문가와의 협업을 통해 도메인 특화 AI 에이전트 개발에 대한 노하우**를 지니고 있으며, 이렇게 개발한 다양한 AI기술을 비즈니스 에이전트와 같은 실제 서비스에 녹여내 활용하고 있습니다.\", \"score\": 0.585789, \"raw_content\": null}, {\"url\": \"https://clickup.com/ko/blog/456142/ai-agents-examples\", \"title\": \"산업을 변화시키는 12가지의 강력한 AI 에이전트 예시 - ClickUp\", \"content\": \"산업별 AI 에이전트 예시 · 1. 고객 지원 · 2. 영업 팀 · 3. 마케팅 · 4. 운영 · 5. 채용 · 6. 코딩 · 7. 개인 생산성 · 8. 금융.\", \"score\": 0.5476824, \"raw_content\": null}, {\"url\": \"https://aisparkup.com/posts/2148\", \"title\": \"2025년 주목해야 할 7가지 AI 에이전트와 멀티모달 트렌드\", \"content\": \"이러한 Super General AI 에이전트들은 복잡한 작업을 자율적으로 수행하고, 다양한 도메인에서 맥락을 이해하며, 최소한의 인간 개입으로 변화하는 환경에 적응할 수 있는 능력을 갖추고 있습니다. 최신 AI 에이전트는 기존의 일반적인 AI 어시스턴트와 달리, 단순한 명령-응답 상호작용을 넘어 확장된 세션에서 맥락을 유지하고, 여러 기능을 조정하며, 복잡한 작업을 완료하는 데 더 큰 자율성을 보여줍니다. Devin은 소프트웨어 개발 분야에 특화된 AI 에이전트로, 코드 작성, 테스트, 디버깅, 리팩토링 등의 작업을 자율적으로 수행할 수 있습니다. 텍스트뿐만 아니라 이미지, 오디오, 비디오 등 다양한 형식의 데이터를 처리하고 통합할 수 있는 멀티모달 AI 에이전트가 주류로 자리잡고 있습니다. 특히 멀티모달 AI 에이전트의 부상은 텍스트뿐만 아니라 이미지, 음성, 영상 등 다양한 형태의 데이터를 종합적으로 이해하고 처리할 수 있는 능력을 통해, 더욱 풍부하고 인간적인 상호작용을 가능하게 할 것입니다.\", \"score\": 0.52962893, \"raw_content\": null}, {\"url\": \"https://www.aitimes.com/news/articleView.html?idxno=166545\", \"title\": \"\\\"2025년은 멀티모달·RAG가 핵심...도메인별 전문 모델 대세될 것\\\" - AI ...\", \"content\": \"국내도 AI 비즈니스 이슈가 진화한 것으로 볼 수 있다. 우선, 뤼튼은 B2C 서비스에서 AI 에이전트가 기존 답만 내놓던 챗봇을 넘어 각종 업무를 처리해 줄 것으로 봤다. 하지만 실제 현장에서는 아직 구체적인 사례가 적은 AI 에이전트보다 멀티모달이 더 큰 영향을 줄 것으로 예측했다. * [[2024 결산] (1) 뤼튼과 제타, AI 'B2C 서비스' 본격 확대한 주인공](https://www.aitimes.com/news/articleView.html? * [[신년사] 이창수 올거나이즈 대표 \\\"에이전트 AI에 RAG 접목해 출시 예정 \\\"](https://www.aitimes.com/news/articleView.html? * [[신년사] 슈퍼브AI “엣지·멀티모달 강화로 AI 올인원 솔루션 지원할 것”](https://www.aitimes.com/news/articleView.html? * [[신년사] 윤성호 마키나락스 대표 “산업 특화 AI 선두 지킬 것”](https://www.aitimes.com/news/articleView.html? * [[신년사] 한국딥러닝 “비전 AI 기술 고도화…B2B·B2G 맞춤형 AI 도입 지원”](https://www.aitimes.com/news/articleView.html? * [[신년사] 김세엽 셀렉트스타 대표 \\\"AI 신뢰성 평가 중심 토털 서비스 기업으로 성장할 것\\\"](https://www.aitimes.com/news/articleView.html? #AI\", \"score\": 0.5230555, \"raw_content\": null}], \"response_time\": 1.24, \"request_id\": \"0756db08-9df8-4057-bae9-1f2669cb04af\"}]\n",
            "Step 7\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  ReviseAnswer (call_WHONoiKgm3waYGyxtCWqlzUk)\n",
            " Call ID: call_WHONoiKgm3waYGyxtCWqlzUk\n",
            "  Args:\n",
            "    answer: Reflect: 원래 질문은 AI 에이전트의 정의였고, 핵심은 환경 감지-행동 루프와 합리적 에이전트의 목표 최적화였습니다. 다만 수식적 정의와 안전/윤리 프레임, 도메인별 구체 예시가 부족했습니다. [1] [2]\n",
            "    search_queries: ['합리적 에이전트 수식적 정의', '에이전트-환경 루프 정량 모델', '도메인별 AI 에이전트 예시']\n",
            "    reflection: {'missing': '수식적 정의, 정량적 성능 척도 예시, 안전성/윤리 프레임의 구체적 수치화', 'superfluous': '학습/추론 메커니즘의 구체적 심화 내용은 현재 필요하지 않음'}\n",
            "    references: ['https://brainpod.ai/ko/%ED%95%A9%EB%A6%AC%EC%A0%81-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-ai%EC%9D%98-%EC%A3%BC%94%EC%9A%94-%EC%9C%A0%ED%98%95-%EC%B0%A8%EC%9D%B4%EC%A0%90-%EB%8C%80%EB%8B%AC%EB%A5%BC-%EC%97%B0%EA%B5%AC/', 'https://ai-ceo.com/blog/what-is-ai-agents/']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plan & Execute"
      ],
      "metadata": {
        "id": "GXCfP7txIJHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")\n",
        "_set_env(\"TAVILY_API_KEY\")"
      ],
      "metadata": {
        "id": "yowKBiuJIOE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FxoH28A7IcSb",
        "outputId": "c8d73866-0c76-41e1-8630-3a2377e08de9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.3.29)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.76)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.24)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.24.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults"
      ],
      "metadata": {
        "id": "hMK229_fIqEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_tool = TavilySearchResults(max_results=3)\n",
        "tools = [search_tool]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZM1UQewI0hU",
        "outputId": "6992360e-da20-4b64-9255-3f99bcd15e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3618365131.py:1: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  search_tool = TavilySearchResults(max_results=3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsJON7eiJEPD",
        "outputId": "f9f5492f-401d-418f-e958-68cf609bc480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.12/dist-packages (0.3.33)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.76 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.3.76)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.106.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.4.24)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (25.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (2.11.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.104.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.76->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBbPAJaJJG-m",
        "outputId": "5087c6f4-062a-49e1-a956-6282f7058248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (0.6.7)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.76)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.1.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.6.4)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.6)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.24)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.24.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ReAct 패턴\n",
        "# 추론 -> 행동 -> 관찰 -> 답변, 자동으로 생성\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-5-nano\")\n",
        "prompt = \"You are a helpful assistant.\"\n",
        "plan_executor = create_react_agent(llm, tools, prompt=prompt)\n",
        "plan_executor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "O0yVOW-iJNam",
        "outputId": "d6ab3b65-24d0-42b7-baa3-1200686bba38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x7b5640929fd0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAD5CAIAAADKsmwpAAAQAElEQVR4nOydB2AUxf7HZ/dKyqX3hBCSEBJ6M4CiFAFRH2BA8SFNwEcRBPEvRd8DAfEpIKKiIkVAQEqUTiBSRAia0Hl0CZAQSEIKIfUu5XK3+//tbnK5JHeBYG4zezcf4Nidmd1L9r43M7/fzPxGzrIsIhAaGzkiEDCACJGABUSIBCwgQiRgAREiAQuIEAlYQIRYkwep5Zfi8wqyy8tKGECvRZQcsTpE0YiFPwxFUQx3wsM5v1gKwR8KsQxCNBxyByzF0hTFpVDgHaO4XOFauiIX/tBypNcxFOJuBel6hoWrhQLcjeGe8E94F5qlGKrqR6x8FwN2KplMhuydZf4hjpF9XZEEoYgfUSDtZtmJ3dn5OVoQBy2jHFRyhR0tkyNdGUMrKKac5bUH2mI5HfDKEnTIHdDcOSgDLoQkQSIUXVmYL0Lx11bojC9Oyym9nqVYQ2HuhpUFuFsyTMVHQ1OIMfqU+K8EQtWEKNeVseVlevjy6HSs3I4ObO4w4F9+SDoQIaKsu9qYtffLinUevnbtnnFt28MFSRoGHduec+e6ukSj9w2yH/puEyQFbF2IO5bfz7xX3KyV86Dxvsi6yEnXHVifVlyk7/26b6suTghvbFqIq/+d7OAgf3NeELJerp1S/7ErKzDcceB4f4QxtivEtXOSm4SpXh5nbRWhSdbOvdOlv0eHnvjaMTYqxFUfJIV1cOk3whvZDD/MveMTaB/1Nqb1Io1sj/XzU5q1dLIpFQIT/huSnVYav+8hwhKbE+LeVRnwaiMtcg0mLAi5GJdv7PfBBxsToh6l3dK89XEwsk3kKDDMYf2COwg/bEuImxbd8wp0QDZM1OQA8C/ePK9GmGFbQizM1Q6TiIPXcjRp7hi/Lwdhhg0Jcd+qDAdHOZIhMfnwww/37t2L6s8LL7yQnp6OLMCg8QHFaj3CDBsSYnZaWbO2KiQu169fR/UnIyMjLy8PWQaZEintqKPReFWKNiTEslJ95PMeyDLEx8dPmjTpueeeGzx48Pz583NyuI85MjLy/v37n3zySe/eveFUrVavWrVqzJgxQrGvvvqqtLRUuLxv377btm2bMGECXBIXFzdo0CBIjIqKmjFjBrIAbj52GckahBO2IsSky8U0hdx8LdIw37hxY/r06V26dNmxY8fs2bNv3ry5YMECxKsTXj/66KPjx4/DQXR09IYNG0aPHv31119D+SNHjqxZs0a4g0Kh2L17d0RExIoVK5599lkoAInQpi9btgxZAN9m9iXFeHlxbGU+YsadEpmCQpbh4sWL9vb2b731Fk3Tfn5+rVu3vn37du1io0aNgpovJCREOL106VJCQsK7776L+BmLrq6uM2fORKLgG2R37SQRYmNQomHkcksJsWPHjtDIvvfee926devZs2fTpk2hha1dDKq9kydPQsMNVaZOp4MUD4+qrgLIF4mFh5eSZfAa2rWVppllGL3FHn3Lli2/+eYbb2/vb7/9dsiQIVOmTIHarnYxyIW2GArs2bPn3Llz48aNM85VKpVINOQybvItTtiKEB1Ucpa14KPv3r079AVjYmKgd1hQUAC1o1DnGWBZdufOncOGDQMhQvMNKUVFRaiRyM8u5WaJ44StCNG3qT2jt1SNeP78eejtwQFUigMHDgRTF0QGLhjjMuXl5SUlJT4+PsKpVqs9ceIEaiSyU8tkciLExiA8UqXTMtpii2gRGmIwlnft2gXOv6tXr4J1DIr09/e3s7MD5Z06dQoaYrBjgoOD9+3bl5aWlp+fv3DhQuhZFhYWajQm3ChQEl7BrIa7IQsAppvSAa+P3ob8iHIlffpQLrIAYA5Dg/vFF1/AcMjEiRNVKhX0BeVyzhAEU/rs2bNQR0J1+Nlnn4FxPXToUHAidu3aderUqXDar18/8DXWuGFgYCC4EsHpCN1KZAHys7V+Te0RTtjQxNifl6UWF+nGLQhBNs+3/3frXx83d3TBqBqyoRrxhZG+6gIdsnlif8xQ2NFYqRDZ1AJ7Dz+lvaNs76r7UW8HmCyg1+vB4WwyC2wL8AJSpizN0NDQ9evXI8uwgcdklpOTE4wZmsxq06YNjNAgM9z9q/ipPpYa6nxibGvNStqt0r2r0t5ZFmauQO3umgB85PDBm8yCvqDBFm5winhMZoELHbqYJrPgOwPWksmsI1uyk68UTVrcHGGGzS2e2rYkVa9nR/3HmpeQ1sGKmUmvTm7m3xy7ltDm1qwM/6Cppkh35pClJlnhzIaPU5qGqzBUIbLNVXyTFoWe/S23MNu2moKtS9LkCvqViZgGxLHdBfbQSL3whn94pCOyATZ+cs8zQDkQ47BMNh1y5PuZSQHBDoOnBiCrZt28FAcn+YjZgQhjbD0I048LUsqK9d1e9u70vMSDgJli36qMe7c04Z1c+o+ylF3fUJCwdChh38PL8fnwFEJaO/Uf7kuLOBvLQiRd1EAnODdb6+yqGP1hkMjrxZ4MIsQKju94cPuSulStp2SUykWucpWrnOS0nCnXVj0fmuYDZho9MFqGGMOCOIoP4InYqliufEBO4X9EVcV4lcm4EJ3cgZzW6xjD5cKdKwqz/MVsZcBPPoN3qMMpY5TIXaVQ0DodKinUgUOgRMPAdS6eit6v+TRpgdeAch0QIdbkz70P05OKSwr18NEyDKvXVT2fSl1VQckQa7Qyk4tqjGhDGe7hVg7GGK5lGEZG00IRCspWxiSu1CEX5JiTnHAtCJE/4guwvEgZlqWpal8HpFDS8JWwc6CdPZQRnZwisI+GWBsiRLGZNm3aiBEjnnnmGUQwggRzFxudTifMECMYQ56I2BAhmoQ8EbEhQjQJeSJiU15erlAoEKE6RIhiQ2pEk5AnIjZEiCYhT0RsiBBNQp6I2IAQSR+xNkSIYkNqRJOQJyI2RIgmIU9EbIgQTUKeiNgQIZqEPBGxAYc2EWJtyBMRFW5XcYbhtpsnVIcIUVRIu2wO8lBEhQjRHOShiAqZ8WAOIkRRITWiOchDERUiRHOQhyIqRIjmIA9FVIgQzUEeiqgQY8UcRIiiQmpEc5CHIjbmYrnaOESIogKDe5mZmYhQCyJEUYF2ucbWaAQBIkRRIUI0BxGiqBAhmoMIUVSIEM1BhCgqRIjmIEIUFSJEcxAhigoRojmIEEWFCNEcRIiiAkLU6/WIUAtb3HmqcYHBFaLF2hAhig1pnU1ChCg2RIgmIX1EsSFCNAkRotgQIZqECFFsiBBNQoQoNkSIJiE7T4lEx44dabrCNIRnDsfwOnDgwIULFyICsZpFo3379ojbVpIDXIkURfn7+48aNQoReIgQReLNN99UqVTGKR06dAgPD0cEHiJEkejXr5+x7Dw9PYcPH44IlRAhisfYsWNdXFyE45YtW7Zr1w4RKiFCFI8ePXpERETAgaur68iRIxHBCGI110KPTuzL0xRqdVo9vyk9t/M8Led3qmf5Pef1TOUBCwYwLaegAMuwXArDIIbLYhiG26+eQvyu4NxDhjuwDJWXm3f12lWVyqFz50hhC3qZnGL4y+GYlkHJimPutPLOwimUNN7FvMYpoHSQ+zV16NDLGUkQIsRq/LIsPSerVKGUwcevL2d5JXEbyNMybjd7BAeVigTRMHpOa5DFyYUVxMqXqSwsyJDlnjKnKr1eT7E0KBSMZs6Hw3DNEXc5vBl/TNG8a4et2NOe064eGT4fmQwZz9rh3qX6JB6lPUiTu0HfYX5hnRyRpCAO7Sr2rr5fXMiMntMcSZmki+rforNopW9oGylpkdSIFexafr9YrY+a2hRZBZs/TR41K9RZOtFNiLFSQWZaad+Rgcha8PKzj1mXiqQDESLH1T+KZHLk5E4ha8E/1FFTKKURbdJH5IBGmSlH1oS9iirXSmlBAhEih47R6Rmr6itDzx+8QhKCCJGABUSIBCwgQuSgrM6FxdIwJiQl24sIkYeW1If2OLD86I50IELkYK3OrQ91vLS+W0SIHBRN0TQZYWpMiBA5uFkHjFU1zty3itSIhEaHE6GkqngiRB5rM1WkBxEiBw1ms3WNunNzGkmNKDkYlp9QbU2wpI8oQaTl+30cuApeUr8TmQbGw4LNjG9LtnvPL4uWzK/XJYghTbMEYXkHMMKVxMTryNohQuSg6XobK2q1evuOzWfOnkxJSfL08Orevddb4ybb29tDFsMwy79Z8mf8caVC2bfvS23bdPj3nPd2bj/k4eGp0+nWrf/+1Ok/s7Mz27btOCTqn08//Zxww8Gv9hs39u2CgvyNm9Y4ODh0iXxm6jszPT293nt/4qVLF6DA4cMHYvYed3JyQtYIaZo5uCG+eo7M7todvXXbhmH/HP3Zp19PmjT9eNwREJCQtX3Hlpj9u6ZNnbVq1WYHB0dQHuK1Dq/ffPv5jp1bhwwetnVLTK+efed/PDvuxFHhKoVC8fPPm6DYnt1HN/6488rVixs2rob0r79c06pV2/79Bxw7eu7xVchKq2EmNaIAP9Rcv6b5n6+PAiU1axYinF69eunM2YRJE9+F40OH9/fs0ad3r35wPHLEOEgXypSVlUHWiOFjXxn0Gpz+4+UouGrTTz/AfYQCTZo0HTXyLe7IyRlqxJs3/0JPCiU11ygRIg9V7ykCUIGdPXdy8ZL5t5NuCvEO3d094FWv16ekJL/80iuGkj179L18+X9wAMLSarWgMENWxw5P/XpwX0FhgauLK5yGh7cyZDk7u2g0amQzECHysKi+82/W/PBtbOweaJRBWL6+fmvXrYj9dS+kqzVquJWjY1XgL1dXN+FArS6C12nT/1XjVnm5DwUhWp8X6fEhQuSgOQnUQwQgtZj9O4e+NmLggCFCiiAywNGBW9ZeXl61Fisv76Fw4OnFLTOe8f4caIKN7+bj44caGslNayNC5ODjfNTjo4P2t6SkxMvLRziFBjfh5AnhGJpsHx9fMKUNheMT4oSDwCZBdnZ2cNCpY6SQkpeXy1efFgjJIDUrlFjNHJwG2XrUiHK5PCgoGLp36ffTwOHy+RcL27XtWFRUqNFoILf7Mz0PHzlw9twpEBlY0JAuXAWCGztmElgnV65cBO2CvTxz9pSvly9+5NtBDfrXX1cv/O+scUVbN5Jb/ECEyEFR9e6efTTnM3s7+7Hjho56c/BTnbuOHz8VToe81i8j8/6YNye2a9dp9gdTR7855O7dO9CCI067Cnh9Y9ibs2bO2xq9YVBUb/A1BvgHzpgx95HvNWjAq/DzzZr9TnGxBlkpJPYNx8nYnAu/Fbw5v2HCL5WWloK/GqpM4TT6501btqyP2XcciciN0wWnDz6Y+mUYkgikRqyk4QxWUN7Et0fu3BUNrfbvxw7/sn3zK68MRYQ6IcYKBzfQ3HANw9gxEwsK8g4f3v/D2m+9vX1hHAXc2khcqqIsSgQiRA4KNfCkqenvfoAaFehTSqvLRYTIwyCG9JUbFSJEDkpGyWiybqUxIULkYDgQoREhQuSguRX21hWWDkkMIkQOfvGUVTXNNfCzegAAEABJREFUnH+eLJ6SHNwEbSvzqLJkzYoEkVx81UdC/IiShPvYrCtGIvEjShIuPKKVhXqQGkSIHEz9F08RGhYiRA6lUq6wty6HNo0UChmSDqQ94ghs7shIaXecR5OfUS6trxYRIodfqFKppM/+moushbQkdUColDaFJEKs4KUxAYkX8pBVcHB9BnR5Xxrjg6QDmaFdQUlJyfvT57RzfcfTzz64pYuditVV9yxyO4gbPyrWEJaVqhGLsGZJIZEvW8O5VyPRcJ9q6ZVr/6nKQxgDMumbkdOyhxna1MRCpaNsxGyJbXBJhFjBTz/91KZNm85tO0cvTy3K1Wl1DGO0P7wwYdHwqIwUw9aI3kTxIeEM7nFjbdUWq2EepHDnisSKN6oWfKJ23E2D3A1ZCjtKoZCXy7LavVDeokULHx9SI0qH3Nzc5cuXf/zxx0gspk+fPmzYsO7duyMLsG7dujVruBhOzs7OLi4uQUFBHTp0CA8P79y5M8IbW3ffzJ07F5SBRMTLy0ulUiHLMHLkyAMHDty7d0+tVqenp9+4cePIkSNubm7wjnv37kUYY6M1YmZm5unTp6OiopDVsWrVqrVr19ZIhE/5/PnzCGNs0WouKCgYP378008/jRoD+A6UlZUhizF06NAmTZoYp9jZ2WGuQmRrQszIyIAGS6fT7d+/39fXFzUGH3zwwe3bt5HFgKb/ueeeMzR0cLBo0SKEPTYkxEuXLk2cOBE+J09PT9R4wBfAIsFujBg+fLi3NxfwSWiR9+zZs3LlSoQ3NiHErKwsxMfJjImJEcIgNSKff/55SEgIsiSBgYGRkZEMw/j5cXHGvvzySxg4mjZtGsIY6zdWwFr8/fffwUeD8AD6BlApyuUW91f079//8OHDhtOTJ0/OmTNn06ZNIFOEH9ZcIxYWcmG4iouL8VEhMHny5OzsbGR5jFUIPPPMM9BGT5069dChQwg/rFaI69evj42NRXyHCeEENJfgcEaNAbi4QYsnTpz46quvEGZYYdNcXl7+4MEDeOJTpkxBBFNs3boVuiu13Y2NiLUJER4u9I2g1oHuOcISGPaAXhrd2KsGwYfw9ttvb9y4EQYAEQZYVdO8Y8cO8BHCACu2KgRGjRpVWlqKGhsYg4Y2esGCBdB0IAywEiFu374dXvv06QPfcoQ3AQEBmHxPFAoFtNFXr1799NNPUWNjDUKcMWOG0MHw8PBA2BMdHS2C7+bxmTt3buvWrUeOHCnsFtNYSLuPeO7cOfDcgmeuxugqzty9e7dZs2YIMxITE8eMGbN69WposlFjINUaUavVwui+0OWXkAqhdwh1D8KPiIiIU6dOffPNN9u2bUONgSSFmJubm5OTs2zZMvzne9YA2p/Q0FCEK+vWrbt//z401kh0JNY0g/4mTJgAzmp3d3dEsAwHDx5cs2YNeHacnZ2RWEhMiLt27erSpUvTpk2RNNHr9RkZGXiO9hoDzk7oMi5evLhbt25IFKTRNCcnJ7/zzjtw8Oqrr0pXhQAM+eDvYALAF3vs2LFNmzZB44NEQRpChPGSefPmIelDURSGJrM5VqxYUVZWBt4xZHmwbpqvXbt2+fJl3GYt2BpxcXGLFi2C2tGi61PxrRHBNF66dOnAgQORFQFeJzBLkaTo1avX5s2bx44de+XKFWQx8BUiDD9s2LBBTMNNBEpKSubPny+5QQQvL6/Y2FjwMgpz3S0BpkLcsmXLmTNnkNXh6ur6/fffx8TESHE7jYsXL1puxRmmC+yzs7PrvXGtRFAoFK+88kpqaioMC0loTOjWrVthYRbc6xRTIYKBgtXMgAYHnFBRUVFbt261XNSHhgWE2KJFC2QxMG2a/fz8oF+CrJq9e/cmJiaq1WokBZKSkixaI2IqxN27d+/btw9ZOzBWnp6enpCQgLDH0k0zpkKEMWUYCkM2QERERHR0NP714u3bty0qREwd2jAUBnZlY0UFER9wLsLvi+0YdEFBAQyuHj16FFkMTGtEb29v21Eh4tcP5OXlNdZcwEdi6eoQYSvEQ4cO/fzzz8iWaNeuHdSL4PFG+GG7Qnz48KHkhsL+PsLimwsXLiDMsLTvBmErxBdffPGNN95Atoejo6O9vf1nn32GcAJqREsLEVOnceNGjmtcWrdufePGDYQTtts0x8XFbdy4EdkqYKLCKyaeVBiNBNvR0uH8MBUi+Avu3buHbBswX2bOnIkaGxE6iAjbprlnz56SW6HX4ISEhIwdOxY1NiK0ywjbGtHNzQ3/FUYi0LZtW3ht3ChyNi3EM2fO4B/2WTSgXmzEJVfiNM2YChHGXu/cuYMIPO7u7kuXLoUDQ3ial156adCgQcjylJWVZWdni7ByElMhRkZGCutHCQLCkgnweGs0moEDB+bk5MCQoAhBiEXwIApgKkQXFxcJLbsUjeXLl7/88suZmZmIX/5i0VkIApae/WUAUyFeu3Zt2bJliFCdYcOGFRcXC8cURSUmJgqitBziWCoIWyHC47bo9kxSZMSIEUlJScYpWVlZ4PlHlkQcSwVhK0QY5po1axYiGCFMWJTJZIYUrVZ75MgRZEksvULAAKYObZVKhXP4tkYhOjr6woULZ8+ePX36NHgVMjIyfFWd2UKPI7tu+gf4CZuHUzRimerbjPPHdW1CTlXuUc6ganugU0hdVBTs2SP1OpWKCqsKo5p7mLMUotnKtOo3p2nKJ9DOq8mjQzXjNUN7/Pjx8IjhR4KmubCwENwWUA3A8W+//YYIRvy4MLm4QA+y03P+nIqd7xH3wSNuwTTFcuoQZCPkcZ9zhcpqKRMyKP6/iqv4/yoW8xoSq5VECBnfgeLSTepIroB0SqGk2j/r3u0fbsg8eNWI0CJv3rzZsPUDuCoQP1sbEYxY82GydzOHoZP9Eb57J1TjWkLBlfhc/2C7oNZmdzrCq484atSo2iN7Xbt2RYRK1vwnuVUXz34jJKNCoE1312GzQmI3Zpw7XGCuDF5C9PHxGTBggHGKp6cnnkGnG4VfN2bLFbKO/VyRBGnVze1i3ENzudhZzcOHDzeuFDt27IjJ1kg4kHWv1MvfHkmTzn09ystZrZl1s9gJEcZUYBRViDfi4eExevRoRKikvEwnt5fw1jhgSOVkmV4dhuNvZagU2/IgQiU6LavTliPJwuhZxsyuQn/LataWoPj9Dx6kagvztOC+Ar3DOxlyaZplGCPvFcX7BShIrSxD834GI7Mf/BGIT+kdvEgfqJfL5Cs/SOb8D2y1yGCct4z7teCAqrob3E8GP4CJnxOqV4qm5TKk8pA3ae7QfaDtLojBlicU4sGNWfduaLRljExGy5VySi5T2ssZhmWNvJk0RTNstSiAgm/KoDyqpmdUcIix/DhqRTHeE1bL2cm7s3j3WDUd0xTFmHJnyeUykKu+TJebqcu6m3f+aK6jkzz8KZceg4kicaHeQjywPivlulomp529nMPbSGDvu9rotfq0a7mX48G5ld/5eben/yEZOUKVb61hI+snxNX/vgN1XLP2fk7eUrXdAJlS1qwT5yTPTi48f/Th1ZNF4z8JRlIAOh6S3juRa8do01+kxzVWUm+WfPt/t529VC17B0lahcb4hLq06RdCy2Tfz0xCBMvD9boY01+kxxJiwYPyvavSW/cNCWhthZ2q0G4BfuE+K4gWG5VHC/H2peItn6e2fSHEaP6RteHR1DG0S5AEtEgh6+whPo4QD228H9bV+ld2OrjQXs3cVn+YjHCGRRLuIdbJI4S4+j93nH2clE7WWxka4RvmRsnpLUtSEa5QlLTrRME1ZzKrLiHG7cxhdGxQBxuahRX+bNO8zLLMFExHL9iarn2JQdPI3M9flxCvJuR7h9jctsgqD4eYtWkIU6p78KUGNwZRX6s5fh83Y8cr2AVhycUrv838qJtak4campBIv1KNrvAhjjtDwdim+P7swa/22/TTWmRhzArxxtkilbsDskmU9oojW3Dc00AY/6zXJR8v/DD2170Ie8wKsUSj8w2z0aFYJx+nh5lahCFsvdcYJSZeR1LA9BDfjTNqaAIcXBXIMqTcu3z42NrUtOtOKvdWEc/1f368vT23E1j8qe1H4tZPfmvlpuh/Z2Un+/uG9ew+vEvnip1y9x/89tylWDulY6f2L/p4BSGL4R/qej01H0mf5/tGwuvSLz5ZueqrmL3H4Tg+Pm7jpjV3791xdXULC4uYPu0DX18/oXAdWQLwHdi5a9uhQ/tT0+42CwqJjHz6rXGTZfVxL3P9inpZzXeuq7lZU5Yh52Hq6g3TysvLpk5cO2bEkoysWyvXT9bzy9FkckVJSdGeA1/8c/B/li481b5tn1/2/DcvnwtmkHBmZ8KZHa8OmDV90o+e7gFHjq1DFoNW0rSMunleg3CD4ma+PX7xg7Hx8Dpr5keCCs+dPz1vwaz+/Qf8Eh07/6PFWVkZX3+zWChZR5aBXbuiN29ZP/S1EdFb9w8a9NqB2D3RP29C9YGrzdn6GCvqXL1cYak5sxcuHZTLFGOHL/H1DvbzCX09ak56RuLVvyoiFuj15S88P75Z03YURUV2HADfwvSMm5D+58lf2rfpC9J0dHSBOjIsNBJZElpGZ6eWIczgahPmya3m9T+u7NmjDygJ6rw2bdpPmfz+qVN/3uDb7jqyDFy6fCEiovWLLw50c3MfOGDIiu82dOv6LGogTKutXM+wFnOcQrvcNLC1SlWxytXD3d/TI/DO3YuGAkFN2ggHjg6czV5SWgRyzMlN9fUJMZQJDGiJLAm3tlqDXTeRZf7WyEpy8q2WLdsYTiPCW8PrjRvX6s4y0LZth/PnT3++dOHBQzEFhQVNAgLDwhpsOZHpPiL1d753j6KkVJ2afh2cL8aJhUVV67tqT7krLdMwjN7OztGQolRa1qKnuO8ofusoKlfNPwFqtbqsrMzOrmrmlKMj9zyLizV1ZBnfAepLR0dVfELcks8/lsvlvXu/MGnCu15eDTPeYVqICqWcQjpkGZydPUOadXyxz0TjRJWqriWS9nYq6LWVl5caUsq0xciSQE/GXoVfPBa24t8TYG/P6ay0tGrtkobXmaeHVx1ZxnegaRpaZPibkpJ84cKZDZvWaDTqz/5bj7DK3Ix6M31c08/a1VORk2GphinAt8X5S7GhwZ0MER0ys5O9PeuygqGOdHfzT7l3pVdln+SvxHhkSRiG9QvBb9olxT6xRxvqsIjwVteuXTakCMehzVvUkWV8B7CXw8NbhYQ0Dw4Ohb9F6qIDsbtRfaj3yErz9k6MzlJDC+CRYRhm369fabWl2Q/u7j/03bLvRmRkPSIIXYe2/a5cPwYDKnD8+x+b7qZdRRZDq9YjBoV1cESYQdVzoYCdnZ23t8+5c6f+d/GcTqcbMnjYn/HHd+7cVlhUCCnfr/yyc6cuLcIioGQdWQaO/n4QLOuEhBPQQQRT5o8/f2/bpgNqIEzXiKHtHUG8hTllLl4Nv80LmL0zp2499sdPX68ak/0gJSiwzeuD56IHC7gAAAR0SURBVDzS+OjXa5xGk7cndtnmX+ZAy/7Ky+9t3T7PQvPms+/kKexwXGjLrZOs5288csRbP25YdeZswrat+8E78yAn++ftP333/TLwEUY+9fSE8VOFYnVkGZjx/tzvVnwx56P3Ebfk3BPa6NeHjkINhFlP/cZP7upZWWgXf2R7JMal+gXbR73thzBj5eykJmEOzw8LQNJkw4LbQ95uEhhhwtA0+73v0MOtpBA7R5o4lGt1UZOwU6EVwBkrZvoWZg3Djr1dTx7IybiR69/S9JrR/IKsL74bYTLLwc6ppMx0jBM/79CpE39ADcfcT/uay4LRGpnMxC8YHNR+/Giztl7S6QwXNyW+00+lvJyUM1bMdC3q8lB0fdn79K8PzAnR2cnz/Sk/mcwCK0SpNG1y0nQD+0TM/Qzcj1FeplSY6OPKZXVFdCspLB23WIxgvU8AZS4gpvSpSxZP9XG58md+yrnM4EgT7RRUNh7ujd9Zadif4eafqU1bONK4hh7kImlIeoq2eR5hG46dFwQ1RH6GZb3HmJB+JQc8m1GT8TYFKCnP0Dbfs3i0k2Ly4uZp17KRtZPxV17hQw3mIR+EUNdIstCcsfLEkR5kaPLnza8euZObXoKslLTLOYXZhZOX4L6PAVcZSrll5vq3fyfSg0yGpn4ZlpmYBf1FZHUk/pGqyddMWiyV3TSs01ipx/jBlKXNEau7/ntKZmLDL1lqFO5efAA1vaubfNIiaaiQa9Zo6zRW6udMGTuv2elDeReP5+XeL3RwtvNu7uHkLp3g9pXkpasfphSUFmsdnORDJjVtEtHww5gWoo6mTRLwSwVMZ9Xbq9ftRXf4e+63/GsJBSnn0xE3vx88OTS39FtGGQfmNN5kptYpy8fYrDo1TLUz7EVDcZMiWVoINCvcAQk2I99lrwzjyZ1Xxo2l+Peg+dmUFa/8fkq0DN5JrtPq9Do9lIRizh6Kfm80CW4ruWWKrKTjI/JLBUxnPaF7ObKfG/yFg9v/Uydd1hTl69QF5dy0ZiMhQs9Sr2cNQV3Bk83oqoLFUiDdyjDDfGhZuiK9YtEkH5+YVxUf3oDiN+hi+eknQthiFjGUsOMX6IwLFAunMobVU5ScRXpuVy44FoIZyxWU0gGOFe4+jq26ujQJk25YPUrKFWJd/N1xjrBOTvAXEcSCslJjBdNNIQkmUShlcoWEA2LJ5RQXftlkFiJIB4U9VVaMYyyUx4RFVGCoaetWwrvH2CDBrZwfZkp1bl7Cvhw7BxkyU6ETIUqJXq95gDH3+1ZJjrjevVbY53Ufc7l47ddMeBw2/fceRdOdens1ayMB81+dz1747cHdG0Vj5garXM12cIkQJcn2r9NzM7V6HaM32uqLrdzYu14YNh1/LOoZjYyWcSFSYOCg/0jfgDq9ZkSIUkaLSkqq9nyrcHZX35GL5b38FSWMBxAMCE5/4028KKMRhqpEI8WyRimGXOGaGnKSyRwez7lHhEjAAuK+IWABESIBC4gQCVhAhEjAAiJEAhYQIRKw4P8BAAD//yZb3M4AAAAGSURBVAMAfz3rSoIOL84AAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plan_executor.invoke({'messages':[('user','2025년 한국의 최저 시급은 얼마입니까?')]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ubd7AUjKJXlL",
        "outputId": "65204a3d-2e81-43e6-eb94-da2fe438f38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='2025년 한국의 최저 시급은 얼마입니까?', additional_kwargs={}, response_metadata={}, id='5246eeea-30d5-45e2-a0eb-3b41f09ff31c'),\n",
              "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_vbkT3Uqz30VEyNN9hMiisgcT', 'function': {'arguments': '{\"query\":\"2025년 한국 최저 시급\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 418, 'prompt_tokens': 183, 'total_tokens': 601, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 384, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CFt3lmsjzUlOyhuF8XKrWERi71g8L', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--147f3583-f12b-4211-9a88-4476fcc44fbe-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': '2025년 한국 최저 시급'}, 'id': 'call_vbkT3Uqz30VEyNN9hMiisgcT', 'type': 'tool_call'}], usage_metadata={'input_tokens': 183, 'output_tokens': 418, 'total_tokens': 601, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 384}}),\n",
              "  ToolMessage(content='[{\"title\": \"2025년 최저시급 \\'1만 30원\\'\", \"url\": \"https://partner.yogiyo.co.kr/content/view/2025%EB%85%84_%EC%B5%9C%EC%A0%80%EC%9E%84%EA%B8%88_%EC%B5%9C%EC%A0%80%EC%8B%9C%EA%B8%89\", \"content\": \"2025년 최저시급이 10,030원으로 확정됐습니다.(2024년 최저시급 9,860원) 최저임금 제도가 도입된 이후 역대 두 번째로 낮은 인상률이지만 최저시급이 1만원을 넘은 건 처음인데요. \\u200b구인·구직 매칭 서비스 플랫폼 ‘급구’와 함께 2025년 직원들에게 지급해야 하는 최저임금과 아르바이트생 급여 관련 유의사항을 정리했습니다.\\\\n\\\\n  \\\\n※ 본 콘텐츠는 2024년 7월 기준으로 작성됐습니다. 정부 정책 및 법령 변경에 따라 일부 내용이 달라질 수 있으니 최신 정보인지 꼭 확인해주시기 바랍니다.  \\\\n  \\\\n  \\\\n  \\\\n  \\\\n\\\\n## 💰 최저시급 170원 상승 [...] 2025년 최저시급이 1만 30원으로 결정됐습니다.  \\\\n2024년보다 1.7%인 170원 오른 금액입니다.  \\\\n  \\\\n하루 8시간 근무하는 직원에게는  \\\\n일당 8만 240원 이상을 지급해야 합니다.  \\\\n  \\\\n직원이 주 5일 근무한다면  \\\\n주휴수당을 포함해 주급 48만 1,440원 이상을  \\\\n월급 209만 6,270원 이상을 지급해야 합니다.  \\\\n최저 월급은 2024년 대비 3만 5,530원 오른 금액입니다.  \\\\n  \\\\n  \\\\n\\\\n## 💰 일반음식점 평균시급 1만 2,350원\\\\n\\\\n  \\\\n실제 사장님이 직원에게 주는 평균 시급은 얼마일까요.  \\\\n  \\\\n급구의 연도별 데이터를 살펴보면  \\\\n한식당, 분식집 등 일반음식점 사장님이 등록한 [...] 본문 바로가기\\\\n주메뉴 바로가기\\\\n\\\\n## 자영업상식\\\\n\\\\n## 공지사항\\\\n\\\\n 민생회복 소비쿠폰 사용에 따른 음식점 운영 참고사항\\\\n 요기요앱 \\'밀키트\\' 카테고리명 변경 안내\\\\n 필수옵션그룹 내 메뉴 가격 설정 안내\\\\n 민생회복 소비쿠폰 사용에 따른 음식점 운영 참고사항\\\\n 요기요앱 \\'밀키트\\' 카테고리명 변경 안내\\\\n\\\\n이전 슬라이드;)\\\\n다음 슬라이드;)\\\\n\\\\n 전체\\\\n 메뉴관리\\\\n 주방\\\\n 마케팅\\\\n 위생/안전\\\\n 인력/노무\\\\n 손익/세무\\\\n 주문접수수단\\\\n 정책\\\\n 부동산\\\\n 배달관리\\\\n 매장관리\\\\n\\\\n닫기;)\\\\n\\\\n노무·세무\\\\n\\\\n# 2025년 최저시급 ‘1만 30원’\\\\n\\\\n## #급구 #2025년 #최저시급 #최저임금 #유의사항\\\\n\\\\n좋아요;)\\\\n공유;)\\\\n\\\\n## 2025년 최저임금과 임금 지급 유의사항\", \"score\": 0.89545894}, {\"title\": \"2025년 최저시급은 1만 30원, 알바하기 전 꼭 알아둘 \\'3종세트\\'\", \"url\": \"https://www.korea.kr/news/reporterView.do?newsId=148938752\", \"content\": \"본문 바로가기\\\\n메인메뉴 바로가기\\\\n\\\\n이 누리집은 대한민국 공식 전자정부 누리집입니다.\\\\n\\\\n대통령실 소식\\\\n공직메일\\\\n\\\\n## 국민이 말하는 정책2025년 최저시급은 1만 30원, 알바하기 전 꼭 알아둘 \\'3종세트\\'\\\\n\\\\n## 사이트 이동경로\\\\n\\\\n 홈으로\\\\n 뉴스\\\\n 국민이 말하는 정책\\\\n\\\\n## 콘텐츠 영역\\\\n\\\\n# 2025년 최저시급은 1만 30원, 알바하기 전 꼭 알아둘 \\'3종세트\\'\\\\n\\\\n## \\'근로계약서 작성, 주휴수당, 청소년·청년근로권익센터\\' 기억하고 즐거운 \\'알바\\' 시작!\\\\n\\\\n2025.01.22\\\\n정책기자단 김재은\\\\n\\\\n글자크기 설정\\\\n\\\\n인쇄하기\\\\n\\\\n목록\\\\n\\\\n\\\\\"최저임금이 1만 30원으로 올랐다는데, 방학에 아르바이트를 해볼까?\\\\\"\\\\n\\\\n매년 1월이 되면 아르바이트 시장은 방학을 맞은 대학생들을 비롯해 이제 막 성인이 된 친구들이 몰리며 후끈 달아오른다. [...] 주변에도 관공서나 카페 아르바이트 등 새로운 일자리에 도전하는 친구들이 많다. 아르바이트를 구할 때에는 집과 근무지의 거리, 근무 내용, 급여, 근무시간 등을 꼼꼼히 따져보게 된다.\\\\n\\\\n근로자의 최저 생계비를 보장하는 최저임금, 2025년의 최저시급은 1만 30원이다. 2024년 최저시급 9860원 대비 170원 인상된 수치이다.\\\\n\\\\n최저임금은 근로자 1명 이상인 모든 사업(사업장)과 근로기준법상 근로자(정규직, 비정규직, 파트타임, 아르바이트, 청소년 근로자, 외국인 근로자) 모두에게 적용된다.\\\\n\\\\n만약 최저임금을 위반할 경우엔 3년 이하의 징역 또는 2천만 원 이하 벌금에 처해지거나, 두 가지 벌칙을 같이 받을 수 있다.\\\\n\\\\n그렇다면, 최저시급 이외에도 아르바이트 하기 전 반드시 알아두어야 할 사항은 또 무엇이 있을까?\\\\n\\\\n◆ 첫 번째, 선택이 아닌 필수! \\'근로계약서 작성\\' [...] 이전기사지방세 자동납부 신청하고 세금 할인 받으세요\\\\n다음기사설 명절, 스미싱 큐싱 예방법 알아두세요\\\\n\\\\n공유\\\\n\\\\n정책브리핑 게시물 운영원칙에 따라 다음과 같은 게시물은 삭제 또는 계정이 차단 될 수 있습니다.\", \"score\": 0.8914433}, {\"title\": \"2025년 적용 최저임금 시간급 10030원 | 고용노동부 > 뉴스·소식 > 보도\", \"url\": \"https://www.moel.go.kr/news/enews/report/enewsView.do?news_seq=16902\", \"content\": \"- 올해에 비해 170원 올라, 월 환산액은 2,096,270원(월 209시간 기준) -  \\\\n  \\\\n8.5.(월), 고용노동부는 2025년도 적용 최저임금을 시간급 10,030원으로 결정·고시했다. 이를 월급으로 환산할 경우 2,096,270원(1주 소정근로 40시간 근무, 월 209시간 기준)이며, 사업의 종류별 구분 없이 전 사업장에 동일한 최저임금이 적용된다.  \\\\n   \\\\n고용노동부는 7.12. 최저임금위원회가 11차례 전원회의를 거쳐 의결한 최저임금안을 고시한 이후 7.29.까지 이의제기 기간을 운영했으며, 노사단체의 이의제기는 없었다. 이는 2020년 이후 4년 만이다.  \\\\n   \\\\n이정식 고용노동부 장관은 “최저임금위원회에서 우리 경제·노동시장 여건, 저임금근로자와 영세소상공인의 어려움 등을 충분히 감안해 결정한 것으로 생각하며 이를 존중한다”라고 밝혔다.\", \"score\": 0.87782305}]', name='tavily_search_results_json', id='132c5c5a-9ff1-469c-8439-54733f054798', tool_call_id='call_vbkT3Uqz30VEyNN9hMiisgcT', artifact={'query': '2025년 한국 최저 시급', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://partner.yogiyo.co.kr/content/view/2025%EB%85%84_%EC%B5%9C%EC%A0%80%EC%9E%84%EA%B8%88_%EC%B5%9C%EC%A0%80%EC%8B%9C%EA%B8%89', 'title': \"2025년 최저시급 '1만 30원'\", 'content': \"2025년 최저시급이 10,030원으로 확정됐습니다.(2024년 최저시급 9,860원) 최저임금 제도가 도입된 이후 역대 두 번째로 낮은 인상률이지만 최저시급이 1만원을 넘은 건 처음인데요. \\u200b구인·구직 매칭 서비스 플랫폼 ‘급구’와 함께 2025년 직원들에게 지급해야 하는 최저임금과 아르바이트생 급여 관련 유의사항을 정리했습니다.\\n\\n  \\n※ 본 콘텐츠는 2024년 7월 기준으로 작성됐습니다. 정부 정책 및 법령 변경에 따라 일부 내용이 달라질 수 있으니 최신 정보인지 꼭 확인해주시기 바랍니다.  \\n  \\n  \\n  \\n  \\n\\n## 💰 최저시급 170원 상승 [...] 2025년 최저시급이 1만 30원으로 결정됐습니다.  \\n2024년보다 1.7%인 170원 오른 금액입니다.  \\n  \\n하루 8시간 근무하는 직원에게는  \\n일당 8만 240원 이상을 지급해야 합니다.  \\n  \\n직원이 주 5일 근무한다면  \\n주휴수당을 포함해 주급 48만 1,440원 이상을  \\n월급 209만 6,270원 이상을 지급해야 합니다.  \\n최저 월급은 2024년 대비 3만 5,530원 오른 금액입니다.  \\n  \\n  \\n\\n## 💰 일반음식점 평균시급 1만 2,350원\\n\\n  \\n실제 사장님이 직원에게 주는 평균 시급은 얼마일까요.  \\n  \\n급구의 연도별 데이터를 살펴보면  \\n한식당, 분식집 등 일반음식점 사장님이 등록한 [...] 본문 바로가기\\n주메뉴 바로가기\\n\\n## 자영업상식\\n\\n## 공지사항\\n\\n 민생회복 소비쿠폰 사용에 따른 음식점 운영 참고사항\\n 요기요앱 '밀키트' 카테고리명 변경 안내\\n 필수옵션그룹 내 메뉴 가격 설정 안내\\n 민생회복 소비쿠폰 사용에 따른 음식점 운영 참고사항\\n 요기요앱 '밀키트' 카테고리명 변경 안내\\n\\n이전 슬라이드;)\\n다음 슬라이드;)\\n\\n 전체\\n 메뉴관리\\n 주방\\n 마케팅\\n 위생/안전\\n 인력/노무\\n 손익/세무\\n 주문접수수단\\n 정책\\n 부동산\\n 배달관리\\n 매장관리\\n\\n닫기;)\\n\\n노무·세무\\n\\n# 2025년 최저시급 ‘1만 30원’\\n\\n## #급구 #2025년 #최저시급 #최저임금 #유의사항\\n\\n좋아요;)\\n공유;)\\n\\n## 2025년 최저임금과 임금 지급 유의사항\", 'score': 0.89545894, 'raw_content': None}, {'url': 'https://www.korea.kr/news/reporterView.do?newsId=148938752', 'title': \"2025년 최저시급은 1만 30원, 알바하기 전 꼭 알아둘 '3종세트'\", 'content': '본문 바로가기\\n메인메뉴 바로가기\\n\\n이 누리집은 대한민국 공식 전자정부 누리집입니다.\\n\\n대통령실 소식\\n공직메일\\n\\n## 국민이 말하는 정책2025년 최저시급은 1만 30원, 알바하기 전 꼭 알아둘 \\'3종세트\\'\\n\\n## 사이트 이동경로\\n\\n 홈으로\\n 뉴스\\n 국민이 말하는 정책\\n\\n## 콘텐츠 영역\\n\\n# 2025년 최저시급은 1만 30원, 알바하기 전 꼭 알아둘 \\'3종세트\\'\\n\\n## \\'근로계약서 작성, 주휴수당, 청소년·청년근로권익센터\\' 기억하고 즐거운 \\'알바\\' 시작!\\n\\n2025.01.22\\n정책기자단 김재은\\n\\n글자크기 설정\\n\\n인쇄하기\\n\\n목록\\n\\n\"최저임금이 1만 30원으로 올랐다는데, 방학에 아르바이트를 해볼까?\"\\n\\n매년 1월이 되면 아르바이트 시장은 방학을 맞은 대학생들을 비롯해 이제 막 성인이 된 친구들이 몰리며 후끈 달아오른다. [...] 주변에도 관공서나 카페 아르바이트 등 새로운 일자리에 도전하는 친구들이 많다. 아르바이트를 구할 때에는 집과 근무지의 거리, 근무 내용, 급여, 근무시간 등을 꼼꼼히 따져보게 된다.\\n\\n근로자의 최저 생계비를 보장하는 최저임금, 2025년의 최저시급은 1만 30원이다. 2024년 최저시급 9860원 대비 170원 인상된 수치이다.\\n\\n최저임금은 근로자 1명 이상인 모든 사업(사업장)과 근로기준법상 근로자(정규직, 비정규직, 파트타임, 아르바이트, 청소년 근로자, 외국인 근로자) 모두에게 적용된다.\\n\\n만약 최저임금을 위반할 경우엔 3년 이하의 징역 또는 2천만 원 이하 벌금에 처해지거나, 두 가지 벌칙을 같이 받을 수 있다.\\n\\n그렇다면, 최저시급 이외에도 아르바이트 하기 전 반드시 알아두어야 할 사항은 또 무엇이 있을까?\\n\\n◆ 첫 번째, 선택이 아닌 필수! \\'근로계약서 작성\\' [...] 이전기사지방세 자동납부 신청하고 세금 할인 받으세요\\n다음기사설 명절, 스미싱 큐싱 예방법 알아두세요\\n\\n공유\\n\\n정책브리핑 게시물 운영원칙에 따라 다음과 같은 게시물은 삭제 또는 계정이 차단 될 수 있습니다.', 'score': 0.8914433, 'raw_content': None}, {'url': 'https://www.moel.go.kr/news/enews/report/enewsView.do?news_seq=16902', 'title': '2025년 적용 최저임금 시간급 10030원 | 고용노동부 > 뉴스·소식 > 보도', 'content': '- 올해에 비해 170원 올라, 월 환산액은 2,096,270원(월 209시간 기준) -  \\n  \\n8.5.(월), 고용노동부는 2025년도 적용 최저임금을 시간급 10,030원으로 결정·고시했다. 이를 월급으로 환산할 경우 2,096,270원(1주 소정근로 40시간 근무, 월 209시간 기준)이며, 사업의 종류별 구분 없이 전 사업장에 동일한 최저임금이 적용된다.  \\n   \\n고용노동부는 7.12. 최저임금위원회가 11차례 전원회의를 거쳐 의결한 최저임금안을 고시한 이후 7.29.까지 이의제기 기간을 운영했으며, 노사단체의 이의제기는 없었다. 이는 2020년 이후 4년 만이다.  \\n   \\n이정식 고용노동부 장관은 “최저임금위원회에서 우리 경제·노동시장 여건, 저임금근로자와 영세소상공인의 어려움 등을 충분히 감안해 결정한 것으로 생각하며 이를 존중한다”라고 밝혔다.', 'score': 0.87782305, 'raw_content': None}], 'response_time': 1.35, 'request_id': '60ef0820-8d2b-4a5e-85b3-fcc665fd69c4'}),\n",
              "  AIMessage(content='답: 2025년 최저시급은 10,030원입니다.  \\n- 2024년 대비 170원 인상되었습니다.  \\n- 월 환산액(주 40시간 기준)은 약 2,096,270원(월 209시간 기준).  \\n- 모든 사업장에 동일하게 적용되며 위반 시 법적 제재가 있습니다.  \\n\\n참고: 이 수치는 고용노동부의 고시를 기준으로 한 공식 수치입니다. 필요하시면 관련 세부사항도 정리해 드리겠습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1025, 'prompt_tokens': 2101, 'total_tokens': 3126, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 896, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CFt3pZrqbDr7G781mMHhmaBcoqJ4J', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8bb1271a-75ed-4b0b-9307-940a567f7f9d-0', usage_metadata={'input_tokens': 2101, 'output_tokens': 1025, 'total_tokens': 3126, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 896}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage"
      ],
      "metadata": {
        "id": "GhkbTSKNJXZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Plan(BaseModel):\n",
        "    \"\"\"Plan to follow in future\"\"\"\n",
        "    steps: List[str] = Field(\n",
        "        # 단계별 진행 예정\n",
        "        description=\"different steps to follow, should be in sorted order\"\n",
        "    )"
      ],
      "metadata": {
        "id": "abawhCfNJToc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "planner_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
        "            This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
        "            The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\"\"\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "planner = planner_prompt | llm.with_structured_output(Plan)"
      ],
      "metadata": {
        "id": "bFW3WkZaLHuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plan_result = planner.invoke(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(\n",
        "            content=\"2025년 한국에서 개봉한 영화 중 가장 흥행한 영화는 무엇인가요?\",\n",
        "        )]\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "FjQ0kSrLLNEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plan_result.steps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKVJceLVL2vu",
        "outputId": "283f673c-fbeb-44ad-88d6-b9a42ea418c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1. 2025년에 한국에서 개봉한 모든 영화의 목록을 확인한다.',\n",
              " '2. 각 영화의 국내 흥행 수익을 KOFIC의 KOBIS 데이터 등 신뢰 가능한 출처에서 수집한다.',\n",
              " '3. 수익 기준으로 내림차순 정렬하여 1위 후보를 선정한다.',\n",
              " '4. 최종적으로 1위의 영화 제목을 결과로 제시한다.']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "replanner_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
        "    This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
        "    The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
        "\n",
        "    Your objective was this:\n",
        "    {input}\n",
        "\n",
        "    Your original plan was this:\n",
        "    {plan}\n",
        "\n",
        "    You have currently done the follow steps:\n",
        "    {past_steps}\n",
        "\n",
        "    Update your plan accordingly.\n",
        "    If no more steps are needed and you can return to the user, then respond with that.\n",
        "    Otherwise, fill out the plan. Only add steps to the plan that still NEED to be done.\n",
        "    Do not return previously done steps as part of the plan.\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "BCuzrc6tL2qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Union\n",
        "\n",
        "class Response(BaseModel):\n",
        "    \"\"\"Response to user.\"\"\"\n",
        "    response: str\n",
        "\n",
        "class Act(BaseModel):\n",
        "    \"\"\"Action to perform.\"\"\"\n",
        "    action: Union[Response, Plan] = Field(\n",
        "        description=\"Action to perform. If you want to respond to user, use Response. \"\n",
        "        \"If you need to further use tools to get the answer, use Plan.\"\n",
        "    )"
      ],
      "metadata": {
        "id": "VTbycTWMMhFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replanner = replanner_prompt | llm.with_structured_output(Act)"
      ],
      "metadata": {
        "id": "pM7Q3Y1pM1LM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import Annotated, List, Tuple\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class PlanExecute(TypedDict):\n",
        "    input: str\n",
        "    plan: List[str]\n",
        "    past_steps: Annotated[List[Tuple], operator.add]\n",
        "    response: str"
      ],
      "metadata": {
        "id": "RLu9UZ6iM_5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 계획 생성\n",
        "def plan_step(state: PlanExecute):  # 계획을 생성하는 노드\n",
        "    plan = planner.invoke({\"messages\": [(\"user\", state[\"input\"])]})\n",
        "    return {\"plan\": plan.steps}"
      ],
      "metadata": {
        "id": "g9eAM15pNXkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 계획 실행\n",
        "def execute_step(state: PlanExecute):\n",
        "    plan = state[\"plan\"]\n",
        "    plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n",
        "    task = plan[0]\n",
        "    task_formatted = f\"\"\"For the following plan:\n",
        "    {plan_str}\\n\\nYou are tasked with executing step {1}, {task}.\"\"\"\n",
        "    agent_response = plan_executor.invoke(\n",
        "        {\"messages\": [(\"user\", task_formatted)]}\n",
        "    )\n",
        "    return {\n",
        "        \"past_steps\": [(task, agent_response[\"messages\"][-1].content)], # 실행 완료한 계획과 결과 저장\n",
        "    }"
      ],
      "metadata": {
        "id": "Vkp83RzvNisN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 계획 수정\n",
        "def replan_step(state: PlanExecute):\n",
        "    output = replanner.invoke(state)\n",
        "    if isinstance(output.action, Response): # 답변이 바로 가능한 상태\n",
        "        return {\"response\": output.action.response}\n",
        "    else:\n",
        "        return {\"plan\": output.action.steps}"
      ],
      "metadata": {
        "id": "K3EL1z6dOefk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END\n",
        "\n",
        "def should_end(state: PlanExecute):\n",
        "    if \"response\" in state and state[\"response\"]:\n",
        "        return END\n",
        "    else:\n",
        "        return \"agent\""
      ],
      "metadata": {
        "id": "TlhcRnpIOhqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START\n",
        "\n",
        "graph_builder = StateGraph(PlanExecute)\n",
        "graph_builder.add_node(\"planner\", plan_step)\n",
        "graph_builder.add_node(\"agent\", execute_step)\n",
        "graph_builder.add_node(\"replan\", replan_step)\n",
        "graph_builder.add_edge(START, \"planner\")\n",
        "graph_builder.add_edge(\"planner\", \"agent\")\n",
        "graph_builder.add_edge(\"agent\", \"replan\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"replan\",\n",
        "    should_end,\n",
        "    [\"agent\", END],\n",
        ")\n",
        "\n",
        "graph = graph_builder.compile()\n",
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "DKjht8PgPAu4",
        "outputId": "4145cb95-c709-4a70-bf38-daaf99933fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x7b563cbcce60>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {'recursion_limit':50}\n",
        "inputs = {'input' :'2024년 노벨 문학상 수상자의 출신국가는 어디인가요?'}\n",
        "\n",
        "for event in graph.stream(inputs, config=config, stream_mode='values'):\n",
        "    for k,v in event.items():\n",
        "        print(k,v)\n",
        "    print('*'*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za6IYFHNPKf4",
        "outputId": "74920636-0019-430e-f04c-28b97087c91e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input 2024년 노벨 문학상 수상자의 출신국가는 어디인가요?\n",
            "past_steps []\n",
            "**************************************************\n",
            "input 2024년 노벨 문학상 수상자의 출신국가는 어디인가요?\n",
            "plan ['1) 공식 노벨상 웹사이트에서 2024년 노벨문학상 수상자를 확인한다.', '2) 수상자의 프로필(또는 신뢰 가능한 출처)에서 출생국가를 확인한다.', '3) 확인된 출생국가를 한국어 표현으로 기록한다.', '4) 한국어로 최종 답을 작성한다(예: 수상자의 출생국가는 ○○입니다).', '5) 필요 시 출처를 함께 제시하여 확인 가능하도록 한다.']\n",
            "past_steps []\n",
            "**************************************************\n",
            "input 2024년 노벨 문학상 수상자의 출신국가는 어디인가요?\n",
            "plan ['1) 공식 노벨상 웹사이트에서 2024년 노벨문학상 수상자를 확인한다.', '2) 수상자의 프로필(또는 신뢰 가능한 출처)에서 출생국가를 확인한다.', '3) 확인된 출생국가를 한국어 표현으로 기록한다.', '4) 한국어로 최종 답을 작성한다(예: 수상자의 출생국가는 ○○입니다).', '5) 필요 시 출처를 함께 제시하여 확인 가능하도록 한다.']\n",
            "past_steps [('1) 공식 노벨상 웹사이트에서 2024년 노벨문학상 수상자를 확인한다.', '확인 결과:\\n- 2024년 노벨문학상 수상자는 Han Kang(한강)입니다.\\n- 공식 노벨상 웹사이트에 수상자 정보가 등재되어 있습니다: https://www.nobelprize.org/prizes/literature/2024/summary/')]\n",
            "**************************************************\n",
            "input 2024년 노벨 문학상 수상자의 출신국가는 어디인가요?\n",
            "plan ['2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '3) 확인된 출생국가를 한국어 표현으로 기록한다.', '4) 한국어로 최종 답을 작성한다(예: 수상자의 출생국가는 ○○입니다).', '5) 필요 시 출처를 함께 제시하여 확인 가능하도록 한다.']\n",
            "past_steps [('1) 공식 노벨상 웹사이트에서 2024년 노벨문학상 수상자를 확인한다.', '확인 결과:\\n- 2024년 노벨문학상 수상자는 Han Kang(한강)입니다.\\n- 공식 노벨상 웹사이트에 수상자 정보가 등재되어 있습니다: https://www.nobelprize.org/prizes/literature/2024/summary/')]\n",
            "**************************************************\n",
            "input 2024년 노벨 문학상 수상자의 출신국가는 어디인가요?\n",
            "plan ['2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '3) 확인된 출생국가를 한국어 표현으로 기록한다.', '4) 한국어로 최종 답을 작성한다(예: 수상자의 출생국가는 ○○입니다).', '5) 필요 시 출처를 함께 제시하여 확인 가능하도록 한다.']\n",
            "past_steps [('1) 공식 노벨상 웹사이트에서 2024년 노벨문학상 수상자를 확인한다.', '확인 결과:\\n- 2024년 노벨문학상 수상자는 Han Kang(한강)입니다.\\n- 공식 노벨상 웹사이트에 수상자 정보가 등재되어 있습니다: https://www.nobelprize.org/prizes/literature/2024/summary/'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '확인했습니다. 다만 어떤 수상자를 지칭하는지 알려주셔야 1단계(공식 프로필 또는 신뢰 가능한 출처에서 출생지 확인)를 실행할 수 있습니다.\\n\\n다음 정보를 제공해 주세요:\\n- 수상 상의 정확한 명칭(예: 특정 상의 이름과 연도)\\n- 수상자 이름(복수일 경우 각 수상자)\\n- 가능하면 수상자 목록도 함께\\n\\n제가 할 일은:\\n1) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인\\n2) 확인된 출생국가를 한국어 표현으로 기록\\n3) 필요한 경우 출처를 함께 제시해 확인 가능하도록 정리\\n\\n참고로 결과 형식은 예시처럼:\\n- 수상자의 출생국가는 미국입니다. (출처: 공식 페이지 A, 기사 B)\\n또는 출생지가 확인되지 않으면 그 상태를 명확히 표시하고, 확인이 필요한 출처를 함께 적겠습니다.')]\n",
            "**************************************************\n",
            "input 2024년 노벨 문학상 수상자의 출신국가는 어디인가요?\n",
            "plan ['2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '3) 확인된 출생국가를 한국어 표현으로 기록한다.', '4) 한국어로 최종 답을 작성한다(예: 수상자의 출생국가는 ○○입니다).', '5) 필요 시 출처를 함께 제시하여 확인 가능하도록 한다.']\n",
            "past_steps [('1) 공식 노벨상 웹사이트에서 2024년 노벨문학상 수상자를 확인한다.', '확인 결과:\\n- 2024년 노벨문학상 수상자는 Han Kang(한강)입니다.\\n- 공식 노벨상 웹사이트에 수상자 정보가 등재되어 있습니다: https://www.nobelprize.org/prizes/literature/2024/summary/'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '확인했습니다. 다만 어떤 수상자를 지칭하는지 알려주셔야 1단계(공식 프로필 또는 신뢰 가능한 출처에서 출생지 확인)를 실행할 수 있습니다.\\n\\n다음 정보를 제공해 주세요:\\n- 수상 상의 정확한 명칭(예: 특정 상의 이름과 연도)\\n- 수상자 이름(복수일 경우 각 수상자)\\n- 가능하면 수상자 목록도 함께\\n\\n제가 할 일은:\\n1) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인\\n2) 확인된 출생국가를 한국어 표현으로 기록\\n3) 필요한 경우 출처를 함께 제시해 확인 가능하도록 정리\\n\\n참고로 결과 형식은 예시처럼:\\n- 수상자의 출생국가는 미국입니다. (출처: 공식 페이지 A, 기사 B)\\n또는 출생지가 확인되지 않으면 그 상태를 명확히 표시하고, 확인이 필요한 출처를 함께 적겠습니다.')]\n",
            "response \n",
            "**************************************************\n",
            "input 2024년 노벨 문학상 수상자의 출신국가는 어디인가요?\n",
            "plan ['2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '3) 확인된 출생국가를 한국어 표현으로 기록한다.', '4) 한국어로 최종 답을 작성한다(예: 수상자의 출생국가는 ○○입니다).', '5) 필요 시 출처를 함께 제시하여 확인 가능하도록 한다.']\n",
            "past_steps [('1) 공식 노벨상 웹사이트에서 2024년 노벨문학상 수상자를 확인한다.', '확인 결과:\\n- 2024년 노벨문학상 수상자는 Han Kang(한강)입니다.\\n- 공식 노벨상 웹사이트에 수상자 정보가 등재되어 있습니다: https://www.nobelprize.org/prizes/literature/2024/summary/'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '확인했습니다. 다만 어떤 수상자를 지칭하는지 알려주셔야 1단계(공식 프로필 또는 신뢰 가능한 출처에서 출생지 확인)를 실행할 수 있습니다.\\n\\n다음 정보를 제공해 주세요:\\n- 수상 상의 정확한 명칭(예: 특정 상의 이름과 연도)\\n- 수상자 이름(복수일 경우 각 수상자)\\n- 가능하면 수상자 목록도 함께\\n\\n제가 할 일은:\\n1) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인\\n2) 확인된 출생국가를 한국어 표현으로 기록\\n3) 필요한 경우 출처를 함께 제시해 확인 가능하도록 정리\\n\\n참고로 결과 형식은 예시처럼:\\n- 수상자의 출생국가는 미국입니다. (출처: 공식 페이지 A, 기사 B)\\n또는 출생지가 확인되지 않으면 그 상태를 명확히 표시하고, 확인이 필요한 출처를 함께 적겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '수상자 이름이 필요합니다. 어떤 수상자의 출생지를 확인하면 될까요?\\n\\n가능하면 아래 정보를 함께 알려 주세요.\\n- 수상자 이름\\n- 상의 이름(또는 주최 기관)과 수상 연도(선택 사항)\\n- 확인하고 싶은 특정 출처 요구 여부(예: 官方 프로필 중심), 없으면 일반적으로 공식 프로필과 신뢰 가능한 보도 자료를 우선 확인하겠습니다.\\n\\n확인 절차 예시:\\n- 공식 프로필(수상 기관 웹사이트 등)에서 출생지 정보 확인\\n- 신뢰 가능한 보도자료나 학술/정부 자료와 교차 확인\\n- 출처를 함께 제시하여 근거를 명시\\n\\n수상자 이름을 알려주시면 바로 1단계인 출생지 확인을 시작하겠습니다.')]\n",
            "response \n",
            "**************************************************\n",
            "input 2024년 노벨 문학상 수상자의 출신국가는 어디인가요?\n",
            "plan ['2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '3) 확인된 출생국가를 한국어 표현으로 기록한다.', '4) 한국어로 최종 답을 작성한다(예: 수상자의 출생국가는 ○○입니다).', '5) 필요 시 출처를 함께 제시하여 확인 가능하도록 한다.']\n",
            "past_steps [('1) 공식 노벨상 웹사이트에서 2024년 노벨문학상 수상자를 확인한다.', '확인 결과:\\n- 2024년 노벨문학상 수상자는 Han Kang(한강)입니다.\\n- 공식 노벨상 웹사이트에 수상자 정보가 등재되어 있습니다: https://www.nobelprize.org/prizes/literature/2024/summary/'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '확인했습니다. 다만 어떤 수상자를 지칭하는지 알려주셔야 1단계(공식 프로필 또는 신뢰 가능한 출처에서 출생지 확인)를 실행할 수 있습니다.\\n\\n다음 정보를 제공해 주세요:\\n- 수상 상의 정확한 명칭(예: 특정 상의 이름과 연도)\\n- 수상자 이름(복수일 경우 각 수상자)\\n- 가능하면 수상자 목록도 함께\\n\\n제가 할 일은:\\n1) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인\\n2) 확인된 출생국가를 한국어 표현으로 기록\\n3) 필요한 경우 출처를 함께 제시해 확인 가능하도록 정리\\n\\n참고로 결과 형식은 예시처럼:\\n- 수상자의 출생국가는 미국입니다. (출처: 공식 페이지 A, 기사 B)\\n또는 출생지가 확인되지 않으면 그 상태를 명확히 표시하고, 확인이 필요한 출처를 함께 적겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '수상자 이름이 필요합니다. 어떤 수상자의 출생지를 확인하면 될까요?\\n\\n가능하면 아래 정보를 함께 알려 주세요.\\n- 수상자 이름\\n- 상의 이름(또는 주최 기관)과 수상 연도(선택 사항)\\n- 확인하고 싶은 특정 출처 요구 여부(예: 官方 프로필 중심), 없으면 일반적으로 공식 프로필과 신뢰 가능한 보도 자료를 우선 확인하겠습니다.\\n\\n확인 절차 예시:\\n- 공식 프로필(수상 기관 웹사이트 등)에서 출생지 정보 확인\\n- 신뢰 가능한 보도자료나 학술/정부 자료와 교차 확인\\n- 출처를 함께 제시하여 근거를 명시\\n\\n수상자 이름을 알려주시면 바로 1단계인 출생지 확인을 시작하겠습니다.')]\n",
            "response \n",
            "**************************************************\n",
            "input 2024년 노벨 문학상 수상자의 출신국가는 어디인가요?\n",
            "plan ['2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '3) 확인된 출생국가를 한국어 표현으로 기록한다.', '4) 한국어로 최종 답을 작성한다(예: 수상자의 출생국가는 ○○입니다).', '5) 필요 시 출처를 함께 제시하여 확인 가능하도록 한다.']\n",
            "past_steps [('1) 공식 노벨상 웹사이트에서 2024년 노벨문학상 수상자를 확인한다.', '확인 결과:\\n- 2024년 노벨문학상 수상자는 Han Kang(한강)입니다.\\n- 공식 노벨상 웹사이트에 수상자 정보가 등재되어 있습니다: https://www.nobelprize.org/prizes/literature/2024/summary/'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '확인했습니다. 다만 어떤 수상자를 지칭하는지 알려주셔야 1단계(공식 프로필 또는 신뢰 가능한 출처에서 출생지 확인)를 실행할 수 있습니다.\\n\\n다음 정보를 제공해 주세요:\\n- 수상 상의 정확한 명칭(예: 특정 상의 이름과 연도)\\n- 수상자 이름(복수일 경우 각 수상자)\\n- 가능하면 수상자 목록도 함께\\n\\n제가 할 일은:\\n1) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인\\n2) 확인된 출생국가를 한국어 표현으로 기록\\n3) 필요한 경우 출처를 함께 제시해 확인 가능하도록 정리\\n\\n참고로 결과 형식은 예시처럼:\\n- 수상자의 출생국가는 미국입니다. (출처: 공식 페이지 A, 기사 B)\\n또는 출생지가 확인되지 않으면 그 상태를 명확히 표시하고, 확인이 필요한 출처를 함께 적겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '수상자 이름이 필요합니다. 어떤 수상자의 출생지를 확인하면 될까요?\\n\\n가능하면 아래 정보를 함께 알려 주세요.\\n- 수상자 이름\\n- 상의 이름(또는 주최 기관)과 수상 연도(선택 사항)\\n- 확인하고 싶은 특정 출처 요구 여부(예: 官方 프로필 중심), 없으면 일반적으로 공식 프로필과 신뢰 가능한 보도 자료를 우선 확인하겠습니다.\\n\\n확인 절차 예시:\\n- 공식 프로필(수상 기관 웹사이트 등)에서 출생지 정보 확인\\n- 신뢰 가능한 보도자료나 학술/정부 자료와 교차 확인\\n- 출처를 함께 제시하여 근거를 명시\\n\\n수상자 이름을 알려주시면 바로 1단계인 출생지 확인을 시작하겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '도와드릴게요. 다만 수상자의 이름이 필요합니다. 이름을 알려주시면 공식 프로필이나 신뢰 가능한 출처에서 출생지(국가)를 확인해 드리겠습니다.\\n\\n제가 수행할 절차은 다음과 같습니다.\\n- 우선순위: 수상자의 공식 프로필/발표 자료를 우선 확인\\n- 그다음: 기관 웹사이트, 정부·공신력 있는 매체의 신뢰 가능한 출처, 수상자 본인의 인터뷰 등에서 출생지 정보를 수집\\n- 다수의 출처를 대조해 일치 여부를 확인하고, 모호하거나 불일치가 있을 경우 근거를 함께 제시\\n- 결과를 한국어 표현으로 정리(예: 수상자의 출생국가는 ○○입니다) 및 필요 시 출처 링크 제공\\n\\n수상자의 이름을 알려주시면 바로 검색을 시작하겠습니다. 또한 특정 상의 수상자(연도나 카테고리)가 있다면 함께 알려주면 더 정확하게 확인할 수 있습니다.')]\n",
            "response \n",
            "**************************************************\n",
            "input 2024년 노벨 문학상 수상자의 출신국가는 어디인가요?\n",
            "plan ['2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다. 대상: 2024년 노벨문학상 수상자 Han Kang(한강). 확인 우선 순위: 공식 노벨상 웹사이트의 수상자 페이지/생애 정보, 수상자 본인의 공식 프로필, Britannica 등 신뢰 가능한 자료. 확인 항목: 출생지 국가(가능하면 도시)와 국가명이 일치하는지 교차 확인.', '3) 확인된 출생국가를 한국어 표현으로 기록한다. 기록 예시: 수상자의 출생국가는 한국입니다. 필요 시 출생지 도시도 함께 기록: 광주, 대한민국.', '4) 한국어로 최종 답을 작성한다. 예시: 수상자의 출생국가는 한국입니다.', '5) 필요 시 출처를 함께 제시하여 확인 가능하도록 한다. 결과에 출처 링크를 첨부하고, 각 출처의 신뢰성을 간단히 표시한다.']\n",
            "past_steps [('1) 공식 노벨상 웹사이트에서 2024년 노벨문학상 수상자를 확인한다.', '확인 결과:\\n- 2024년 노벨문학상 수상자는 Han Kang(한강)입니다.\\n- 공식 노벨상 웹사이트에 수상자 정보가 등재되어 있습니다: https://www.nobelprize.org/prizes/literature/2024/summary/'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '확인했습니다. 다만 어떤 수상자를 지칭하는지 알려주셔야 1단계(공식 프로필 또는 신뢰 가능한 출처에서 출생지 확인)를 실행할 수 있습니다.\\n\\n다음 정보를 제공해 주세요:\\n- 수상 상의 정확한 명칭(예: 특정 상의 이름과 연도)\\n- 수상자 이름(복수일 경우 각 수상자)\\n- 가능하면 수상자 목록도 함께\\n\\n제가 할 일은:\\n1) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인\\n2) 확인된 출생국가를 한국어 표현으로 기록\\n3) 필요한 경우 출처를 함께 제시해 확인 가능하도록 정리\\n\\n참고로 결과 형식은 예시처럼:\\n- 수상자의 출생국가는 미국입니다. (출처: 공식 페이지 A, 기사 B)\\n또는 출생지가 확인되지 않으면 그 상태를 명확히 표시하고, 확인이 필요한 출처를 함께 적겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '수상자 이름이 필요합니다. 어떤 수상자의 출생지를 확인하면 될까요?\\n\\n가능하면 아래 정보를 함께 알려 주세요.\\n- 수상자 이름\\n- 상의 이름(또는 주최 기관)과 수상 연도(선택 사항)\\n- 확인하고 싶은 특정 출처 요구 여부(예: 官方 프로필 중심), 없으면 일반적으로 공식 프로필과 신뢰 가능한 보도 자료를 우선 확인하겠습니다.\\n\\n확인 절차 예시:\\n- 공식 프로필(수상 기관 웹사이트 등)에서 출생지 정보 확인\\n- 신뢰 가능한 보도자료나 학술/정부 자료와 교차 확인\\n- 출처를 함께 제시하여 근거를 명시\\n\\n수상자 이름을 알려주시면 바로 1단계인 출생지 확인을 시작하겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '도와드릴게요. 다만 수상자의 이름이 필요합니다. 이름을 알려주시면 공식 프로필이나 신뢰 가능한 출처에서 출생지(국가)를 확인해 드리겠습니다.\\n\\n제가 수행할 절차은 다음과 같습니다.\\n- 우선순위: 수상자의 공식 프로필/발표 자료를 우선 확인\\n- 그다음: 기관 웹사이트, 정부·공신력 있는 매체의 신뢰 가능한 출처, 수상자 본인의 인터뷰 등에서 출생지 정보를 수집\\n- 다수의 출처를 대조해 일치 여부를 확인하고, 모호하거나 불일치가 있을 경우 근거를 함께 제시\\n- 결과를 한국어 표현으로 정리(예: 수상자의 출생국가는 ○○입니다) 및 필요 시 출처 링크 제공\\n\\n수상자의 이름을 알려주시면 바로 검색을 시작하겠습니다. 또한 특정 상의 수상자(연도나 카테고리)가 있다면 함께 알려주면 더 정확하게 확인할 수 있습니다.')]\n",
            "response \n",
            "**************************************************\n",
            "input 2024년 노벨 문학상 수상자의 출신국가는 어디인가요?\n",
            "plan ['2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다. 대상: 2024년 노벨문학상 수상자 Han Kang(한강). 확인 우선 순위: 공식 노벨상 웹사이트의 수상자 페이지/생애 정보, 수상자 본인의 공식 프로필, Britannica 등 신뢰 가능한 자료. 확인 항목: 출생지 국가(가능하면 도시)와 국가명이 일치하는지 교차 확인.', '3) 확인된 출생국가를 한국어 표현으로 기록한다. 기록 예시: 수상자의 출생국가는 한국입니다. 필요 시 출생지 도시도 함께 기록: 광주, 대한민국.', '4) 한국어로 최종 답을 작성한다. 예시: 수상자의 출생국가는 한국입니다.', '5) 필요 시 출처를 함께 제시하여 확인 가능하도록 한다. 결과에 출처 링크를 첨부하고, 각 출처의 신뢰성을 간단히 표시한다.']\n",
            "past_steps [('1) 공식 노벨상 웹사이트에서 2024년 노벨문학상 수상자를 확인한다.', '확인 결과:\\n- 2024년 노벨문학상 수상자는 Han Kang(한강)입니다.\\n- 공식 노벨상 웹사이트에 수상자 정보가 등재되어 있습니다: https://www.nobelprize.org/prizes/literature/2024/summary/'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '확인했습니다. 다만 어떤 수상자를 지칭하는지 알려주셔야 1단계(공식 프로필 또는 신뢰 가능한 출처에서 출생지 확인)를 실행할 수 있습니다.\\n\\n다음 정보를 제공해 주세요:\\n- 수상 상의 정확한 명칭(예: 특정 상의 이름과 연도)\\n- 수상자 이름(복수일 경우 각 수상자)\\n- 가능하면 수상자 목록도 함께\\n\\n제가 할 일은:\\n1) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인\\n2) 확인된 출생국가를 한국어 표현으로 기록\\n3) 필요한 경우 출처를 함께 제시해 확인 가능하도록 정리\\n\\n참고로 결과 형식은 예시처럼:\\n- 수상자의 출생국가는 미국입니다. (출처: 공식 페이지 A, 기사 B)\\n또는 출생지가 확인되지 않으면 그 상태를 명확히 표시하고, 확인이 필요한 출처를 함께 적겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '수상자 이름이 필요합니다. 어떤 수상자의 출생지를 확인하면 될까요?\\n\\n가능하면 아래 정보를 함께 알려 주세요.\\n- 수상자 이름\\n- 상의 이름(또는 주최 기관)과 수상 연도(선택 사항)\\n- 확인하고 싶은 특정 출처 요구 여부(예: 官方 프로필 중심), 없으면 일반적으로 공식 프로필과 신뢰 가능한 보도 자료를 우선 확인하겠습니다.\\n\\n확인 절차 예시:\\n- 공식 프로필(수상 기관 웹사이트 등)에서 출생지 정보 확인\\n- 신뢰 가능한 보도자료나 학술/정부 자료와 교차 확인\\n- 출처를 함께 제시하여 근거를 명시\\n\\n수상자 이름을 알려주시면 바로 1단계인 출생지 확인을 시작하겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '도와드릴게요. 다만 수상자의 이름이 필요합니다. 이름을 알려주시면 공식 프로필이나 신뢰 가능한 출처에서 출생지(국가)를 확인해 드리겠습니다.\\n\\n제가 수행할 절차은 다음과 같습니다.\\n- 우선순위: 수상자의 공식 프로필/발표 자료를 우선 확인\\n- 그다음: 기관 웹사이트, 정부·공신력 있는 매체의 신뢰 가능한 출처, 수상자 본인의 인터뷰 등에서 출생지 정보를 수집\\n- 다수의 출처를 대조해 일치 여부를 확인하고, 모호하거나 불일치가 있을 경우 근거를 함께 제시\\n- 결과를 한국어 표현으로 정리(예: 수상자의 출생국가는 ○○입니다) 및 필요 시 출처 링크 제공\\n\\n수상자의 이름을 알려주시면 바로 검색을 시작하겠습니다. 또한 특정 상의 수상자(연도나 카테고리)가 있다면 함께 알려주면 더 정확하게 확인할 수 있습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다. 대상: 2024년 노벨문학상 수상자 Han Kang(한강). 확인 우선 순위: 공식 노벨상 웹사이트의 수상자 페이지/생애 정보, 수상자 본인의 공식 프로필, Britannica 등 신뢰 가능한 자료. 확인 항목: 출생지 국가(가능하면 도시)와 국가명이 일치하는지 교차 확인.', '다음은 1단계(출생지 확인) 결과입니다.\\n\\n결과 요약\\n- 수상자: Han Kang(한강), 2024년 노벨문학상 수상자\\n- 확인된 출생 도시: 광주\\n- 확인된 출생 국가: 대한민국(한국)\\n- 교차 확인 결과: 공식 노벨상 웹사이트의 수상자 정보와 Britannica의 인물 정보 모두 \"광주, 대한민국\"으로 일치합니다.\\n\\n주요 근거\\n- Nobel Prize in Literature 2024 – Han Kang – Facts\\n  - Born: 27 November 1970, Gwangju, South Korea\\n  - 신뢰성: 공식 수상자 페이지(1차 자료)\\n  - 링크: https://www.nobelprize.org/prizes/literature/2024/han/facts/\\n\\n- Britannica – Han Kang\\n  - Born: November 27, 1970, Gwangju, South Korea\\n  - 신뢰성: 권위 있는 백과사전\\n  - 링크: https://www.britannica.com/biography/Han-Kang\\n\\n추가 메모\\n- 다른 신뢰 가능한 자료(예: 공식 출판사/대학 프로필)에서도 동일한 정보가 확인됩니다. 다만 1단계의 우선 순위가 공식 노벨상 사이트와 Britannica이므로 이 두 출처의 일치가 확인의 핵심 근거입니다.\\n\\n다음으로 진행하시려면, 2단계(한국어 표현으로 기록)와 3단계(한국어 최종 문장 작성)도 진행해 드리겠습니다. 필요 시 출처를 함께 제시하는 형식으로 이어서 작성해 드릴게요.')]\n",
            "response \n",
            "**************************************************\n",
            "input 2024년 노벨 문학상 수상자의 출신국가는 어디인가요?\n",
            "plan ['3) 확인된 출생국가를 한국어 표현으로 기록한다. 필요 시 출생지 도시도 함께 기록: 광주, 대한민국. 기록 예시: 수상자의 출생국가는 한국입니다.', '4) 한국어로 최종 답을 작성한다. 예시: 수상자의 출생국가는 한국입니다. 필요 시 도시를 함께 표시할 수 있다: 광주, 대한민국.', '5) 필요 시 출처를 함께 제시하여 확인 가능하도록 한다. 결과에 출처 링크를 첨부하고, 각 출처의 신뢰성을 간단히 표시한다. 사용 근거: Nobel Prize in Literature 2024 – Han Kang – Facts; Britannica – Han Kang.']\n",
            "past_steps [('1) 공식 노벨상 웹사이트에서 2024년 노벨문학상 수상자를 확인한다.', '확인 결과:\\n- 2024년 노벨문학상 수상자는 Han Kang(한강)입니다.\\n- 공식 노벨상 웹사이트에 수상자 정보가 등재되어 있습니다: https://www.nobelprize.org/prizes/literature/2024/summary/'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '확인했습니다. 다만 어떤 수상자를 지칭하는지 알려주셔야 1단계(공식 프로필 또는 신뢰 가능한 출처에서 출생지 확인)를 실행할 수 있습니다.\\n\\n다음 정보를 제공해 주세요:\\n- 수상 상의 정확한 명칭(예: 특정 상의 이름과 연도)\\n- 수상자 이름(복수일 경우 각 수상자)\\n- 가능하면 수상자 목록도 함께\\n\\n제가 할 일은:\\n1) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인\\n2) 확인된 출생국가를 한국어 표현으로 기록\\n3) 필요한 경우 출처를 함께 제시해 확인 가능하도록 정리\\n\\n참고로 결과 형식은 예시처럼:\\n- 수상자의 출생국가는 미국입니다. (출처: 공식 페이지 A, 기사 B)\\n또는 출생지가 확인되지 않으면 그 상태를 명확히 표시하고, 확인이 필요한 출처를 함께 적겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '수상자 이름이 필요합니다. 어떤 수상자의 출생지를 확인하면 될까요?\\n\\n가능하면 아래 정보를 함께 알려 주세요.\\n- 수상자 이름\\n- 상의 이름(또는 주최 기관)과 수상 연도(선택 사항)\\n- 확인하고 싶은 특정 출처 요구 여부(예: 官方 프로필 중심), 없으면 일반적으로 공식 프로필과 신뢰 가능한 보도 자료를 우선 확인하겠습니다.\\n\\n확인 절차 예시:\\n- 공식 프로필(수상 기관 웹사이트 등)에서 출생지 정보 확인\\n- 신뢰 가능한 보도자료나 학술/정부 자료와 교차 확인\\n- 출처를 함께 제시하여 근거를 명시\\n\\n수상자 이름을 알려주시면 바로 1단계인 출생지 확인을 시작하겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '도와드릴게요. 다만 수상자의 이름이 필요합니다. 이름을 알려주시면 공식 프로필이나 신뢰 가능한 출처에서 출생지(국가)를 확인해 드리겠습니다.\\n\\n제가 수행할 절차은 다음과 같습니다.\\n- 우선순위: 수상자의 공식 프로필/발표 자료를 우선 확인\\n- 그다음: 기관 웹사이트, 정부·공신력 있는 매체의 신뢰 가능한 출처, 수상자 본인의 인터뷰 등에서 출생지 정보를 수집\\n- 다수의 출처를 대조해 일치 여부를 확인하고, 모호하거나 불일치가 있을 경우 근거를 함께 제시\\n- 결과를 한국어 표현으로 정리(예: 수상자의 출생국가는 ○○입니다) 및 필요 시 출처 링크 제공\\n\\n수상자의 이름을 알려주시면 바로 검색을 시작하겠습니다. 또한 특정 상의 수상자(연도나 카테고리)가 있다면 함께 알려주면 더 정확하게 확인할 수 있습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다. 대상: 2024년 노벨문학상 수상자 Han Kang(한강). 확인 우선 순위: 공식 노벨상 웹사이트의 수상자 페이지/생애 정보, 수상자 본인의 공식 프로필, Britannica 등 신뢰 가능한 자료. 확인 항목: 출생지 국가(가능하면 도시)와 국가명이 일치하는지 교차 확인.', '다음은 1단계(출생지 확인) 결과입니다.\\n\\n결과 요약\\n- 수상자: Han Kang(한강), 2024년 노벨문학상 수상자\\n- 확인된 출생 도시: 광주\\n- 확인된 출생 국가: 대한민국(한국)\\n- 교차 확인 결과: 공식 노벨상 웹사이트의 수상자 정보와 Britannica의 인물 정보 모두 \"광주, 대한민국\"으로 일치합니다.\\n\\n주요 근거\\n- Nobel Prize in Literature 2024 – Han Kang – Facts\\n  - Born: 27 November 1970, Gwangju, South Korea\\n  - 신뢰성: 공식 수상자 페이지(1차 자료)\\n  - 링크: https://www.nobelprize.org/prizes/literature/2024/han/facts/\\n\\n- Britannica – Han Kang\\n  - Born: November 27, 1970, Gwangju, South Korea\\n  - 신뢰성: 권위 있는 백과사전\\n  - 링크: https://www.britannica.com/biography/Han-Kang\\n\\n추가 메모\\n- 다른 신뢰 가능한 자료(예: 공식 출판사/대학 프로필)에서도 동일한 정보가 확인됩니다. 다만 1단계의 우선 순위가 공식 노벨상 사이트와 Britannica이므로 이 두 출처의 일치가 확인의 핵심 근거입니다.\\n\\n다음으로 진행하시려면, 2단계(한국어 표현으로 기록)와 3단계(한국어 최종 문장 작성)도 진행해 드리겠습니다. 필요 시 출처를 함께 제시하는 형식으로 이어서 작성해 드릴게요.')]\n",
            "response \n",
            "**************************************************\n",
            "input 2024년 노벨 문학상 수상자의 출신국가는 어디인가요?\n",
            "plan ['3) 확인된 출생국가를 한국어 표현으로 기록한다. 필요 시 출생지 도시도 함께 기록: 광주, 대한민국. 기록 예시: 수상자의 출생국가는 한국입니다.', '4) 한국어로 최종 답을 작성한다. 예시: 수상자의 출생국가는 한국입니다. 필요 시 도시를 함께 표시할 수 있다: 광주, 대한민국.', '5) 필요 시 출처를 함께 제시하여 확인 가능하도록 한다. 결과에 출처 링크를 첨부하고, 각 출처의 신뢰성을 간단히 표시한다. 사용 근거: Nobel Prize in Literature 2024 – Han Kang – Facts; Britannica – Han Kang.']\n",
            "past_steps [('1) 공식 노벨상 웹사이트에서 2024년 노벨문학상 수상자를 확인한다.', '확인 결과:\\n- 2024년 노벨문학상 수상자는 Han Kang(한강)입니다.\\n- 공식 노벨상 웹사이트에 수상자 정보가 등재되어 있습니다: https://www.nobelprize.org/prizes/literature/2024/summary/'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '확인했습니다. 다만 어떤 수상자를 지칭하는지 알려주셔야 1단계(공식 프로필 또는 신뢰 가능한 출처에서 출생지 확인)를 실행할 수 있습니다.\\n\\n다음 정보를 제공해 주세요:\\n- 수상 상의 정확한 명칭(예: 특정 상의 이름과 연도)\\n- 수상자 이름(복수일 경우 각 수상자)\\n- 가능하면 수상자 목록도 함께\\n\\n제가 할 일은:\\n1) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인\\n2) 확인된 출생국가를 한국어 표현으로 기록\\n3) 필요한 경우 출처를 함께 제시해 확인 가능하도록 정리\\n\\n참고로 결과 형식은 예시처럼:\\n- 수상자의 출생국가는 미국입니다. (출처: 공식 페이지 A, 기사 B)\\n또는 출생지가 확인되지 않으면 그 상태를 명확히 표시하고, 확인이 필요한 출처를 함께 적겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '수상자 이름이 필요합니다. 어떤 수상자의 출생지를 확인하면 될까요?\\n\\n가능하면 아래 정보를 함께 알려 주세요.\\n- 수상자 이름\\n- 상의 이름(또는 주최 기관)과 수상 연도(선택 사항)\\n- 확인하고 싶은 특정 출처 요구 여부(예: 官方 프로필 중심), 없으면 일반적으로 공식 프로필과 신뢰 가능한 보도 자료를 우선 확인하겠습니다.\\n\\n확인 절차 예시:\\n- 공식 프로필(수상 기관 웹사이트 등)에서 출생지 정보 확인\\n- 신뢰 가능한 보도자료나 학술/정부 자료와 교차 확인\\n- 출처를 함께 제시하여 근거를 명시\\n\\n수상자 이름을 알려주시면 바로 1단계인 출생지 확인을 시작하겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '도와드릴게요. 다만 수상자의 이름이 필요합니다. 이름을 알려주시면 공식 프로필이나 신뢰 가능한 출처에서 출생지(국가)를 확인해 드리겠습니다.\\n\\n제가 수행할 절차은 다음과 같습니다.\\n- 우선순위: 수상자의 공식 프로필/발표 자료를 우선 확인\\n- 그다음: 기관 웹사이트, 정부·공신력 있는 매체의 신뢰 가능한 출처, 수상자 본인의 인터뷰 등에서 출생지 정보를 수집\\n- 다수의 출처를 대조해 일치 여부를 확인하고, 모호하거나 불일치가 있을 경우 근거를 함께 제시\\n- 결과를 한국어 표현으로 정리(예: 수상자의 출생국가는 ○○입니다) 및 필요 시 출처 링크 제공\\n\\n수상자의 이름을 알려주시면 바로 검색을 시작하겠습니다. 또한 특정 상의 수상자(연도나 카테고리)가 있다면 함께 알려주면 더 정확하게 확인할 수 있습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다. 대상: 2024년 노벨문학상 수상자 Han Kang(한강). 확인 우선 순위: 공식 노벨상 웹사이트의 수상자 페이지/생애 정보, 수상자 본인의 공식 프로필, Britannica 등 신뢰 가능한 자료. 확인 항목: 출생지 국가(가능하면 도시)와 국가명이 일치하는지 교차 확인.', '다음은 1단계(출생지 확인) 결과입니다.\\n\\n결과 요약\\n- 수상자: Han Kang(한강), 2024년 노벨문학상 수상자\\n- 확인된 출생 도시: 광주\\n- 확인된 출생 국가: 대한민국(한국)\\n- 교차 확인 결과: 공식 노벨상 웹사이트의 수상자 정보와 Britannica의 인물 정보 모두 \"광주, 대한민국\"으로 일치합니다.\\n\\n주요 근거\\n- Nobel Prize in Literature 2024 – Han Kang – Facts\\n  - Born: 27 November 1970, Gwangju, South Korea\\n  - 신뢰성: 공식 수상자 페이지(1차 자료)\\n  - 링크: https://www.nobelprize.org/prizes/literature/2024/han/facts/\\n\\n- Britannica – Han Kang\\n  - Born: November 27, 1970, Gwangju, South Korea\\n  - 신뢰성: 권위 있는 백과사전\\n  - 링크: https://www.britannica.com/biography/Han-Kang\\n\\n추가 메모\\n- 다른 신뢰 가능한 자료(예: 공식 출판사/대학 프로필)에서도 동일한 정보가 확인됩니다. 다만 1단계의 우선 순위가 공식 노벨상 사이트와 Britannica이므로 이 두 출처의 일치가 확인의 핵심 근거입니다.\\n\\n다음으로 진행하시려면, 2단계(한국어 표현으로 기록)와 3단계(한국어 최종 문장 작성)도 진행해 드리겠습니다. 필요 시 출처를 함께 제시하는 형식으로 이어서 작성해 드릴게요.'), ('3) 확인된 출생국가를 한국어 표현으로 기록한다. 필요 시 출생지 도시도 함께 기록: 광주, 대한민국. 기록 예시: 수상자의 출생국가는 한국입니다.', '수상자의 출생국가는 한국입니다.\\n필요 시 출생지 도시는 광주, 대한민국입니다.')]\n",
            "response \n",
            "**************************************************\n",
            "input 2024년 노벨 문학상 수상자의 출신국가는 어디인가요?\n",
            "plan ['4) 한국어로 최종 답을 작성한다. 예시: 수상자의 출생국가는 한국입니다. 필요 시 출생지 도시를 함께 표시할 수 있다: 광주, 대한민국.', '5) 필요 시 출처를 함께 제시하여 확인 가능하도록 한다. 결과에 출처 링크를 첨부하고, 각 출처의 신뢰성을 간단히 표시한다. 사용 근거: Nobel Prize in Literature 2024 – Han Kang – Facts; Britannica – Han Kang.']\n",
            "past_steps [('1) 공식 노벨상 웹사이트에서 2024년 노벨문학상 수상자를 확인한다.', '확인 결과:\\n- 2024년 노벨문학상 수상자는 Han Kang(한강)입니다.\\n- 공식 노벨상 웹사이트에 수상자 정보가 등재되어 있습니다: https://www.nobelprize.org/prizes/literature/2024/summary/'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '확인했습니다. 다만 어떤 수상자를 지칭하는지 알려주셔야 1단계(공식 프로필 또는 신뢰 가능한 출처에서 출생지 확인)를 실행할 수 있습니다.\\n\\n다음 정보를 제공해 주세요:\\n- 수상 상의 정확한 명칭(예: 특정 상의 이름과 연도)\\n- 수상자 이름(복수일 경우 각 수상자)\\n- 가능하면 수상자 목록도 함께\\n\\n제가 할 일은:\\n1) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인\\n2) 확인된 출생국가를 한국어 표현으로 기록\\n3) 필요한 경우 출처를 함께 제시해 확인 가능하도록 정리\\n\\n참고로 결과 형식은 예시처럼:\\n- 수상자의 출생국가는 미국입니다. (출처: 공식 페이지 A, 기사 B)\\n또는 출생지가 확인되지 않으면 그 상태를 명확히 표시하고, 확인이 필요한 출처를 함께 적겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '수상자 이름이 필요합니다. 어떤 수상자의 출생지를 확인하면 될까요?\\n\\n가능하면 아래 정보를 함께 알려 주세요.\\n- 수상자 이름\\n- 상의 이름(또는 주최 기관)과 수상 연도(선택 사항)\\n- 확인하고 싶은 특정 출처 요구 여부(예: 官方 프로필 중심), 없으면 일반적으로 공식 프로필과 신뢰 가능한 보도 자료를 우선 확인하겠습니다.\\n\\n확인 절차 예시:\\n- 공식 프로필(수상 기관 웹사이트 등)에서 출생지 정보 확인\\n- 신뢰 가능한 보도자료나 학술/정부 자료와 교차 확인\\n- 출처를 함께 제시하여 근거를 명시\\n\\n수상자 이름을 알려주시면 바로 1단계인 출생지 확인을 시작하겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '도와드릴게요. 다만 수상자의 이름이 필요합니다. 이름을 알려주시면 공식 프로필이나 신뢰 가능한 출처에서 출생지(국가)를 확인해 드리겠습니다.\\n\\n제가 수행할 절차은 다음과 같습니다.\\n- 우선순위: 수상자의 공식 프로필/발표 자료를 우선 확인\\n- 그다음: 기관 웹사이트, 정부·공신력 있는 매체의 신뢰 가능한 출처, 수상자 본인의 인터뷰 등에서 출생지 정보를 수집\\n- 다수의 출처를 대조해 일치 여부를 확인하고, 모호하거나 불일치가 있을 경우 근거를 함께 제시\\n- 결과를 한국어 표현으로 정리(예: 수상자의 출생국가는 ○○입니다) 및 필요 시 출처 링크 제공\\n\\n수상자의 이름을 알려주시면 바로 검색을 시작하겠습니다. 또한 특정 상의 수상자(연도나 카테고리)가 있다면 함께 알려주면 더 정확하게 확인할 수 있습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다. 대상: 2024년 노벨문학상 수상자 Han Kang(한강). 확인 우선 순위: 공식 노벨상 웹사이트의 수상자 페이지/생애 정보, 수상자 본인의 공식 프로필, Britannica 등 신뢰 가능한 자료. 확인 항목: 출생지 국가(가능하면 도시)와 국가명이 일치하는지 교차 확인.', '다음은 1단계(출생지 확인) 결과입니다.\\n\\n결과 요약\\n- 수상자: Han Kang(한강), 2024년 노벨문학상 수상자\\n- 확인된 출생 도시: 광주\\n- 확인된 출생 국가: 대한민국(한국)\\n- 교차 확인 결과: 공식 노벨상 웹사이트의 수상자 정보와 Britannica의 인물 정보 모두 \"광주, 대한민국\"으로 일치합니다.\\n\\n주요 근거\\n- Nobel Prize in Literature 2024 – Han Kang – Facts\\n  - Born: 27 November 1970, Gwangju, South Korea\\n  - 신뢰성: 공식 수상자 페이지(1차 자료)\\n  - 링크: https://www.nobelprize.org/prizes/literature/2024/han/facts/\\n\\n- Britannica – Han Kang\\n  - Born: November 27, 1970, Gwangju, South Korea\\n  - 신뢰성: 권위 있는 백과사전\\n  - 링크: https://www.britannica.com/biography/Han-Kang\\n\\n추가 메모\\n- 다른 신뢰 가능한 자료(예: 공식 출판사/대학 프로필)에서도 동일한 정보가 확인됩니다. 다만 1단계의 우선 순위가 공식 노벨상 사이트와 Britannica이므로 이 두 출처의 일치가 확인의 핵심 근거입니다.\\n\\n다음으로 진행하시려면, 2단계(한국어 표현으로 기록)와 3단계(한국어 최종 문장 작성)도 진행해 드리겠습니다. 필요 시 출처를 함께 제시하는 형식으로 이어서 작성해 드릴게요.'), ('3) 확인된 출생국가를 한국어 표현으로 기록한다. 필요 시 출생지 도시도 함께 기록: 광주, 대한민국. 기록 예시: 수상자의 출생국가는 한국입니다.', '수상자의 출생국가는 한국입니다.\\n필요 시 출생지 도시는 광주, 대한민국입니다.')]\n",
            "response \n",
            "**************************************************\n",
            "input 2024년 노벨 문학상 수상자의 출신국가는 어디인가요?\n",
            "plan ['4) 한국어로 최종 답을 작성한다. 예시: 수상자의 출생국가는 한국입니다. 필요 시 출생지 도시를 함께 표시할 수 있다: 광주, 대한민국.', '5) 필요 시 출처를 함께 제시하여 확인 가능하도록 한다. 결과에 출처 링크를 첨부하고, 각 출처의 신뢰성을 간단히 표시한다. 사용 근거: Nobel Prize in Literature 2024 – Han Kang – Facts; Britannica – Han Kang.']\n",
            "past_steps [('1) 공식 노벨상 웹사이트에서 2024년 노벨문학상 수상자를 확인한다.', '확인 결과:\\n- 2024년 노벨문학상 수상자는 Han Kang(한강)입니다.\\n- 공식 노벨상 웹사이트에 수상자 정보가 등재되어 있습니다: https://www.nobelprize.org/prizes/literature/2024/summary/'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '확인했습니다. 다만 어떤 수상자를 지칭하는지 알려주셔야 1단계(공식 프로필 또는 신뢰 가능한 출처에서 출생지 확인)를 실행할 수 있습니다.\\n\\n다음 정보를 제공해 주세요:\\n- 수상 상의 정확한 명칭(예: 특정 상의 이름과 연도)\\n- 수상자 이름(복수일 경우 각 수상자)\\n- 가능하면 수상자 목록도 함께\\n\\n제가 할 일은:\\n1) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인\\n2) 확인된 출생국가를 한국어 표현으로 기록\\n3) 필요한 경우 출처를 함께 제시해 확인 가능하도록 정리\\n\\n참고로 결과 형식은 예시처럼:\\n- 수상자의 출생국가는 미국입니다. (출처: 공식 페이지 A, 기사 B)\\n또는 출생지가 확인되지 않으면 그 상태를 명확히 표시하고, 확인이 필요한 출처를 함께 적겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '수상자 이름이 필요합니다. 어떤 수상자의 출생지를 확인하면 될까요?\\n\\n가능하면 아래 정보를 함께 알려 주세요.\\n- 수상자 이름\\n- 상의 이름(또는 주최 기관)과 수상 연도(선택 사항)\\n- 확인하고 싶은 특정 출처 요구 여부(예: 官方 프로필 중심), 없으면 일반적으로 공식 프로필과 신뢰 가능한 보도 자료를 우선 확인하겠습니다.\\n\\n확인 절차 예시:\\n- 공식 프로필(수상 기관 웹사이트 등)에서 출생지 정보 확인\\n- 신뢰 가능한 보도자료나 학술/정부 자료와 교차 확인\\n- 출처를 함께 제시하여 근거를 명시\\n\\n수상자 이름을 알려주시면 바로 1단계인 출생지 확인을 시작하겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '도와드릴게요. 다만 수상자의 이름이 필요합니다. 이름을 알려주시면 공식 프로필이나 신뢰 가능한 출처에서 출생지(국가)를 확인해 드리겠습니다.\\n\\n제가 수행할 절차은 다음과 같습니다.\\n- 우선순위: 수상자의 공식 프로필/발표 자료를 우선 확인\\n- 그다음: 기관 웹사이트, 정부·공신력 있는 매체의 신뢰 가능한 출처, 수상자 본인의 인터뷰 등에서 출생지 정보를 수집\\n- 다수의 출처를 대조해 일치 여부를 확인하고, 모호하거나 불일치가 있을 경우 근거를 함께 제시\\n- 결과를 한국어 표현으로 정리(예: 수상자의 출생국가는 ○○입니다) 및 필요 시 출처 링크 제공\\n\\n수상자의 이름을 알려주시면 바로 검색을 시작하겠습니다. 또한 특정 상의 수상자(연도나 카테고리)가 있다면 함께 알려주면 더 정확하게 확인할 수 있습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다. 대상: 2024년 노벨문학상 수상자 Han Kang(한강). 확인 우선 순위: 공식 노벨상 웹사이트의 수상자 페이지/생애 정보, 수상자 본인의 공식 프로필, Britannica 등 신뢰 가능한 자료. 확인 항목: 출생지 국가(가능하면 도시)와 국가명이 일치하는지 교차 확인.', '다음은 1단계(출생지 확인) 결과입니다.\\n\\n결과 요약\\n- 수상자: Han Kang(한강), 2024년 노벨문학상 수상자\\n- 확인된 출생 도시: 광주\\n- 확인된 출생 국가: 대한민국(한국)\\n- 교차 확인 결과: 공식 노벨상 웹사이트의 수상자 정보와 Britannica의 인물 정보 모두 \"광주, 대한민국\"으로 일치합니다.\\n\\n주요 근거\\n- Nobel Prize in Literature 2024 – Han Kang – Facts\\n  - Born: 27 November 1970, Gwangju, South Korea\\n  - 신뢰성: 공식 수상자 페이지(1차 자료)\\n  - 링크: https://www.nobelprize.org/prizes/literature/2024/han/facts/\\n\\n- Britannica – Han Kang\\n  - Born: November 27, 1970, Gwangju, South Korea\\n  - 신뢰성: 권위 있는 백과사전\\n  - 링크: https://www.britannica.com/biography/Han-Kang\\n\\n추가 메모\\n- 다른 신뢰 가능한 자료(예: 공식 출판사/대학 프로필)에서도 동일한 정보가 확인됩니다. 다만 1단계의 우선 순위가 공식 노벨상 사이트와 Britannica이므로 이 두 출처의 일치가 확인의 핵심 근거입니다.\\n\\n다음으로 진행하시려면, 2단계(한국어 표현으로 기록)와 3단계(한국어 최종 문장 작성)도 진행해 드리겠습니다. 필요 시 출처를 함께 제시하는 형식으로 이어서 작성해 드릴게요.'), ('3) 확인된 출생국가를 한국어 표현으로 기록한다. 필요 시 출생지 도시도 함께 기록: 광주, 대한민국. 기록 예시: 수상자의 출생국가는 한국입니다.', '수상자의 출생국가는 한국입니다.\\n필요 시 출생지 도시는 광주, 대한민국입니다.'), ('4) 한국어로 최종 답을 작성한다. 예시: 수상자의 출생국가는 한국입니다. 필요 시 출생지 도시를 함께 표시할 수 있다: 광주, 대한민국.', '수상자의 출생국가는 한국입니다. 필요 시 출생지 도시를 함께 표시할 수 있다: 광주, 대한민국.')]\n",
            "response \n",
            "**************************************************\n",
            "input 2024년 노벨 문학상 수상자의 출신국가는 어디인가요?\n",
            "plan ['5) 한국어 최종 답변에 수상자의 출생국가를 한국어로 명시하고 필요 시 출생지 도시를 함께 기록한다(예: 수상자의 출생국가는 한국입니다. 필요 시 출생지: 광주, 대한민국). 또한 출처를 함께 제시하고 각 출처의 신뢰성을 간단히 표시한다. 예시 출처: Nobel Prize in Literature 2024 – Han Kang – Facts; Britannica – Han Kang.']\n",
            "past_steps [('1) 공식 노벨상 웹사이트에서 2024년 노벨문학상 수상자를 확인한다.', '확인 결과:\\n- 2024년 노벨문학상 수상자는 Han Kang(한강)입니다.\\n- 공식 노벨상 웹사이트에 수상자 정보가 등재되어 있습니다: https://www.nobelprize.org/prizes/literature/2024/summary/'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '확인했습니다. 다만 어떤 수상자를 지칭하는지 알려주셔야 1단계(공식 프로필 또는 신뢰 가능한 출처에서 출생지 확인)를 실행할 수 있습니다.\\n\\n다음 정보를 제공해 주세요:\\n- 수상 상의 정확한 명칭(예: 특정 상의 이름과 연도)\\n- 수상자 이름(복수일 경우 각 수상자)\\n- 가능하면 수상자 목록도 함께\\n\\n제가 할 일은:\\n1) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인\\n2) 확인된 출생국가를 한국어 표현으로 기록\\n3) 필요한 경우 출처를 함께 제시해 확인 가능하도록 정리\\n\\n참고로 결과 형식은 예시처럼:\\n- 수상자의 출생국가는 미국입니다. (출처: 공식 페이지 A, 기사 B)\\n또는 출생지가 확인되지 않으면 그 상태를 명확히 표시하고, 확인이 필요한 출처를 함께 적겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '수상자 이름이 필요합니다. 어떤 수상자의 출생지를 확인하면 될까요?\\n\\n가능하면 아래 정보를 함께 알려 주세요.\\n- 수상자 이름\\n- 상의 이름(또는 주최 기관)과 수상 연도(선택 사항)\\n- 확인하고 싶은 특정 출처 요구 여부(예: 官方 프로필 중심), 없으면 일반적으로 공식 프로필과 신뢰 가능한 보도 자료를 우선 확인하겠습니다.\\n\\n확인 절차 예시:\\n- 공식 프로필(수상 기관 웹사이트 등)에서 출생지 정보 확인\\n- 신뢰 가능한 보도자료나 학술/정부 자료와 교차 확인\\n- 출처를 함께 제시하여 근거를 명시\\n\\n수상자 이름을 알려주시면 바로 1단계인 출생지 확인을 시작하겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '도와드릴게요. 다만 수상자의 이름이 필요합니다. 이름을 알려주시면 공식 프로필이나 신뢰 가능한 출처에서 출생지(국가)를 확인해 드리겠습니다.\\n\\n제가 수행할 절차은 다음과 같습니다.\\n- 우선순위: 수상자의 공식 프로필/발표 자료를 우선 확인\\n- 그다음: 기관 웹사이트, 정부·공신력 있는 매체의 신뢰 가능한 출처, 수상자 본인의 인터뷰 등에서 출생지 정보를 수집\\n- 다수의 출처를 대조해 일치 여부를 확인하고, 모호하거나 불일치가 있을 경우 근거를 함께 제시\\n- 결과를 한국어 표현으로 정리(예: 수상자의 출생국가는 ○○입니다) 및 필요 시 출처 링크 제공\\n\\n수상자의 이름을 알려주시면 바로 검색을 시작하겠습니다. 또한 특정 상의 수상자(연도나 카테고리)가 있다면 함께 알려주면 더 정확하게 확인할 수 있습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다. 대상: 2024년 노벨문학상 수상자 Han Kang(한강). 확인 우선 순위: 공식 노벨상 웹사이트의 수상자 페이지/생애 정보, 수상자 본인의 공식 프로필, Britannica 등 신뢰 가능한 자료. 확인 항목: 출생지 국가(가능하면 도시)와 국가명이 일치하는지 교차 확인.', '다음은 1단계(출생지 확인) 결과입니다.\\n\\n결과 요약\\n- 수상자: Han Kang(한강), 2024년 노벨문학상 수상자\\n- 확인된 출생 도시: 광주\\n- 확인된 출생 국가: 대한민국(한국)\\n- 교차 확인 결과: 공식 노벨상 웹사이트의 수상자 정보와 Britannica의 인물 정보 모두 \"광주, 대한민국\"으로 일치합니다.\\n\\n주요 근거\\n- Nobel Prize in Literature 2024 – Han Kang – Facts\\n  - Born: 27 November 1970, Gwangju, South Korea\\n  - 신뢰성: 공식 수상자 페이지(1차 자료)\\n  - 링크: https://www.nobelprize.org/prizes/literature/2024/han/facts/\\n\\n- Britannica – Han Kang\\n  - Born: November 27, 1970, Gwangju, South Korea\\n  - 신뢰성: 권위 있는 백과사전\\n  - 링크: https://www.britannica.com/biography/Han-Kang\\n\\n추가 메모\\n- 다른 신뢰 가능한 자료(예: 공식 출판사/대학 프로필)에서도 동일한 정보가 확인됩니다. 다만 1단계의 우선 순위가 공식 노벨상 사이트와 Britannica이므로 이 두 출처의 일치가 확인의 핵심 근거입니다.\\n\\n다음으로 진행하시려면, 2단계(한국어 표현으로 기록)와 3단계(한국어 최종 문장 작성)도 진행해 드리겠습니다. 필요 시 출처를 함께 제시하는 형식으로 이어서 작성해 드릴게요.'), ('3) 확인된 출생국가를 한국어 표현으로 기록한다. 필요 시 출생지 도시도 함께 기록: 광주, 대한민국. 기록 예시: 수상자의 출생국가는 한국입니다.', '수상자의 출생국가는 한국입니다.\\n필요 시 출생지 도시는 광주, 대한민국입니다.'), ('4) 한국어로 최종 답을 작성한다. 예시: 수상자의 출생국가는 한국입니다. 필요 시 출생지 도시를 함께 표시할 수 있다: 광주, 대한민국.', '수상자의 출생국가는 한국입니다. 필요 시 출생지 도시를 함께 표시할 수 있다: 광주, 대한민국.')]\n",
            "response \n",
            "**************************************************\n",
            "input 2024년 노벨 문학상 수상자의 출신국가는 어디인가요?\n",
            "plan ['5) 한국어 최종 답변에 수상자의 출생국가를 한국어로 명시하고 필요 시 출생지 도시를 함께 기록한다(예: 수상자의 출생국가는 한국입니다. 필요 시 출생지: 광주, 대한민국). 또한 출처를 함께 제시하고 각 출처의 신뢰성을 간단히 표시한다. 예시 출처: Nobel Prize in Literature 2024 – Han Kang – Facts; Britannica – Han Kang.']\n",
            "past_steps [('1) 공식 노벨상 웹사이트에서 2024년 노벨문학상 수상자를 확인한다.', '확인 결과:\\n- 2024년 노벨문학상 수상자는 Han Kang(한강)입니다.\\n- 공식 노벨상 웹사이트에 수상자 정보가 등재되어 있습니다: https://www.nobelprize.org/prizes/literature/2024/summary/'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '확인했습니다. 다만 어떤 수상자를 지칭하는지 알려주셔야 1단계(공식 프로필 또는 신뢰 가능한 출처에서 출생지 확인)를 실행할 수 있습니다.\\n\\n다음 정보를 제공해 주세요:\\n- 수상 상의 정확한 명칭(예: 특정 상의 이름과 연도)\\n- 수상자 이름(복수일 경우 각 수상자)\\n- 가능하면 수상자 목록도 함께\\n\\n제가 할 일은:\\n1) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인\\n2) 확인된 출생국가를 한국어 표현으로 기록\\n3) 필요한 경우 출처를 함께 제시해 확인 가능하도록 정리\\n\\n참고로 결과 형식은 예시처럼:\\n- 수상자의 출생국가는 미국입니다. (출처: 공식 페이지 A, 기사 B)\\n또는 출생지가 확인되지 않으면 그 상태를 명확히 표시하고, 확인이 필요한 출처를 함께 적겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '수상자 이름이 필요합니다. 어떤 수상자의 출생지를 확인하면 될까요?\\n\\n가능하면 아래 정보를 함께 알려 주세요.\\n- 수상자 이름\\n- 상의 이름(또는 주최 기관)과 수상 연도(선택 사항)\\n- 확인하고 싶은 특정 출처 요구 여부(예: 官方 프로필 중심), 없으면 일반적으로 공식 프로필과 신뢰 가능한 보도 자료를 우선 확인하겠습니다.\\n\\n확인 절차 예시:\\n- 공식 프로필(수상 기관 웹사이트 등)에서 출생지 정보 확인\\n- 신뢰 가능한 보도자료나 학술/정부 자료와 교차 확인\\n- 출처를 함께 제시하여 근거를 명시\\n\\n수상자 이름을 알려주시면 바로 1단계인 출생지 확인을 시작하겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '도와드릴게요. 다만 수상자의 이름이 필요합니다. 이름을 알려주시면 공식 프로필이나 신뢰 가능한 출처에서 출생지(국가)를 확인해 드리겠습니다.\\n\\n제가 수행할 절차은 다음과 같습니다.\\n- 우선순위: 수상자의 공식 프로필/발표 자료를 우선 확인\\n- 그다음: 기관 웹사이트, 정부·공신력 있는 매체의 신뢰 가능한 출처, 수상자 본인의 인터뷰 등에서 출생지 정보를 수집\\n- 다수의 출처를 대조해 일치 여부를 확인하고, 모호하거나 불일치가 있을 경우 근거를 함께 제시\\n- 결과를 한국어 표현으로 정리(예: 수상자의 출생국가는 ○○입니다) 및 필요 시 출처 링크 제공\\n\\n수상자의 이름을 알려주시면 바로 검색을 시작하겠습니다. 또한 특정 상의 수상자(연도나 카테고리)가 있다면 함께 알려주면 더 정확하게 확인할 수 있습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다. 대상: 2024년 노벨문학상 수상자 Han Kang(한강). 확인 우선 순위: 공식 노벨상 웹사이트의 수상자 페이지/생애 정보, 수상자 본인의 공식 프로필, Britannica 등 신뢰 가능한 자료. 확인 항목: 출생지 국가(가능하면 도시)와 국가명이 일치하는지 교차 확인.', '다음은 1단계(출생지 확인) 결과입니다.\\n\\n결과 요약\\n- 수상자: Han Kang(한강), 2024년 노벨문학상 수상자\\n- 확인된 출생 도시: 광주\\n- 확인된 출생 국가: 대한민국(한국)\\n- 교차 확인 결과: 공식 노벨상 웹사이트의 수상자 정보와 Britannica의 인물 정보 모두 \"광주, 대한민국\"으로 일치합니다.\\n\\n주요 근거\\n- Nobel Prize in Literature 2024 – Han Kang – Facts\\n  - Born: 27 November 1970, Gwangju, South Korea\\n  - 신뢰성: 공식 수상자 페이지(1차 자료)\\n  - 링크: https://www.nobelprize.org/prizes/literature/2024/han/facts/\\n\\n- Britannica – Han Kang\\n  - Born: November 27, 1970, Gwangju, South Korea\\n  - 신뢰성: 권위 있는 백과사전\\n  - 링크: https://www.britannica.com/biography/Han-Kang\\n\\n추가 메모\\n- 다른 신뢰 가능한 자료(예: 공식 출판사/대학 프로필)에서도 동일한 정보가 확인됩니다. 다만 1단계의 우선 순위가 공식 노벨상 사이트와 Britannica이므로 이 두 출처의 일치가 확인의 핵심 근거입니다.\\n\\n다음으로 진행하시려면, 2단계(한국어 표현으로 기록)와 3단계(한국어 최종 문장 작성)도 진행해 드리겠습니다. 필요 시 출처를 함께 제시하는 형식으로 이어서 작성해 드릴게요.'), ('3) 확인된 출생국가를 한국어 표현으로 기록한다. 필요 시 출생지 도시도 함께 기록: 광주, 대한민국. 기록 예시: 수상자의 출생국가는 한국입니다.', '수상자의 출생국가는 한국입니다.\\n필요 시 출생지 도시는 광주, 대한민국입니다.'), ('4) 한국어로 최종 답을 작성한다. 예시: 수상자의 출생국가는 한국입니다. 필요 시 출생지 도시를 함께 표시할 수 있다: 광주, 대한민국.', '수상자의 출생국가는 한국입니다. 필요 시 출생지 도시를 함께 표시할 수 있다: 광주, 대한민국.'), ('5) 한국어 최종 답변에 수상자의 출생국가를 한국어로 명시하고 필요 시 출생지 도시를 함께 기록한다(예: 수상자의 출생국가는 한국입니다. 필요 시 출생지: 광주, 대한민국). 또한 출처를 함께 제시하고 각 출처의 신뢰성을 간단히 표시한다. 예시 출처: Nobel Prize in Literature 2024 – Han Kang – Facts; Britannica – Han Kang.', '다음은 요청하신 형태로 정리한 최종 답변 초안입니다.\\n\\n- 수상자: 한강(Han Kang) — 2024년 노벨 문학상 수상자\\n- 출생국가: 한국(대한민국)\\n- 필요 시 출생지: 광주, 대한민국\\n\\n참고 출처 및 신뢰도\\n- Nobel Prize in Literature 2024 – Han Kang – NobelPrize.org. 신뢰도: 공식 기관 사이트로 수상자 정보의 1차 출처.\\n- Britannica – Han Kang. 신뢰도: 권위 있는 국제 백과사전으로 생애 및 선수 정보의 신뢰도 높음.')]\n",
            "response \n",
            "**************************************************\n",
            "input 2024년 노벨 문학상 수상자의 출신국가는 어디인가요?\n",
            "plan ['5) 한국어 최종 답변에 수상자의 출생국가를 한국어로 명시하고 필요 시 출생지 도시를 함께 기록한다(예: 수상자의 출생국가는 한국입니다. 필요 시 출생지: 광주, 대한민국). 또한 출처를 함께 제시하고 각 출처의 신뢰성을 간단히 표시한다. 예시 출처: Nobel Prize in Literature 2024 – Han Kang – Facts; Britannica – Han Kang.']\n",
            "past_steps [('1) 공식 노벨상 웹사이트에서 2024년 노벨문학상 수상자를 확인한다.', '확인 결과:\\n- 2024년 노벨문학상 수상자는 Han Kang(한강)입니다.\\n- 공식 노벨상 웹사이트에 수상자 정보가 등재되어 있습니다: https://www.nobelprize.org/prizes/literature/2024/summary/'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '확인했습니다. 다만 어떤 수상자를 지칭하는지 알려주셔야 1단계(공식 프로필 또는 신뢰 가능한 출처에서 출생지 확인)를 실행할 수 있습니다.\\n\\n다음 정보를 제공해 주세요:\\n- 수상 상의 정확한 명칭(예: 특정 상의 이름과 연도)\\n- 수상자 이름(복수일 경우 각 수상자)\\n- 가능하면 수상자 목록도 함께\\n\\n제가 할 일은:\\n1) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인\\n2) 확인된 출생국가를 한국어 표현으로 기록\\n3) 필요한 경우 출처를 함께 제시해 확인 가능하도록 정리\\n\\n참고로 결과 형식은 예시처럼:\\n- 수상자의 출생국가는 미국입니다. (출처: 공식 페이지 A, 기사 B)\\n또는 출생지가 확인되지 않으면 그 상태를 명확히 표시하고, 확인이 필요한 출처를 함께 적겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '수상자 이름이 필요합니다. 어떤 수상자의 출생지를 확인하면 될까요?\\n\\n가능하면 아래 정보를 함께 알려 주세요.\\n- 수상자 이름\\n- 상의 이름(또는 주최 기관)과 수상 연도(선택 사항)\\n- 확인하고 싶은 특정 출처 요구 여부(예: 官方 프로필 중심), 없으면 일반적으로 공식 프로필과 신뢰 가능한 보도 자료를 우선 확인하겠습니다.\\n\\n확인 절차 예시:\\n- 공식 프로필(수상 기관 웹사이트 등)에서 출생지 정보 확인\\n- 신뢰 가능한 보도자료나 학술/정부 자료와 교차 확인\\n- 출처를 함께 제시하여 근거를 명시\\n\\n수상자 이름을 알려주시면 바로 1단계인 출생지 확인을 시작하겠습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다.', '도와드릴게요. 다만 수상자의 이름이 필요합니다. 이름을 알려주시면 공식 프로필이나 신뢰 가능한 출처에서 출생지(국가)를 확인해 드리겠습니다.\\n\\n제가 수행할 절차은 다음과 같습니다.\\n- 우선순위: 수상자의 공식 프로필/발표 자료를 우선 확인\\n- 그다음: 기관 웹사이트, 정부·공신력 있는 매체의 신뢰 가능한 출처, 수상자 본인의 인터뷰 등에서 출생지 정보를 수집\\n- 다수의 출처를 대조해 일치 여부를 확인하고, 모호하거나 불일치가 있을 경우 근거를 함께 제시\\n- 결과를 한국어 표현으로 정리(예: 수상자의 출생국가는 ○○입니다) 및 필요 시 출처 링크 제공\\n\\n수상자의 이름을 알려주시면 바로 검색을 시작하겠습니다. 또한 특정 상의 수상자(연도나 카테고리)가 있다면 함께 알려주면 더 정확하게 확인할 수 있습니다.'), ('2) 수상자의 공식 프로필 또는 신뢰 가능한 출처에서 출생지(국가)를 확인한다. 대상: 2024년 노벨문학상 수상자 Han Kang(한강). 확인 우선 순위: 공식 노벨상 웹사이트의 수상자 페이지/생애 정보, 수상자 본인의 공식 프로필, Britannica 등 신뢰 가능한 자료. 확인 항목: 출생지 국가(가능하면 도시)와 국가명이 일치하는지 교차 확인.', '다음은 1단계(출생지 확인) 결과입니다.\\n\\n결과 요약\\n- 수상자: Han Kang(한강), 2024년 노벨문학상 수상자\\n- 확인된 출생 도시: 광주\\n- 확인된 출생 국가: 대한민국(한국)\\n- 교차 확인 결과: 공식 노벨상 웹사이트의 수상자 정보와 Britannica의 인물 정보 모두 \"광주, 대한민국\"으로 일치합니다.\\n\\n주요 근거\\n- Nobel Prize in Literature 2024 – Han Kang – Facts\\n  - Born: 27 November 1970, Gwangju, South Korea\\n  - 신뢰성: 공식 수상자 페이지(1차 자료)\\n  - 링크: https://www.nobelprize.org/prizes/literature/2024/han/facts/\\n\\n- Britannica – Han Kang\\n  - Born: November 27, 1970, Gwangju, South Korea\\n  - 신뢰성: 권위 있는 백과사전\\n  - 링크: https://www.britannica.com/biography/Han-Kang\\n\\n추가 메모\\n- 다른 신뢰 가능한 자료(예: 공식 출판사/대학 프로필)에서도 동일한 정보가 확인됩니다. 다만 1단계의 우선 순위가 공식 노벨상 사이트와 Britannica이므로 이 두 출처의 일치가 확인의 핵심 근거입니다.\\n\\n다음으로 진행하시려면, 2단계(한국어 표현으로 기록)와 3단계(한국어 최종 문장 작성)도 진행해 드리겠습니다. 필요 시 출처를 함께 제시하는 형식으로 이어서 작성해 드릴게요.'), ('3) 확인된 출생국가를 한국어 표현으로 기록한다. 필요 시 출생지 도시도 함께 기록: 광주, 대한민국. 기록 예시: 수상자의 출생국가는 한국입니다.', '수상자의 출생국가는 한국입니다.\\n필요 시 출생지 도시는 광주, 대한민국입니다.'), ('4) 한국어로 최종 답을 작성한다. 예시: 수상자의 출생국가는 한국입니다. 필요 시 출생지 도시를 함께 표시할 수 있다: 광주, 대한민국.', '수상자의 출생국가는 한국입니다. 필요 시 출생지 도시를 함께 표시할 수 있다: 광주, 대한민국.'), ('5) 한국어 최종 답변에 수상자의 출생국가를 한국어로 명시하고 필요 시 출생지 도시를 함께 기록한다(예: 수상자의 출생국가는 한국입니다. 필요 시 출생지: 광주, 대한민국). 또한 출처를 함께 제시하고 각 출처의 신뢰성을 간단히 표시한다. 예시 출처: Nobel Prize in Literature 2024 – Han Kang – Facts; Britannica – Han Kang.', '다음은 요청하신 형태로 정리한 최종 답변 초안입니다.\\n\\n- 수상자: 한강(Han Kang) — 2024년 노벨 문학상 수상자\\n- 출생국가: 한국(대한민국)\\n- 필요 시 출생지: 광주, 대한민국\\n\\n참고 출처 및 신뢰도\\n- Nobel Prize in Literature 2024 – Han Kang – NobelPrize.org. 신뢰도: 공식 기관 사이트로 수상자 정보의 1차 출처.\\n- Britannica – Han Kang. 신뢰도: 권위 있는 국제 백과사전으로 생애 및 선수 정보의 신뢰도 높음.')]\n",
            "response 수상자의 출생국가는 한국(대한민국)입니다. 필요 시 출생지는 광주, 대한민국입니다. 신뢰할 만한 근거: Nobel Prize in Literature 2024 – Han Kang – Facts(공식 수상 페이지) 및 Britannica – Han Kang. 두 출처의 정보가 일치합니다.\n",
            "**************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 코드 수정을 반복하는 데이터 전처리 Agent"
      ],
      "metadata": {
        "id": "I8A_ujta32uf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 클로드\n",
        "\n",
        "클로드(Claude)는 앤트로픽(Anthropic)에서 개발한 대규모 언어 모델(LLM) 기반의 인공지능 챗봇으로, 사람과의 대화, 글쓰기, 요약, 코드 작성 등 다양한 작업을 수행할 수 있는 생성형 AI입니다. 이름은 인공지능의 선구자 클로드 섀넌(Claude Shannon)에서 따왔으며, “헌宪법 기반 AI(constitutional AI)” 접근법을 적용해 안전성과 투명성을 강화한 것이 특징입니다. 즉, 인간의 직접적인 지시보다는 미리 정해둔 원칙과 가이드라인을 통해 스스로 출력을 조율하도록 설계되었기 때문에, 사용자가 안심하고 활용할 수 있는 대화형 AI라는 점에서 주목받고 있습니다."
      ],
      "metadata": {
        "id": "CFoLjMt04oV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "_set_env(\"OPENAI_API_KEY\")\n",
        "_set_env(\"ANTHROPIC_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9bD6KEP357H",
        "outputId": "ae9c5f69-ba07-4554-d7fd-e2e5d8d3111f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANTHROPIC_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "3YYY_5ht7FBR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def describe_data(csv: str) -> str:\n",
        "    \"\"\"Describe the date column in the dataframe.\n",
        "    Args:\n",
        "        csv: csv data path string\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(csv)\n",
        "    describe_str = f\"\"\"Data: {csv}\"\"\" + df.describe(include='all').to_string()\n",
        "    return describe_str"
      ],
      "metadata": {
        "id": "RU4UyO3j7Nas"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools=[describe_data]"
      ],
      "metadata": {
        "id": "wHuISQ357gsA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "8JRVi7Yp7j9l",
        "outputId": "a806ba20-3599-4038-80fc-c950c7b5a3b8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.76 (from langchain_openai)\n",
            "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.106.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.4.24)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (25.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (2.11.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.104.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.76->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.5.0)\n",
            "Downloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core, langchain_openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.75\n",
            "    Uninstalling langchain-core-0.3.75:\n",
            "      Successfully uninstalled langchain-core-0.3.75\n",
            "Successfully installed langchain-core-0.3.76 langchain_openai-0.3.33\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "langchain_core"
                ]
              },
              "id": "45c35728138a4802a3d95d11f1fafaed"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_anthropic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBhy9chE7rbz",
        "outputId": "5430ff87-d3c1-41e0-9e9f-419309f378c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_anthropic\n",
            "  Downloading langchain_anthropic-0.3.20-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting anthropic<1,>=0.67.0 (from langchain_anthropic)\n",
            "  Downloading anthropic-0.67.0-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.76 in /usr/local/lib/python3.12/dist-packages (from langchain_anthropic) (0.3.76)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain_anthropic) (2.11.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1,>=0.67.0->langchain_anthropic) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1,>=0.67.0->langchain_anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1,>=0.67.0->langchain_anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1,>=0.67.0->langchain_anthropic) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic<1,>=0.67.0->langchain_anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic<1,>=0.67.0->langchain_anthropic) (4.15.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (0.4.24)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (6.0.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (0.4.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.67.0->langchain_anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic<1,>=0.67.0->langchain_anthropic) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic<1,>=0.67.0->langchain_anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1,>=0.67.0->langchain_anthropic) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (0.24.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (2.5.0)\n",
            "Downloading langchain_anthropic-0.3.20-py3-none-any.whl (31 kB)\n",
            "Downloading anthropic-0.67.0-py3-none-any.whl (317 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic, langchain_anthropic\n",
            "Successfully installed anthropic-0.67.0 langchain_anthropic-0.3.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "llm_gpt = ChatOpenAI(model=\"gpt-5-nano\")\n",
        "llm_with_tools = llm_gpt.bind_tools(tools, tool_choice=\"any\")"
      ],
      "metadata": {
        "id": "7yGFyopQ730Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm_with_tools.invoke(\n",
        "    \"https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diabetes.csv 이 데이터의 전처리를 해주세요.\"\n",
        ")"
      ],
      "metadata": {
        "id": "H2jG9WUg79d3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.tool_calls[0]['args']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKzKnVp39smc",
        "outputId": "88001153-0ab6-4859-98bb-cd8c15579562"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'csv': 'https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diabetes.csv'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class code(BaseModel):\n",
        "    \"\"\"Schema for code solutions.\"\"\"\n",
        "    # 코드에 대한 접근방식\n",
        "    prefix: str = Field(description=\"Description of the problem and approach\")\n",
        "    # 코드의 import 영역\n",
        "    imports: str = Field(description=\"Code block import statements\")\n",
        "    # 코드 자체에 대한\n",
        "    code: str = Field(description=\"Code block not including import statements\")"
      ],
      "metadata": {
        "id": "cOnhO6Cy9y5e"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "GENERATE_CODE_TEMPLATE = \"\"\"\n",
        "Given the following pandas `describe()` output of a dataset,\n",
        "write a **directly executable Python code** to:\n",
        "1. handle missing values,\n",
        "2. convert categorical columns,\n",
        "3. ...any additional preprocessing needed,\n",
        "4. prepare the dataset for machine learning.\n",
        "Here is the describe result of the dataset:\n",
        "\\n ------- \\n  {context} \\n ------- \\n\n",
        "Do not wrap the code in a function and the response in any backticks or anything else. The code should be written as a flat script, so that it can be run immediately and any errors will be visible during execution.\n",
        "Ensure any code you provide can be executed \\n\n",
        "with all required imports and variables defined. Structure your answer with a description of the code solution. \\n\n",
        "Then list the imports. And finally list the functioning code block.\n",
        "\"\"\"\n",
        "\n",
        "code_gen_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"user\", GENERATE_CODE_TEMPLATE),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "9ZiSXPgc-QZa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "llm_claude= ChatAnthropic(model=\"claude-sonnet-4-20250514\")"
      ],
      "metadata": {
        "id": "OqboRNW-_gcd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool_result = describe_data.invoke(response.tool_calls[0]['args'])\n",
        "print(tool_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezWfIRgi_5h0",
        "outputId": "bcdc023b-3b79-49fb-e44a-714cfea94e82"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diabetes.csv       Number of times pregnant  Plasma glucose concentration a 2 hours in an oral glucose tolerance test  Diastolic blood pressure (mm Hg)  Triceps skin fold thickness (mm)  2-Hour serum insulin (mu U/ml)  Body mass index (weight in kg/(height in m)^2)  Diabetes pedigree function  Age (years)  Class variable\n",
            "count                768.000000                                                                768.000000                        768.000000                        768.000000                      768.000000                                      768.000000                  768.000000   768.000000      768.000000\n",
            "mean                   3.845052                                                                120.894531                         69.105469                         20.536458                       79.799479                                       31.992578                    0.471876    33.240885        0.348958\n",
            "std                    3.369578                                                                 31.972618                         19.355807                         15.952218                      115.244002                                        7.884160                    0.331329    11.760232        0.476951\n",
            "min                    0.000000                                                                  0.000000                          0.000000                          0.000000                        0.000000                                        0.000000                    0.078000    21.000000        0.000000\n",
            "25%                    1.000000                                                                 99.000000                         62.000000                          0.000000                        0.000000                                       27.300000                    0.243750    24.000000        0.000000\n",
            "50%                    3.000000                                                                117.000000                         72.000000                         23.000000                       30.500000                                       32.000000                    0.372500    29.000000        0.000000\n",
            "75%                    6.000000                                                                140.250000                         80.000000                         32.000000                      127.250000                                       36.600000                    0.626250    41.000000        1.000000\n",
            "max                   17.000000                                                                199.000000                        122.000000                         99.000000                      846.000000                                       67.100000                    2.420000    81.000000        1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_code = llm_claude.invoke(\n",
        "    code_gen_prompt.format_messages(context=tool_result)\n",
        ")\n",
        "print(\"generated_code\", generated_code)\n",
        "# 클라드 결제 안되서 키 에러남"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "LO6WvZq5_wtb",
        "outputId": "681b8a80-4a9d-486e-fbf2-0b2a421961d9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "\"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3573555560.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m generated_code = llm_claude.invoke(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mcode_gen_prompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generated_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m         return cast(\n\u001b[1;32m    394\u001b[0m             \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    396\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     ) -> LLMResult:\n\u001b[1;32m   1022\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    838\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 results.append(\n\u001b[0;32m--> 840\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    841\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1090\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_anthropic/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1633\u001b[0m         \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_request_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1636\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0manthropic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBadRequestError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m             \u001b[0m_handle_anthropic_bad_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_anthropic/chat_models.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m   1492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"betas\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_acreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/anthropic/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/anthropic/resources/messages/messages.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, max_tokens, messages, model, metadata, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m             )\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;34m\"/v1/messages\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m         )\n\u001b[0;32m-> 1324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0mremaining_retries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_retries\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mretries_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretries_taken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretries_taken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36m_build_request\u001b[0;34m(self, options, retries_taken)\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unexpected JSON data type, {type(json_data)}, cannot merge with `extra_body`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretries_taken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretries_taken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_merge_mappings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mcontent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36m_build_headers\u001b[0;34m(self, options, retries_taken)\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mcustom_headers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         )\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;31m# headers are case-insensitive while dictionaries are not.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/anthropic/_client.py\u001b[0m in \u001b[0;36m_validate_headers\u001b[0;34m(self, headers, custom_headers)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;34m'\"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
            "\u001b[0;31mTypeError\u001b[0m: \"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_structurer = llm_gpt.with_structured_output(code)\n",
        "code_solution = code_structurer.invoke(generated_code.content)\n",
        "print(\"code_solution\", code_solution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "wOEBJB1SA_9b",
        "outputId": "566b37fe-9e6a-40aa-a674-fc3db96da5f2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'generated_code' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2942024546.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcode_structurer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm_gpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_structured_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcode_solution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode_structurer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_code\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"code_solution\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_solution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generated_code' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(code_solution.imports)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "eh_YYj3cBRGw",
        "outputId": "ba24368a-caad-413c-c1a3-77f1d71dec98"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'code_solution' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2512048323.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_solution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimports\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'code_solution' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8IaG0feEyXS",
        "outputId": "3b0aebde-86f9-4eda-e431-ac1bf7839926"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.76)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.6-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.24)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.24.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.6-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.6 ormsgpack-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, MessagesState\n",
        "\n",
        "class State(MessagesState): # messages\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "    Attributes:\n",
        "        error : Binary flag for control flow to indicate whether test error was tripped\n",
        "        context: Data summary\n",
        "        generation : Code solution\n",
        "        iterations : Number of tries\n",
        "    \"\"\"\n",
        "    error: str # yes or no\n",
        "    context: str\n",
        "    generation: str\n",
        "    iterations: int\n",
        "graph_builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "iANb19ZoE1OZ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_with_tools = llm_gpt.bind_tools(tools=[describe_data])  # llm이 알아서 하도록"
      ],
      "metadata": {
        "id": "9BMb5PppFMTP"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state: State):\n",
        "    print(\"##### HI ! #####\")\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    print(\"첫번째 LLM 호출 결과 : \", response)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I8--br8Fn70",
        "outputId": "1eac4826-3c57-44c0-b118-a9387f3fb430"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7a9640dc6a80>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_context(state: State):\n",
        "    print(\"##### ADD CONTEXT #####\")\n",
        "    if messages := state.get(\"messages\", []):\n",
        "        message = messages[-1] # 마지막 message 꺼내서 저장\n",
        "    else:\n",
        "        raise ValueError(\"No message found in input\")\n",
        "    for tool_call in message.tool_calls:\n",
        "        for tool in tools:\n",
        "            if tool.name == tool_call['name']:\n",
        "                describe_str = tool.invoke(tool_call['args'])\n",
        "\n",
        "    # Get context from describe_data tool\n",
        "    print(\"데이터 통계 (context) : \", describe_str[:100])\n",
        "    return {\"context\": describe_str}\n",
        "\n",
        "graph_builder.add_node(\"add_context\", add_context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6IRSsnuF47_",
        "outputId": "948c9191-437a-496b-a45e-f69366740cfb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7a9640dc6a80>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END\n",
        "\n",
        "def guardrail_route(\n",
        "    state: State,\n",
        "):\n",
        "    \"\"\"\n",
        "    Use in the conditional_edge to route to the ToolNode if the last message\n",
        "    has tool calls. Otherwise, route to the end.\n",
        "    \"\"\"\n",
        "    if isinstance(state, list):\n",
        "        ai_message = state[-1]\n",
        "    elif messages := state.get(\"messages\", []):\n",
        "        ai_message = messages[-1]\n",
        "    else:\n",
        "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
        "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "        return \"add_context\"\n",
        "    return END\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    guardrail_route,\n",
        "    {\"add_context\": \"add_context\", END: END},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYvlund8Gf15",
        "outputId": "cb0101c6-2cf8-4d62-f413-4cf9b9ad1ab2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7a9640dc6a80>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class code(BaseModel):\n",
        "    \"\"\"Schema for code solutions.\"\"\"\n",
        "    prefix: str = Field(description=\"Description of the problem and approach\")\n",
        "    imports: str = Field(description=\"Code block import statements\")\n",
        "    code: str = Field(description=\"Code block not including import statements\")"
      ],
      "metadata": {
        "id": "jkwS1HwxHUFy"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "GENERATE_CODE_TEMPLATE = \"\"\"\n",
        "Given the following pandas `describe()` output of a dataset,\n",
        "write a **directly executable Python code** to:\n",
        "1. handle missing values,\n",
        "2. convert categorical columns,\n",
        "3. ...any additional preprocessing needed,\n",
        "4. prepare the dataset for machine learning.\n",
        "Here is the describe result of the dataset:\n",
        "\\n ------- \\n  {context} \\n ------- \\n\n",
        "Do not wrap the code in a function and the response in any backticks or anything else. The code should be written as a flat script, so that it can be run immediately and any errors will be visible during execution.\n",
        "Ensure any code you provide can be executed \\n\n",
        "with all required imports and variables defined. Structure your answer with a description of the code solution. \\n\n",
        "Then list the imports. And finally list the functioning code block.\n",
        "\"\"\"\n",
        "\n",
        "code_gen_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"user\", GENERATE_CODE_TEMPLATE),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "A_-bN69pHWq_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(state: State):\n",
        "    print(\"##### GENERATING CODE SOLUTION #####\")\n",
        "    context = state[\"context\"]\n",
        "    generated_code = llm_claude.invoke(\n",
        "        code_gen_prompt.format_messages(context=context)\n",
        "    )\n",
        "    code_structurer = llm_gpt.with_structured_output(code)\n",
        "    code_solution = code_structurer.invoke(generated_code.content)\n",
        "    messages = [\n",
        "        (\n",
        "            \"assistant\",\n",
        "            f\"{code_solution.prefix} \\n Imports: {code_solution.imports} \\n Code: {code_solution.code}\",\n",
        "        )\n",
        "    ]\n",
        "    return {\"generation\": code_solution, \"messages\": messages}\n",
        "graph_builder.add_node(\"generate\", generate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc-uJUtjIHnP",
        "outputId": "02536fa8-da23-4fb7-af3f-ac4d86f8e192"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7a9640dc6a80>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def code_check(state: State):\n",
        "    print(\"##### CHECKING CODE #####\")\n",
        "    code_solution = state[\"generation\"]\n",
        "    imports = code_solution.imports\n",
        "    code = code_solution.code\n",
        "    # Check imports\n",
        "    try:\n",
        "        exec(imports)\n",
        "    except Exception as e:\n",
        "        print(\"---CODE IMPORT CHECK: FAILED---\")\n",
        "        error_message = [(\"user\", f\"Your solution failed the import test: {e}\")]\n",
        "        print(\"에러 메시지 : \", error_message)\n",
        "        return {\n",
        "            \"generation\": code_solution,\n",
        "            \"messages\": error_message,\n",
        "            \"error\": \"yes\",\n",
        "        }\n",
        "    # Check execution\n",
        "    try:\n",
        "        exec(imports + \"\\n\" + code)\n",
        "    except Exception as e:\n",
        "        print(\"---CODE BLOCK CHECK: FAILED---\")\n",
        "        error_message = [(\"user\", f\"Your solution failed the code execution test: {e}\")]\n",
        "        print(\"에러 메시지 : \", error_message)\n",
        "        return {\n",
        "            \"generation\": code_solution,\n",
        "            \"messages\": error_message,\n",
        "            \"error\": \"yes\",\n",
        "        }\n",
        "    # No errors\n",
        "    print(\"---NO CODE TEST FAILURES---\")\n",
        "    return {\n",
        "        \"generation\": code_solution,\n",
        "        \"error\": \"no\",\n",
        "    }\n",
        "graph_builder.add_node(\"code_check\", code_check)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kvbs3wVhIJ72",
        "outputId": "295d26b1-db0d-4f8b-e554-e5838d781ada"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7a9640dc6a80>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "reflect_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"\n",
        "            You are given an error message that occurred while running a Python script, along with the original code that produced the error.\n",
        "            Provide a corrected version of the original code that resolves the issue.\n",
        "            Ensure the code runs without errors and maintains the intended functionality.\"\"\"\n",
        "        ),\n",
        "        (\n",
        "            \"user\",\n",
        "            \"\"\"\n",
        "            --- ERROR MESSAGE ---\n",
        "            {error}\n",
        "            --- ORIGINAL CODE ---\n",
        "            {code_solution}\n",
        "            ----------------------\n",
        "            Ensure any code you provide can be executed \\n\n",
        "            with all required imports and variables defined. Structure your answer with a description of the code solution. \\n\n",
        "            Then list the imports. And finally list the functioning code block.\"\"\",\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "JLomuyDZIrXt"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reflect(state: State):\n",
        "    print(\"---REFLECTING CODE SOLUTION---\")\n",
        "    error = state[\"messages\"][-1].content\n",
        "    code_solution = state[\"generation\"]\n",
        "    code_solution = f\"{code_solution.prefix} \\n Imports: {code_solution.imports} \\n Code: {code_solution.code}\"\n",
        "    corrected_code = llm_claude.invoke(reflect_prompt.format_messages(error=error, code_solution=code_solution))\n",
        "    code_structurer = llm_gpt.with_structured_output(code)\n",
        "    reflections = code_structurer.invoke(corrected_code.content)\n",
        "    print(\"수정된 코드 : \", reflections)\n",
        "    messages = [\n",
        "        (\n",
        "            \"assistant\",\n",
        "            f\"{reflections.prefix} \\n Imports: {reflections.imports} \\n Code: {reflections.code}\",\n",
        "        )\n",
        "    ]\n",
        "    return {\"generation\": reflections, \"messages\": messages, \"iterations\": state[\"iterations\"] + 1}\n",
        "graph_builder.add_node(\"reflect\", reflect)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TVmDUOPIw79",
        "outputId": "ce9f9eba-9b34-4d3e-b2a6-144e489a5086"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7a9640dc6a80>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_iterations=5"
      ],
      "metadata": {
        "id": "PeJZd8rNJfS-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decide_to_finish(state: State):\n",
        "    error = state[\"error\"]\n",
        "    iterations = state[\"iterations\"]\n",
        "    if error == \"no\" or iterations == max_iterations: # 에러가 없거나 max_iterations에 도달하면 종료\n",
        "        print(\"---DECISION: FINISH---\")\n",
        "        return \"end\"\n",
        "    else:\n",
        "        print(\"---DECISION: RE-TRY SOLUTION---\")\n",
        "        return \"reflect\""
      ],
      "metadata": {
        "id": "ajnpm4ZHJjgG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import START, END\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"add_context\", \"generate\")\n",
        "graph_builder.add_edge(\"generate\", \"code_check\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"code_check\",\n",
        "    decide_to_finish,\n",
        "    {\n",
        "        \"end\": END,\n",
        "        \"reflect\": \"reflect\"\n",
        "    },\n",
        ")\n",
        "graph_builder.add_edge(\"reflect\", \"code_check\")\n",
        "graph = graph_builder.compile()\n",
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "id": "Z9V48kz7Jl1p",
        "outputId": "36f57b60-eec8-4407-8119-eda5a9db6b47"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x7a955f5cf260>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q3I412ecXXwN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}