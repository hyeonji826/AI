{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNlViivff2asq5Z2breLmBO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 1. PyTorch\n","PyTorch는 파이썬 기반의 오픈소스 딥러닝 프레임워크로, 파이썬 코드로 AI 모델을 직관적으로 만들고 학습할 수 있도록 도와주는 도구입니다. 특히 동적 계산 그래프 방식을 사용하기 때문에 코드 실행 시점에 실시간으로 계산 흐름이 결정되어 디버깅과 수정이 쉽고, GPU 가속과 자동 미분 기능을 통해 대규모 모델도 빠르게 학습할 수 있습니다."],"metadata":{"id":"vL9ryBc9ePRw"}},{"cell_type":"markdown","source":["### ※ 동적 계산 그래프 방식\n","\n","딥러닝 모델이 학습 및 예측을 수행할 때 계산 그래프를 실행 시점(runtime)에 실시간으로 생성 및 수정하는 방식입니다. 이 방식은 조건문, 반복문 등 복잡한 논리 구조를 유연하게 처리할 수 있으며, 주로 PyTorch와 같은 프레임워크에서 사용됩니다. 계산 그래프는 입력 데이터를 바탕으로 연산을 수행하면서 그래프를 생성하고, 역전파를 통해 미분을 계산하며, 최종적으로 가중치를 업데이트하는 과정을 거칩니다. 이러한 특성 덕분에 디버깅이 용이하고 연구 및 개발 속도가 빠르며 직관적인 코드 작성이 가능합니다."],"metadata":{"id":"Tv15rNc6eUtP"}},{"cell_type":"markdown","source":["### 1. 스칼라(Scalar)\n","\n","스칼라(Scalar)는 단 하나의 숫자(정수, 실수 등)만을 담는 자료형을 말합니다. 파이토치(PyTorch)에서 스칼라는 0차원 텐서(0-dimensional Tensor)로 표현합니다. 즉, 텐서의 차원(Shape)이 전혀 없는 상태를 의미합니다."],"metadata":{"id":"n7dStuukeW-L"}},{"cell_type":"code","source":["import torch"],"metadata":{"id":"YnTE_OB6e1qb","executionInfo":{"status":"ok","timestamp":1753335540251,"user_tz":-540,"elapsed":5386,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"epbXy0MXdAFe","executionInfo":{"status":"ok","timestamp":1753334793709,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"95d5d190-b84c-4adf-8e4b-6fca2ef9fdbb"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(5)\n","torch.Size([])\n","torch.Size([1])\n","tensor(8)\n","8\n"]}],"source":["# tensor : 자료구조!\n","var1 = torch.tensor(5)\n","print(var1)\n","print(var1.shape)       # torch.Size([]) -> 0차원 텐서\n","var2 = torch.tensor([10])\n","print(var2.shape)       # torch.Size([1]) -> 1차원 텐서. 스칼라가 아님\n","\n","var3 = torch.tensor(3)\n","result = var1 + var3\n","print(result)        # tensor(8)\n","print(result.item()) # 8 -> 텐서 값(스칼라)을 파이썬 숫자로 추출함"]},{"cell_type":"markdown","source":["### 2. 벡터(Vector)\n","\n","벡터(Vector)는 하나 이상의 원소가 일렬로 나열된 1차원 텐서(1D Tensor)를 의미합니다. 파이토치(PyTorch)에서 벡터는 일반적으로 torch.tensor([...]) 형태로 만들며, 이때 텐서의 shape(차원)가 (n,) 형태입니다. 즉, 원소가 n개 들어 있으면 1차원 벡터가 됩니다.\n","\n","<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2F3k1UK%2FbtqAMORINFu%2FAAAAAAAAAAAAAAAAAAAAAJokwdKl_tvOLf4uCncm4SvcR5Jx2xJfo-bD16G-aiBf%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1753973999%26allow_ip%3D%26allow_referer%3D%26signature%3DBDEJeAX2okMMtIumdKSLBdt18Vs%253D\">"],"metadata":{"id":"t35V0UUcefCG"}},{"cell_type":"code","source":["var1 = torch.tensor([1.0, 2.0, 3.0])\n","print(var1)\n","print(var1.shape) # torch.Size([3]) -> 1차원 텐서\n","\n","var2 = var1 + 10\n","print(var2)\n","var3 = var1 * 2\n","print(var3)\n","\n","# float형 tensor\n","var2 = torch.FloatTensor([1, 2, 3])\n","print(var2)\n","\n","# int형 tensor\n","var3 = torch.LongTensor([1, 2, 3])\n","print(var3)\n","\n","var4 = torch.tensor([4.0, 5.0, 6.0])\n","result = var1 + var4\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8tOEs0INeh4A","executionInfo":{"status":"ok","timestamp":1753334793764,"user_tz":-540,"elapsed":53,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"3233b9cb-83aa-4c79-a8cc-0ed5eb7ac7a7"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 2., 3.])\n","torch.Size([3])\n","tensor([11., 12., 13.])\n","tensor([2., 4., 6.])\n","tensor([1., 2., 3.])\n","tensor([1, 2, 3])\n","tensor([5., 7., 9.])\n"]}]},{"cell_type":"markdown","source":["### 3. 행렬(Matrix)\n","\n","행렬(Matrix)은 2차원 형태의 텐서로, 파이토치(PyTorch)에서는 shape가 (m, n)처럼 2개의 차원을 가진 텐서를 의미합니다. 예를 들어, torch.tensor([[1, 2], [3, 4]])는 2행×2열 형태의 행렬입니다. 행렬 연산에서는 행렬 곱셈, 원소별 연산, 전치(Transpose) 등이 자주 활용되며, 파이토치는 torch.mm 또는 @ 연산자를 통해 행렬 곱셈을 수행할 수 있습니다."],"metadata":{"id":"KqU9AW6MekTQ"}},{"cell_type":"code","source":["var1 = torch.tensor([[1, 2],\n","                  [3, 4]])\n","var2 = torch.tensor([[5, 6],\n","                  [7, 8]])\n","\n","print(var1)\n","print(var1.shape) # torch.Size([2, 2]) -> 2차원 텐서\n","\n","result1 = var1 + var2\n","print(result1)\n","result2 = var1 * var2\n","print(result2)\n","\n","result3 = torch.mm(var1, var2)\n","print(result3)\n","result4 = var1 @ var2\n","print(result4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S5Qowz_Nemtd","executionInfo":{"status":"ok","timestamp":1753334793807,"user_tz":-540,"elapsed":25,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"422cecb0-65f3-4d55-d82e-c254c44e583c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 2],\n","        [3, 4]])\n","torch.Size([2, 2])\n","tensor([[ 6,  8],\n","        [10, 12]])\n","tensor([[ 5, 12],\n","        [21, 32]])\n","tensor([[19, 22],\n","        [43, 50]])\n","tensor([[19, 22],\n","        [43, 50]])\n"]}]},{"cell_type":"markdown","source":["### 4. 다차원 텐서 ((Multi-dimensional Tensor))\n","\n","파이토치(PyTorch)에서 다차원 텐서란, 여러 축(차원)을 가지는 텐서를 의미합니다. 예를 들어, 0차원 텐서는 “스칼라(Scalar)”, 1차원 텐서는 “벡터(Vector)”, 2차원 텐서는 “행렬(Matrix)”, 그 이상의 3차원, 4차원 텐서 등을 통틀어 “다차원 텐서(Multi-dimensional Tensor)”라고 부릅니다. 다차원 텐서는 이미지, 음성, 동영상, 시계열 데이터를 비롯하여 여러 축을 필요로 하는 다양한 형태의 데이터를 표현할 때 쓰입니다."],"metadata":{"id":"A-UPeiIkeqUc"}},{"cell_type":"code","source":["var1 = torch.tensor([\n","    [[1, 2],\n","     [3, 4]],\n","\n","    [[5, 6],\n","     [7, 8]]\n","])\n","\n","print(var1)\n","print(var1.shape)  # torch.Size([2, 2, 2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H19j5mpResh3","executionInfo":{"status":"ok","timestamp":1753334794043,"user_tz":-540,"elapsed":234,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"8ed056d3-1431-4cb7-d66e-97d772c8c9c0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[1, 2],\n","         [3, 4]],\n","\n","        [[5, 6],\n","         [7, 8]]])\n","torch.Size([2, 2, 2])\n"]}]},{"cell_type":"markdown","source":["<img src=\"https://blog.kakaocdn.net/dna/biuxtz/btsPv6i3FEq/AAAAAAAAAAAAAAAAAAAAAOx79mK30ZVYKDa8R4ThVux0PNY3I7OVzUHgJVMHstaa/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1753973999&allow_ip=&allow_referer=&signature=jSWHlIKYEngJU5jRn5ZaBS4giJs%3D\">"],"metadata":{"id":"nYOOGW5teuvL"}},{"cell_type":"markdown","source":["## 2. 텐서\n","PyTorch의 텐서(Tensor)는 딥러닝 모델에서 데이터를 다룰 때 사용되는 기본 데이터 구조입니다. 텐서는 다차원 배열로, NumPy의 배열과 비슷하지만, GPU에서 연산을 수행할 수 있다는 점에서 차이가 있습니다. PyTorch의 텐서는 데이터의 표현뿐만 아니라, 자동 미분(autograd) 기능을 제공하여 딥러닝 모델의 학습을 도와줍니다."],"metadata":{"id":"ESm5iP5M3jGB"}},{"cell_type":"code","source":["data = [\n","  [1, 2],\n","  [3, 4]\n","]\n","t1 = torch.tensor(data)\n","\n","print(t1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ExfHNeRK3lJp","executionInfo":{"status":"ok","timestamp":1753334794049,"user_tz":-540,"elapsed":159,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"dc52972b-30d5-4b73-8cb3-d661318f8085"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 2],\n","        [3, 4]])\n"]}]},{"cell_type":"code","source":["t1 = torch.tensor([5])\n","t2 = torch.tensor([7])\n","\n","ndarr1 = (t1 + t2).numpy()\n","print(ndarr1)\n","print(type(ndarr1))\n","\n","result = ndarr1 * 10\n","t3 = torch.from_numpy(result)\n","print(t3)\n","print(type(t3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"svQMWMAQ3nLQ","executionInfo":{"status":"ok","timestamp":1753334794294,"user_tz":-540,"elapsed":245,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"3065fa32-8a53-44b3-9aac-3e1a28382b48"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[12]\n","<class 'numpy.ndarray'>\n","tensor([120])\n","<class 'torch.Tensor'>\n"]}]},{"cell_type":"code","source":["t1 = torch.tensor([\n","    [1, 2, 3, 4],\n","    [5, 6, 7, 8],\n","    [9, 10, 11, 12]\n","])\n","\n","print(t1[0])\n","print(t1[:, 0])\n","print(t1[:, -1])\n","print(t1[..., -1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yc2l2TtM3ogB","executionInfo":{"status":"ok","timestamp":1753334794300,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"6adeadd2-016a-4aa1-fa48-cc4050a94133"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3, 4])\n","tensor([1, 5, 9])\n","tensor([ 4,  8, 12])\n","tensor([ 4,  8, 12])\n"]}]},{"cell_type":"code","source":["t1 = torch.tensor([[[1, 2, 3],\n","                    [4, 5, 6]],\n","                    [[7, 8, 9],\n","                    [10, 11, 12]]])\n","\n","print(t1.shape)\n","print(t1[..., -1]) # 첫 번째와 두 번째 차원을 유지. 마지막 요소만 선택"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ICj6H_p_3qo2","executionInfo":{"status":"ok","timestamp":1753334794322,"user_tz":-540,"elapsed":20,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"80c3e638-235a-4387-fbbe-a1089f146156"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 2, 3])\n","tensor([[ 3,  6],\n","        [ 9, 12]])\n"]}]},{"cell_type":"markdown","source":["## 3. GPU 사용\n","GPU (Graphics Processing Unit)는 그래픽 처리 장치로, 주로 이미지 렌더링과 같은 대규모 병렬 계산을 수행하는 데 최적화된 하드웨어입니다. 원래는 그래픽 처리를 위해 설계되었지만, 최근에는 인공지능(AI) 및 딥러닝의 연산 가속기로 널리 사용되고 있습니다. 딥러닝은 수천, 수만 개의 행렬 및 벡터 연산을 필요로 합니다. GPU는 여러 개의 코어를 사용하여 이 연산을 병렬로 처리할 수 있습니다. 따라서 GPU는 딥러닝 에 최적화된 구조를 가지고 있습니다.\n","\n","\n","\n","Google Colab을 이용하면, 손쉽게 PyTorch를 이용해 GPU를 사용할 수 있습니다.\n","\n","    [런타임] - [런타임 유형 변경] - [원하는 GPU, TPU를 선택]\n"],"metadata":{"id":"4II2T_Weeyn5"}},{"cell_type":"markdown","source":["## ※ 구글 코랩 GPU, TPU 비교\n","\n","<img src=\"https://blog.kakaocdn.net/dna/cUZ2jf/btsPxe82oXc/AAAAAAAAAAAAAAAAAAAAAM_sW8YyDgsaqvzFrEaiEwGVfvuNzLc3uYl4156_1-de/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1753973999&allow_ip=&allow_referer=&signature=2rjEGx2VJEOcLejZst9Z3i9VUSI%3D\">\n","\n","> Colab은 T4 GPU를 무료로 제공하고 있습니다.\n","유료 GPU 옵션은 비용 대비 효과적일 수 있습니다. A100은 비싸지만 속도가 13배 빠릅니다.\n","\n","\n","\n","- A100 GPU: 대규모 학습과 고성능 컴퓨팅에 최적화되어 있으며, 높은 메모리 용량과 대역폭을 제공합니다.\n","\n","- L4 GPU: 에너지 효율성이 높고, 추론 작업에 최적화되어 있습니다.\n","\n","- T4 GPU: 에너지 효율성이 우수하며, 중간 규모의 학습 및 추론 작업에 적합합니다.\n","\n","- TPU v2-8: 대규모 행렬 연산에 최적화되어 있으며, TensorFlow와의 호환성이 높습니다.\n","\n","- TPU v5e-1: 중형 및 대규모 학습, 추론에 필요한 비용 효율성과 성능을 제공하며, 최신 TPU 아키텍처를 기반으로 합니다.\n","\n"],"metadata":{"id":"ntf6COBf5BWu"}},{"cell_type":"code","source":["data = [\n","  [1, 2],\n","  [3, 4]\n","]\n","\n","t1 = torch.tensor(data)\n","print(t1.is_cuda)\n","\n","t1 = t1.cuda() # GPU로 옮기기\n","print(t1.is_cuda)\n","\n","t1 = t1.cpu() # CPU로 옮기기\n","print(t1.is_cuda)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CnnoGUc15Uhf","executionInfo":{"status":"ok","timestamp":1753334794342,"user_tz":-540,"elapsed":18,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"d6c3f230-e804-4217-c4da-e93541f721c1"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n","True\n","False\n"]}]},{"cell_type":"code","source":["t1 = torch.tensor([\n","    [1, 1],\n","    [2, 2]\n","]).cuda()\n","\n","t2 = torch.tensor([\n","    [5, 6],\n","    [7, 8]\n","])\n","\n","# print(torch.matmul(t1, t2)) # 오류 발생\n","print(torch.matmul(t1.cpu(), t2))\n","print(f\"Device: {t1.device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4p901alE5eVg","executionInfo":{"status":"ok","timestamp":1753334803950,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"b6136d66-357e-4e28-af27-a75c4643a91f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[12, 14],\n","        [24, 28]])\n","Device: cuda:0\n"]}]},{"cell_type":"markdown","source":["## 4. 텐서의 연산과 함수"],"metadata":{"id":"hgodwmAX8CA9"}},{"cell_type":"code","source":["t1 = torch.tensor([\n","    [1, 2],\n","    [3, 4]\n","])\n","t2 = torch.tensor([\n","    [5, 6],\n","    [7, 8]\n","])\n","print(t1 + t2)\n","print(t1 - t2)\n","print(t1 * t2)\n","print(t1 / t2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wOh4BgV48DWD","executionInfo":{"status":"ok","timestamp":1753335547236,"user_tz":-540,"elapsed":175,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"804a38c1-666d-474e-e092-5eec8679b772"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 6,  8],\n","        [10, 12]])\n","tensor([[-4, -4],\n","        [-4, -4]])\n","tensor([[ 5, 12],\n","        [21, 32]])\n","tensor([[0.2000, 0.3333],\n","        [0.4286, 0.5000]])\n"]}]},{"cell_type":"code","source":["t1 = torch.tensor([\n","    [1, 2],\n","    [3, 4]\n","])\n","t2 = torch.tensor([\n","    [5, 6],\n","    [7, 8]\n","])\n","\n","# 행렬곱 방법1\n","print(t1.matmul(t2))\n","# 행렬곱 방법2\n","print(torch.matmul(t1, t2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qut_m_q48Gmt","executionInfo":{"status":"ok","timestamp":1753335551502,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"e7ff2f7d-9b8b-430e-ae17-c09feb3d5777"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[19, 22],\n","        [43, 50]])\n","tensor([[19, 22],\n","        [43, 50]])\n"]}]},{"cell_type":"code","source":["t1 = torch.Tensor([\n","    [1, 2, 3, 4],\n","    [5, 6, 7, 8]\n","])\n","print(t1)\n","print(t1.mean()) # 전체 원소에 대한 평균\n","print(t1.mean(dim=0)) # 각 열에 대하여 평균 계산\n","print(t1.mean(dim=1)) # 각 행에 대하여 평균 계산"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ESum83Kq8I_c","executionInfo":{"status":"ok","timestamp":1753335573166,"user_tz":-540,"elapsed":35,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"44bfda37-1564-4e23-8856-9f000e77e0d3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 2., 3., 4.],\n","        [5., 6., 7., 8.]])\n","tensor(4.5000)\n","tensor([3., 4., 5., 6.])\n","tensor([2.5000, 6.5000])\n"]}]},{"cell_type":"code","source":["t1 = torch.Tensor([\n","    [1, 2, 3, 4],\n","    [5, 6, 7, 8]\n","])\n","print(t1)\n","print(t1.argmax())      # 전체 원소에 대한 최댓값의 인덱스\n","print(t1.argmax(dim=0)) # 각 열에 대하여 최댓값의 인덱스 계산\n","print(t1.argmax(dim=1)) # 각 행에 대하여 최댓값의 인덱스 계산"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fvFvkGNJ8KOc","executionInfo":{"status":"ok","timestamp":1753335574496,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"051df202-0aae-4ccd-aad7-48ba2513a5e3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 2., 3., 4.],\n","        [5., 6., 7., 8.]])\n","tensor(7)\n","tensor([1, 1, 1, 1])\n","tensor([3, 3])\n"]}]},{"cell_type":"markdown","source":["## 5. 텐서의 차원 조작"],"metadata":{"id":"aGUlwPLR8McV"}},{"cell_type":"code","source":["t1 = torch.tensor([\n","    [1, 2, 3, 4],\n","    [5, 6, 7, 8],\n","    [9, 10, 11, 12]\n","])\n","\n","# 계산이면 0: 열 , 1: 행\n","# 계산이 아니면 0: 행, 1: 열\n","\n","# dim: 텐서를 이어 붙이기 위한 축\n","# 0번 축(행)을 기준으로 이어 붙이기\n","result = torch.cat([t1, t1, t1], dim=0)\n","print(result)\n","\n","# 1번 축(열)을 기준으로 이어 붙이기\n","result = torch.cat([t1, t1, t1], dim=1)\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RisaOpvR8NYc","executionInfo":{"status":"ok","timestamp":1753335892962,"user_tz":-540,"elapsed":73,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"e3f1af95-bab8-43dd-ff94-4d3c251ccdb4"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1,  2,  3,  4],\n","        [ 5,  6,  7,  8],\n","        [ 9, 10, 11, 12],\n","        [ 1,  2,  3,  4],\n","        [ 5,  6,  7,  8],\n","        [ 9, 10, 11, 12],\n","        [ 1,  2,  3,  4],\n","        [ 5,  6,  7,  8],\n","        [ 9, 10, 11, 12]])\n","tensor([[ 1,  2,  3,  4,  1,  2,  3,  4,  1,  2,  3,  4],\n","        [ 5,  6,  7,  8,  5,  6,  7,  8,  5,  6,  7,  8],\n","        [ 9, 10, 11, 12,  9, 10, 11, 12,  9, 10, 11, 12]])\n"]}]},{"cell_type":"code","source":["# LongTensor -> IntTensor\n","t1 = torch.tensor([2], dtype=torch.int)\n","t2 = torch.tensor([5.0])\n","\n","print(t1.dtype)\n","print(t2.dtype)\n","\n","# 텐서 t1는 자동으로 float32형으로 형변환 처리\n","print(t1 + t2)\n","# 텐서 t2를 int32형으로 형변환하여 덧셈 수행\n","print(t1 + t2.type(torch.int32))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YIQKG-Q08Otq","executionInfo":{"status":"ok","timestamp":1753336190932,"user_tz":-540,"elapsed":24,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"af966ed5-abf9-4ac6-f9da-3cf98d43854f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.int64\n","torch.float32\n","tensor([7.])\n","tensor([7])\n"]}]},{"cell_type":"code","source":["# view()는 텐서의 모양을 변경할 때 사용한다.\n","# 이때, 텐서(tensor)의 순서는 변경되지 않는다.\n","t1 = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8])\n","# view : 가상데이터로 하나 더 만들어주는 것\n","t2 = t1.view(4, 2)\n","print(t2)\n","\n","# t1의 값을 변경하면 t2도 변경\n","t1[0] = 7\n","print(t1)\n","print(t2)\n","\n","# t1의 값을 복사(copy)한 뒤에 변경\n","t3 = t1.clone().view(4, 2)\n","t1[0] = 9\n","print(t3)\n","\n","t4 = t1.reshape(4,2)\n","print(t4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DH4QV3tT-2Mb","executionInfo":{"status":"ok","timestamp":1753336408374,"user_tz":-540,"elapsed":28,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"2afea707-c037-43e1-f230-bc1f2e0893ad"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 2],\n","        [3, 4],\n","        [5, 6],\n","        [7, 8]])\n","tensor([7, 2, 3, 4, 5, 6, 7, 8])\n","tensor([[7, 2],\n","        [3, 4],\n","        [5, 6],\n","        [7, 8]])\n","tensor([[7, 2],\n","        [3, 4],\n","        [5, 6],\n","        [7, 8]])\n","tensor([[9, 2],\n","        [3, 4],\n","        [5, 6],\n","        [7, 8]])\n"]}]},{"cell_type":"code","source":["t1 = torch.rand((64, 32, 3))\n","print(t1.shape)\n","\n","t2 = t1.permute(2, 1, 0) # 차원 자체를 교환\n","# (2번째 축, 1번째 축, 0번째 축)의 형태가 됨\n","print(t2.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AFv1JiEWDuP2","executionInfo":{"status":"ok","timestamp":1753337506449,"user_tz":-540,"elapsed":36,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"fdfe488e-63c2-449b-9bbf-73df7ee7f54c"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 32, 3])\n","torch.Size([3, 32, 64])\n"]}]},{"cell_type":"code","source":["t1 = torch.Tensor([\n","    [1, 2, 3, 4],\n","    [5, 6, 7, 8]\n","])\n","print(t1.shape)\n","\n","# 첫 번째 축에 차원 추가\n","t1 = t1.unsqueeze(0)\n","print(t1)\n","print(t1.shape)\n","\n","# 네 번째 축에 차원 추가\n","t1 = t1.unsqueeze(3)\n","print(t1)\n","print(t1.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8-NjwF4SDvmQ","executionInfo":{"status":"ok","timestamp":1753337510034,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"572e11eb-728e-430c-a77b-1ee5e0db1854"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 4])\n","tensor([[[1., 2., 3., 4.],\n","         [5., 6., 7., 8.]]])\n","torch.Size([1, 2, 4])\n","tensor([[[[1.],\n","          [2.],\n","          [3.],\n","          [4.]],\n","\n","         [[5.],\n","          [6.],\n","          [7.],\n","          [8.]]]])\n","torch.Size([1, 2, 4, 1])\n"]}]},{"cell_type":"code","source":["# 크기가 1인 차원 제거, squeeze(dim): 특정 차원이 1인 경우에만 차원을 제거\n","t1 = t1.squeeze()\n","print(t1)\n","print(t1.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TMNmohMIDxWQ","executionInfo":{"status":"ok","timestamp":1753337508429,"user_tz":-540,"elapsed":38,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"dea11519-1556-48a2-bbd2-5487df4af29d"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[0.6115, 0.0021, 0.8021],\n","         [0.5175, 0.2970, 0.1433],\n","         [0.9983, 0.3853, 0.6583],\n","         ...,\n","         [0.1485, 0.4299, 0.6302],\n","         [0.6690, 0.5214, 0.5744],\n","         [0.5012, 0.6834, 0.2396]],\n","\n","        [[0.8022, 0.6082, 0.3303],\n","         [0.2885, 0.1158, 0.8829],\n","         [0.0408, 0.3779, 0.7715],\n","         ...,\n","         [0.0120, 0.3779, 0.4016],\n","         [0.2209, 0.7626, 0.9883],\n","         [0.7052, 0.5601, 0.9572]],\n","\n","        [[0.5112, 0.9325, 0.4033],\n","         [0.5950, 0.9569, 0.4166],\n","         [0.2489, 0.6621, 0.0172],\n","         ...,\n","         [0.6088, 0.0884, 0.5127],\n","         [0.9337, 0.2063, 0.6083],\n","         [0.4937, 0.1104, 0.1060]],\n","\n","        ...,\n","\n","        [[0.8333, 0.5061, 0.0209],\n","         [0.9297, 0.4620, 0.9148],\n","         [0.1982, 0.2772, 0.2840],\n","         ...,\n","         [0.9416, 0.8520, 0.4170],\n","         [0.7257, 0.2320, 0.3540],\n","         [0.2955, 0.2867, 0.9394]],\n","\n","        [[0.3456, 0.5320, 0.4584],\n","         [0.5667, 0.3132, 0.2447],\n","         [0.3332, 0.9351, 0.2557],\n","         ...,\n","         [0.4799, 0.0814, 0.0339],\n","         [0.6689, 0.5656, 0.1010],\n","         [0.0468, 0.9266, 0.5832]],\n","\n","        [[0.0767, 0.3680, 0.2525],\n","         [0.9412, 0.9168, 0.9640],\n","         [0.9374, 0.5889, 0.5134],\n","         ...,\n","         [0.6157, 0.7511, 0.3339],\n","         [0.2414, 0.6410, 0.1746],\n","         [0.4924, 0.5681, 0.8526]]])\n","torch.Size([64, 32, 3])\n"]}]},{"cell_type":"markdown","source":["## 6. 자동 미분과 기울기"],"metadata":{"id":"x9kRQHTpE8CG"}},{"cell_type":"code","source":["import torch\n","\n","x = torch.tensor([3.0, 4.0], requires_grad=True) # 미분 예정\n","y = torch.tensor([1.0, 2.0], requires_grad=True) # 미분 예정\n","\n","z = x + y # 단순 덧셈\n","out = z.mean() # 평균 계산\n","\n","# out에 대해서 역으로 계산\n","# 각각의 입력 값이 이 결과에 얼마나 영향을 줬는지 알려줘!\n","# 미분값을 자동으로 계산\n","out.backward()\n","\n","print(\"x.grad:\", x.grad) # [0.5, 0.5] 평균 계산에서는 각 원소가 결과에 절반 만큼 영향\n","print(\"y.grad:\", y.grad)\n","print(\"z.grad:\", z.grad) # z는 계산 결과로 만들어진 중간 변수"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5pr6qSYDE95t","executionInfo":{"status":"ok","timestamp":1753337829305,"user_tz":-540,"elapsed":31,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"31b8fd87-a688-4883-a9d7-ec89ec254d07"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["x.grad: tensor([0.5000, 0.5000])\n","y.grad: tensor([0.5000, 0.5000])\n","z.grad: None\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-22-1753591764.py:16: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n","  print(\"z.grad:\", z.grad) # z는 계산 결과로 만들어진 중간 변수\n"]}]},{"cell_type":"markdown","source":["### ※ 수식으로 분석\n","\n","<img src=\"https://blog.kakaocdn.net/dna/b3FpCk/btsPxLLt5q6/AAAAAAAAAAAAAAAAAAAAAFoOzSw4AsevnRQi00-PW1iImRD7p57SvmNFQx8TD5Sy/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1753973999&allow_ip=&allow_referer=&signature=KiJ2iOFrcbK30jCMdKDWQ9xMY24%3D\">\n","\n","```r\n","x[0] ─┬──► z[0] ───► out\n","       │      ↑      ↑\n","y[0] ─┘      │      │\n","               │      │\n","x[1] ─┬──► z[1] ───► out\n","       │\n","y[1] ─┘\n","\n","z의 각 항목은 x와 y에서 왔고,\n","out은 z의 평균이니까 z의 각 항목은 결과에 1/2만큼 기여\n","```"],"metadata":{"id":"zRIxSq4_FKQy"}},{"cell_type":"markdown","source":["<img src=\"https://blog.kakaocdn.net/dna/yl6nL/btsPwzyt61m/AAAAAAAAAAAAAAAAAAAAAAs4-Jwv7fMItUWqrLP4uenzALqumjhRs3aZx-N-P8cT/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1753973999&allow_ip=&allow_referer=&signature=I8O8dg0sVUE4n23%2F49fsAGo3xdA%3D\">"],"metadata":{"id":"vVEkp4idFbc1"}},{"cell_type":"code","source":["# 완전 쉬운 예제\n","x = torch.tensor(4.0,requires_grad=True)\n","y = x*2\n","\n","z = y +1    # z = 2x + 1\n","z.backward()\n","\n","# x가 z에 얼마나 영향을 줬을까?\n","print(x.grad)\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OS4BF6oEFge7","executionInfo":{"status":"ok","timestamp":1753338853480,"user_tz":-540,"elapsed":15,"user":{"displayName":"Hyeonji","userId":"17627784022328153589"}},"outputId":"c21765f9-1439-4577-e2a2-0ce3d0c17f8e"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2.)\n","tensor(9., grad_fn=<AddBackward0>)\n"]}]}]}